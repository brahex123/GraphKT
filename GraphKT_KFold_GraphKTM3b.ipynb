{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "OXYhnccdXdKY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e822996c-c880-4120-c1b7-947cddc26e9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2026.1.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "11hq0iBhW7Kb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a87a27c9-0e2a-4f98-cd6a-38174a52a707"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "PyTorch version: 2.9.0+cu128\n",
            "Configuration loaded successfully (M3 - Dual Propagation)\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Cell 1: Imports and Configuration\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.nn import GCNConv, RGCNConv\n",
        "from torch_geometric.nn import MessagePassing  # ← AJOUT pour MasteryMessagePassing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "from collections import defaultdict\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configuration\n",
        "class Config:\n",
        "    # Data\n",
        "    SEED = 42\n",
        "    TEST_STUDENT_RATIO = 0.15      # 15% students for TEST (Split B)\n",
        "    VAL_STUDENT_RATIO = 0.15       # 15% of TRAIN students for VAL\n",
        "\n",
        "    # Model Architecture\n",
        "    FEATURE_DIM = 5                # ← AJOUT: 5D statistical features\n",
        "    EMBED_DIM = 32\n",
        "    HIDDEN_DIM = 64\n",
        "    NUM_GNN_LAYERS = 2\n",
        "    DROPOUT = 0.2\n",
        "    NUM_BASES = 2                  # ← AJOUT: For RGCN basis decomposition\n",
        "\n",
        "    # Training\n",
        "    BATCH_SIZE = 512               # ← MODIFIÉ: 64 → 512 (meilleure efficacité)\n",
        "    LEARNING_RATE = 1e-3\n",
        "    WEIGHT_DECAY = 0.01\n",
        "    EPOCHS = 100\n",
        "    PATIENCE = 10\n",
        "    GRAD_CLIP = 1.0\n",
        "\n",
        "    # Mastery (M3 specific)\n",
        "    MASTERY_INIT = 0.5             # Valeur init de mastery [0.5 ou 'global_mean']\n",
        "    LAMBDA_EMA = 0.1               # Learning rate mastery update (0.05, 0.1, 0.2)\n",
        "    MASTERY_GATING = 'identity'    # Gating function ['identity' ou 'sigmoid']\n",
        "    GATING_ALPHA = 2.0             # Si sigmoid, alpha parameter\n",
        "\n",
        "    # Device\n",
        "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "config = Config()\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "np.random.seed(config.SEED)\n",
        "torch.manual_seed(config.SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(config.SEED)\n",
        "\n",
        "print(f\"Device: {config.DEVICE}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Configuration loaded successfully (M3 - Dual Propagation)\")  # ← MODIFIÉ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "g3UDZq76XawB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f7dc1f1a-0ec5-4302-b19a-833c4e646788"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "DATASET OVERVIEW\n",
            "============================================================\n",
            "Shape: (809694, 19)\n",
            "\n",
            "Columns (19):\n",
            "   1. Row\n",
            "   2. Anon Student Id\n",
            "   3. Problem Hierarchy\n",
            "   4. Problem Name\n",
            "   5. Problem View\n",
            "   6. Step Name\n",
            "   7. Step Start Time\n",
            "   8. First Transaction Time\n",
            "   9. Correct Transaction Time\n",
            "  10. Step End Time\n",
            "  11. Step Duration (sec)\n",
            "  12. Correct Step Duration (sec)\n",
            "  13. Error Step Duration (sec)\n",
            "  14. Correct First Attempt\n",
            "  15. Incorrects\n",
            "  16. Hints\n",
            "  17. Corrects\n",
            "  18. KC(Default)\n",
            "  19. Opportunity(Default)\n",
            "\n",
            "============================================================\n",
            "FIRST 3 ROWS\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Row Anon Student Id            Problem Hierarchy Problem Name  \\\n",
              "0    1      0BrbPbwCMz  Unit ES_04, Section ES_04-1    EG4-FIXED   \n",
              "1    2      0BrbPbwCMz  Unit ES_04, Section ES_04-1    EG4-FIXED   \n",
              "2    3      0BrbPbwCMz  Unit ES_04, Section ES_04-1         EG40   \n",
              "\n",
              "   Problem View    Step Name        Step Start Time First Transaction Time  \\\n",
              "0             1  3(x+2) = 15  2005-09-09 12:24:35.0  2005-09-09 12:24:49.0   \n",
              "1             1      x+2 = 5  2005-09-09 12:25:15.0  2005-09-09 12:25:31.0   \n",
              "2             1    2-8y = -4  2005-09-09 12:25:36.0  2005-09-09 12:25:43.0   \n",
              "\n",
              "  Correct Transaction Time          Step End Time  Step Duration (sec)  \\\n",
              "0    2005-09-09 12:25:15.0  2005-09-09 12:25:15.0                 40.0   \n",
              "1    2005-09-09 12:25:31.0  2005-09-09 12:25:31.0                 16.0   \n",
              "2    2005-09-09 12:26:12.0  2005-09-09 12:26:12.0                 36.0   \n",
              "\n",
              "   Correct Step Duration (sec)  Error Step Duration (sec)  \\\n",
              "0                          NaN                       40.0   \n",
              "1                         16.0                        NaN   \n",
              "2                          NaN                       36.0   \n",
              "\n",
              "   Correct First Attempt  Incorrects  Hints  Corrects  \\\n",
              "0                      0           2      3         1   \n",
              "1                      1           0      0         1   \n",
              "2                      0           2      3         1   \n",
              "\n",
              "                                         KC(Default) Opportunity(Default)  \n",
              "0  [SkillRule: Eliminate Parens; {CLT nested; CLT...                    1  \n",
              "1  [SkillRule: Remove constant; {ax+b=c, positive...                 1~~1  \n",
              "2  [SkillRule: Remove constant; {ax+b=c, positive...                    2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3bdf5c89-f1a6-4151-a320-5a7a5ff51ee9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Row</th>\n",
              "      <th>Anon Student Id</th>\n",
              "      <th>Problem Hierarchy</th>\n",
              "      <th>Problem Name</th>\n",
              "      <th>Problem View</th>\n",
              "      <th>Step Name</th>\n",
              "      <th>Step Start Time</th>\n",
              "      <th>First Transaction Time</th>\n",
              "      <th>Correct Transaction Time</th>\n",
              "      <th>Step End Time</th>\n",
              "      <th>Step Duration (sec)</th>\n",
              "      <th>Correct Step Duration (sec)</th>\n",
              "      <th>Error Step Duration (sec)</th>\n",
              "      <th>Correct First Attempt</th>\n",
              "      <th>Incorrects</th>\n",
              "      <th>Hints</th>\n",
              "      <th>Corrects</th>\n",
              "      <th>KC(Default)</th>\n",
              "      <th>Opportunity(Default)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0BrbPbwCMz</td>\n",
              "      <td>Unit ES_04, Section ES_04-1</td>\n",
              "      <td>EG4-FIXED</td>\n",
              "      <td>1</td>\n",
              "      <td>3(x+2) = 15</td>\n",
              "      <td>2005-09-09 12:24:35.0</td>\n",
              "      <td>2005-09-09 12:24:49.0</td>\n",
              "      <td>2005-09-09 12:25:15.0</td>\n",
              "      <td>2005-09-09 12:25:15.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>[SkillRule: Eliminate Parens; {CLT nested; CLT...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0BrbPbwCMz</td>\n",
              "      <td>Unit ES_04, Section ES_04-1</td>\n",
              "      <td>EG4-FIXED</td>\n",
              "      <td>1</td>\n",
              "      <td>x+2 = 5</td>\n",
              "      <td>2005-09-09 12:25:15.0</td>\n",
              "      <td>2005-09-09 12:25:31.0</td>\n",
              "      <td>2005-09-09 12:25:31.0</td>\n",
              "      <td>2005-09-09 12:25:31.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[SkillRule: Remove constant; {ax+b=c, positive...</td>\n",
              "      <td>1~~1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0BrbPbwCMz</td>\n",
              "      <td>Unit ES_04, Section ES_04-1</td>\n",
              "      <td>EG40</td>\n",
              "      <td>1</td>\n",
              "      <td>2-8y = -4</td>\n",
              "      <td>2005-09-09 12:25:36.0</td>\n",
              "      <td>2005-09-09 12:25:43.0</td>\n",
              "      <td>2005-09-09 12:26:12.0</td>\n",
              "      <td>2005-09-09 12:26:12.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>[SkillRule: Remove constant; {ax+b=c, positive...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3bdf5c89-f1a6-4151-a320-5a7a5ff51ee9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3bdf5c89-f1a6-4151-a320-5a7a5ff51ee9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3bdf5c89-f1a6-4151-a320-5a7a5ff51ee9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(df_raw['Correct First Attempt']\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Row\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Anon Student Id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"0BrbPbwCMz\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Problem Hierarchy\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Unit ES_04, Section ES_04-1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Problem Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"EG40\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Problem View\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Step Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"3(x+2) = 15\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Step Start Time\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"2005-09-09 12:24:35.0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"First Transaction Time\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"2005-09-09 12:24:49.0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Correct Transaction Time\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"2005-09-09 12:25:15.0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Step End Time\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"2005-09-09 12:25:15.0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Step Duration (sec)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.858201014657274,\n        \"min\": 16.0,\n        \"max\": 40.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          40.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Correct Step Duration (sec)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 16.0,\n        \"max\": 16.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          16.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Error Step Duration (sec)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.8284271247461903,\n        \"min\": 36.0,\n        \"max\": 40.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          36.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Correct First Attempt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Incorrects\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hints\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Corrects\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"KC(Default)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"[SkillRule: Eliminate Parens; {CLT nested; CLT nested, parens; Distribute Mult right; Distribute Mult left; (+/-x +/-a)/b=c, mult; (+/-x +/-a)*b=c, div; [var expr]/[const expr] = [const expr], multiply; Distribute Division left; Distribute Division right; Distribute both mult left; Distribute both mult right; Distribute both divide left; Distribute both divide right; Distribute subex}]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Opportunity(Default)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "DATA TYPES\n",
            "============================================================\n",
            "Row                              int64\n",
            "Anon Student Id                 object\n",
            "Problem Hierarchy               object\n",
            "Problem Name                    object\n",
            "Problem View                     int64\n",
            "Step Name                       object\n",
            "Step Start Time                 object\n",
            "First Transaction Time          object\n",
            "Correct Transaction Time        object\n",
            "Step End Time                   object\n",
            "Step Duration (sec)            float64\n",
            "Correct Step Duration (sec)    float64\n",
            "Error Step Duration (sec)      float64\n",
            "Correct First Attempt            int64\n",
            "Incorrects                       int64\n",
            "Hints                            int64\n",
            "Corrects                         int64\n",
            "KC(Default)                     object\n",
            "Opportunity(Default)            object\n",
            "dtype: object\n",
            "\n",
            "============================================================\n",
            "MISSING VALUES\n",
            "============================================================\n",
            "                             Missing  Percent\n",
            "Step Start Time                  919     0.11\n",
            "Correct Transaction Time       25851     3.19\n",
            "Step Duration (sec)              919     0.11\n",
            "Correct Step Duration (sec)   189565    23.41\n",
            "Error Step Duration (sec)     621048    76.70\n",
            "KC(Default)                   202669    25.03\n",
            "Opportunity(Default)          202669    25.03\n",
            "\n",
            "============================================================\n",
            "KEY STATISTICS\n",
            "============================================================\n",
            "Total interactions: 809,694\n",
            "Unique students: 574\n",
            "Unique problems (questions): 1,084\n",
            "Unique steps: 210,710\n",
            "Unique KC(Default): 436\n",
            "KC(Default) missing: 202,669 (25.03%)\n",
            "\n",
            "============================================================\n",
            "TARGET DISTRIBUTION (Correct First Attempt)\n",
            "============================================================\n",
            "Correct First Attempt\n",
            "1    0.7665\n",
            "0    0.2335\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Cell 2: Load and Explore Dataset\n",
        "# =============================================================================\n",
        "\n",
        "# Load the Algebra 2005-2006 dataset\n",
        "DATA_PATH = \"algebra_2005_2006_train.txt\"\n",
        "\n",
        "# Load with tab separator (standard format for this dataset)\n",
        "df_raw = pd.read_csv(DATA_PATH, sep='\\t', low_memory=False)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"DATASET OVERVIEW\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Shape: {df_raw.shape}\")\n",
        "print(f\"\\nColumns ({len(df_raw.columns)}):\")\n",
        "for i, col in enumerate(df_raw.columns):\n",
        "    print(f\"  {i+1:2d}. {col}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"FIRST 3 ROWS\")\n",
        "print(\"=\" * 60)\n",
        "display(df_raw.head(3))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"DATA TYPES\")\n",
        "print(\"=\" * 60)\n",
        "print(df_raw.dtypes)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"MISSING VALUES\")\n",
        "print(\"=\" * 60)\n",
        "missing = df_raw.isnull().sum()\n",
        "missing_pct = (missing / len(df_raw) * 100).round(2)\n",
        "missing_df = pd.DataFrame({'Missing': missing, 'Percent': missing_pct})\n",
        "print(missing_df[missing_df['Missing'] > 0])\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"KEY STATISTICS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Total interactions: {len(df_raw):,}\")\n",
        "print(f\"Unique students: {df_raw['Anon Student Id'].nunique():,}\")\n",
        "print(f\"Unique problems (questions): {df_raw['Problem Name'].nunique():,}\")\n",
        "print(f\"Unique steps: {df_raw[['Problem Name', 'Step Name']].drop_duplicates().shape[0]:,}\")\n",
        "print(f\"Unique KC(Default): {df_raw['KC(Default)'].nunique():,}\")\n",
        "print(f\"KC(Default) missing: {df_raw['KC(Default)'].isnull().sum():,} ({df_raw['KC(Default)'].isnull().mean()*100:.2f}%)\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TARGET DISTRIBUTION (Correct First Attempt)\")\n",
        "print(\"=\" * 60)\n",
        "print(df_raw['Correct First Attempt'].value_counts(normalize=True).round(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "id": "4X0IrVL6X5Du",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6d570e5f-8cec-4d43-ae4e-cab9fc355630"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "STEP 1: Drop rows with missing critical fields (NOT KC)\n",
            "============================================================\n",
            "Dropped 0 rows (0.00%)\n",
            "Remaining: 809,694 rows\n",
            "\n",
            "============================================================\n",
            "STEP 2: Handle missing KC(Default)\n",
            "============================================================\n",
            "Missing KC(Default): 202,669 (25.03%)\n",
            "Filled with 'UNKNOWN_KC' token\n",
            "\n",
            "============================================================\n",
            "STEP 3: Create canonical identifiers\n",
            "============================================================\n",
            "Unique students: 574\n",
            "Unique questions: 1,084\n",
            "Unique steps: 210,710\n",
            "Unique KCs (including UNKNOWN): 437\n",
            "\n",
            "============================================================\n",
            "STEP 4: Parse timestamps and create temporal ordering\n",
            "============================================================\n",
            "Rows with missing timestamp after fallback: 0\n",
            "Final dataset size: 809,694 rows\n",
            "\n",
            "============================================================\n",
            "STEP 5: Process behavioral features\n",
            "============================================================\n",
            "Median duration: 11.00 sec\n",
            "Log duration range: [0.00, 7.90]\n",
            "\n",
            "============================================================\n",
            "STEP 6: Final dataset summary\n",
            "============================================================\n",
            "Total interactions: 809,694\n",
            "Unique students: 574\n",
            "Unique questions: 1,084\n",
            "Unique steps: 210,710\n",
            "Unique KCs: 437\n",
            "  - Real KCs: 607,025 interactions\n",
            "  - UNKNOWN_KC: 202,669 interactions\n",
            "\n",
            "Target distribution:\n",
            "correct\n",
            "1    0.7665\n",
            "0    0.2335\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "============================================================\n",
            "STEP 7: Verify temporal ordering\n",
            "============================================================\n",
            "Sample student '02ZjVTxC34' first 5 interactions:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   time_idx           timestamp question_id  \\\n",
              "0         0 2005-09-06 13:00:23  LDEMO_WKST   \n",
              "1         1 2005-09-06 13:00:44  LDEMO_WKST   \n",
              "2         2 2005-09-06 13:01:12  LDEMO_WKST   \n",
              "3         3 2005-09-06 13:01:46  LDEMO_WKST   \n",
              "4         4 2005-09-06 13:02:27  LDEMO_WKST   \n",
              "\n",
              "                                        kc_id  correct  \n",
              "0                                  UNKNOWN_KC        1  \n",
              "1                           Identifying units        1  \n",
              "2                                  UNKNOWN_KC        1  \n",
              "3                           Identifying units        1  \n",
              "4  Entering a given~~Convert unit, multiplier        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-98471ee0-6ecd-4f9b-bacf-4f6e96115760\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time_idx</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>question_id</th>\n",
              "      <th>kc_id</th>\n",
              "      <th>correct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2005-09-06 13:00:23</td>\n",
              "      <td>LDEMO_WKST</td>\n",
              "      <td>UNKNOWN_KC</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2005-09-06 13:00:44</td>\n",
              "      <td>LDEMO_WKST</td>\n",
              "      <td>Identifying units</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2005-09-06 13:01:12</td>\n",
              "      <td>LDEMO_WKST</td>\n",
              "      <td>UNKNOWN_KC</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2005-09-06 13:01:46</td>\n",
              "      <td>LDEMO_WKST</td>\n",
              "      <td>Identifying units</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2005-09-06 13:02:27</td>\n",
              "      <td>LDEMO_WKST</td>\n",
              "      <td>Entering a given~~Convert unit, multiplier</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98471ee0-6ecd-4f9b-bacf-4f6e96115760')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-98471ee0-6ecd-4f9b-bacf-4f6e96115760 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-98471ee0-6ecd-4f9b-bacf-4f6e96115760');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_17ac0d5c-7e78-4950-81a1-8e936a17b38c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('sample_seq')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_17ac0d5c-7e78-4950-81a1-8e936a17b38c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('sample_seq');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "sample_seq",
              "summary": "{\n  \"name\": \"sample_seq\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"time_idx\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2005-09-06 13:00:23\",\n        \"max\": \"2005-09-06 13:02:27\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2005-09-06 13:00:44\",\n          \"2005-09-06 13:02:27\",\n          \"2005-09-06 13:01:12\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"LDEMO_WKST\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"kc_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"UNKNOWN_KC\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"correct\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Cell 3 (Corrected): Data Cleaning - Keep Missing KC as UNKNOWN\n",
        "# =============================================================================\n",
        "\n",
        "# Start with a copy\n",
        "df = df_raw.copy()\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"STEP 1: Drop rows with missing critical fields (NOT KC)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Critical fields: student, step, target (NOT KC - we'll handle separately)\n",
        "critical_cols = ['Anon Student Id', 'Problem Name', 'Step Name', 'Correct First Attempt']\n",
        "before_drop = len(df)\n",
        "df = df.dropna(subset=critical_cols)\n",
        "after_drop = len(df)\n",
        "print(f\"Dropped {before_drop - after_drop:,} rows ({(before_drop - after_drop)/before_drop*100:.2f}%)\")\n",
        "print(f\"Remaining: {after_drop:,} rows\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 2: Handle missing KC(Default)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "kc_missing_before = df['KC(Default)'].isnull().sum()\n",
        "print(f\"Missing KC(Default): {kc_missing_before:,} ({kc_missing_before/len(df)*100:.2f}%)\")\n",
        "\n",
        "# Fill missing KC with special token\n",
        "df['KC(Default)'] = df['KC(Default)'].fillna('UNKNOWN_KC')\n",
        "print(f\"Filled with 'UNKNOWN_KC' token\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 3: Create canonical identifiers\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Student ID\n",
        "df['student_id'] = df['Anon Student Id'].astype(str).str.strip()\n",
        "\n",
        "# Question ID (Problem Name)\n",
        "df['question_id'] = df['Problem Name'].astype(str).str.strip()\n",
        "\n",
        "# Step ID (Problem Name + Step Name)\n",
        "df['step_id'] = df['Problem Name'].astype(str).str.strip() + \"||\" + df['Step Name'].astype(str).str.strip()\n",
        "\n",
        "# KC ID (KC(Default) as composite string)\n",
        "df['kc_id'] = df['KC(Default)'].astype(str).str.strip()\n",
        "\n",
        "# Target\n",
        "df['correct'] = df['Correct First Attempt'].astype(int)\n",
        "\n",
        "print(f\"Unique students: {df['student_id'].nunique():,}\")\n",
        "print(f\"Unique questions: {df['question_id'].nunique():,}\")\n",
        "print(f\"Unique steps: {df['step_id'].nunique():,}\")\n",
        "print(f\"Unique KCs (including UNKNOWN): {df['kc_id'].nunique():,}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 4: Parse timestamps and create temporal ordering\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Parse First Transaction Time (primary timestamp)\n",
        "df['timestamp'] = pd.to_datetime(df['First Transaction Time'], errors='coerce')\n",
        "\n",
        "# Fallback to Step Start Time\n",
        "mask_missing_ts = df['timestamp'].isnull()\n",
        "df.loc[mask_missing_ts, 'timestamp'] = pd.to_datetime(\n",
        "    df.loc[mask_missing_ts, 'Step Start Time'], errors='coerce'\n",
        ")\n",
        "\n",
        "# Check remaining missing timestamps\n",
        "ts_missing = df['timestamp'].isnull().sum()\n",
        "print(f\"Rows with missing timestamp after fallback: {ts_missing}\")\n",
        "\n",
        "if ts_missing > 0:\n",
        "    # Drop only these (should be minimal)\n",
        "    df = df.dropna(subset=['timestamp'])\n",
        "    print(f\"Dropped {ts_missing} rows with no valid timestamp\")\n",
        "\n",
        "# Sort by student and timestamp\n",
        "df = df.sort_values(['student_id', 'timestamp']).reset_index(drop=True)\n",
        "\n",
        "# Create time index within each student\n",
        "df['time_idx'] = df.groupby('student_id').cumcount()\n",
        "\n",
        "print(f\"Final dataset size: {len(df):,} rows\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 5: Process behavioral features\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Fill missing durations with median\n",
        "duration_col = 'Step Duration (sec)'\n",
        "median_duration = df[duration_col].median()\n",
        "df[duration_col] = df[duration_col].fillna(median_duration)\n",
        "\n",
        "# Log transform duration\n",
        "df['log_duration'] = np.log1p(df[duration_col].clip(lower=0))\n",
        "\n",
        "# Clip extreme values\n",
        "df['Incorrects'] = df['Incorrects'].clip(upper=10)\n",
        "df['Hints'] = df['Hints'].clip(upper=10)\n",
        "\n",
        "print(f\"Median duration: {median_duration:.2f} sec\")\n",
        "print(f\"Log duration range: [{df['log_duration'].min():.2f}, {df['log_duration'].max():.2f}]\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 6: Final dataset summary\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"Total interactions: {len(df):,}\")\n",
        "print(f\"Unique students: {df['student_id'].nunique():,}\")\n",
        "print(f\"Unique questions: {df['question_id'].nunique():,}\")\n",
        "print(f\"Unique steps: {df['step_id'].nunique():,}\")\n",
        "print(f\"Unique KCs: {df['kc_id'].nunique():,}\")\n",
        "print(f\"  - Real KCs: {(df['kc_id'] != 'UNKNOWN_KC').sum():,} interactions\")\n",
        "print(f\"  - UNKNOWN_KC: {(df['kc_id'] == 'UNKNOWN_KC').sum():,} interactions\")\n",
        "\n",
        "print(f\"\\nTarget distribution:\")\n",
        "print(df['correct'].value_counts(normalize=True).round(4))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 7: Verify temporal ordering\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "sample_student = df['student_id'].iloc[0]\n",
        "sample_seq = df[df['student_id'] == sample_student][['time_idx', 'timestamp', 'question_id', 'kc_id', 'correct']].head(5)\n",
        "print(f\"Sample student '{sample_student}' first 5 interactions:\")\n",
        "display(sample_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "LvLbzcxFo-pm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5740695e-26cc-42bd-8c79-58361ba293e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "STEP 1: SEPARATE TEST STUDENTS (HELD OUT ENTIRELY)\n",
            "============================================================\n",
            "Total students: 574\n",
            "\n",
            "TEST set (held out):\n",
            "  Students: 87 (15.2%)\n",
            "  Interactions: 118,261\n",
            "\n",
            "Non-test (enters K-Fold CV):\n",
            "  Students: 487 (84.8%)\n",
            "  Interactions: 691,433\n",
            "\n",
            "============================================================\n",
            "STEP 2: DEFINE 5-FOLD STUDENT-LEVEL SPLITS\n",
            "============================================================\n",
            "\n",
            "Fold 1:\n",
            "  TRAIN: 389 students\n",
            "  VAL:   98 students\n",
            "\n",
            "Fold 2:\n",
            "  TRAIN: 389 students\n",
            "  VAL:   98 students\n",
            "\n",
            "Fold 3:\n",
            "  TRAIN: 390 students\n",
            "  VAL:   97 students\n",
            "\n",
            "Fold 4:\n",
            "  TRAIN: 390 students\n",
            "  VAL:   97 students\n",
            "\n",
            "Fold 5:\n",
            "  TRAIN: 390 students\n",
            "  VAL:   97 students\n",
            "\n",
            "✓ All folds verified: no student overlap, no test leakage\n",
            "✓ TEST set (87 students) completely isolated\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Cell 4: Separate TEST Set + 5-Fold Student-Level CV Setup\n",
        "# =============================================================================\n",
        "\n",
        "import time\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from collections import defaultdict\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"STEP 1: SEPARATE TEST STUDENTS (HELD OUT ENTIRELY)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "all_students = df['student_id'].unique()\n",
        "n_students = len(all_students)\n",
        "print(f\"Total students: {n_students}\")\n",
        "\n",
        "# Hold out 15% of students as TEST - NEVER touched during CV\n",
        "non_test_students, test_students = train_test_split(\n",
        "    all_students,\n",
        "    test_size=config.TEST_STUDENT_RATIO,\n",
        "    random_state=config.SEED\n",
        ")\n",
        "\n",
        "df_test_final = df[df['student_id'].isin(test_students)].copy()\n",
        "df_non_test = df[df['student_id'].isin(non_test_students)].copy()\n",
        "\n",
        "print(f\"\\nTEST set (held out):\")\n",
        "print(f\"  Students: {len(test_students)} ({len(test_students)/n_students*100:.1f}%)\")\n",
        "print(f\"  Interactions: {len(df_test_final):,}\")\n",
        "\n",
        "print(f\"\\nNon-test (enters K-Fold CV):\")\n",
        "print(f\"  Students: {len(non_test_students)} ({len(non_test_students)/n_students*100:.1f}%)\")\n",
        "print(f\"  Interactions: {len(df_non_test):,}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 2: DEFINE 5-FOLD STUDENT-LEVEL SPLITS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=config.SEED)\n",
        "\n",
        "fold_assignments = {}\n",
        "for fold_idx, (train_indices, val_indices) in enumerate(kf.split(non_test_students)):\n",
        "    train_studs = non_test_students[train_indices]\n",
        "    val_studs = non_test_students[val_indices]\n",
        "    fold_assignments[fold_idx] = {\n",
        "        'train_students': train_studs,\n",
        "        'val_students': val_studs\n",
        "    }\n",
        "    print(f\"\\nFold {fold_idx+1}:\")\n",
        "    print(f\"  TRAIN: {len(train_studs)} students\")\n",
        "    print(f\"  VAL:   {len(val_studs)} students\")\n",
        "\n",
        "    # Verify no overlap\n",
        "    overlap = set(train_studs) & set(val_studs)\n",
        "    assert len(overlap) == 0, f\"LEAK in fold {fold_idx+1}!\"\n",
        "\n",
        "    # Verify no test leakage\n",
        "    test_leak = set(train_studs) & set(test_students)\n",
        "    assert len(test_leak) == 0, f\"TEST LEAK in fold {fold_idx+1}!\"\n",
        "\n",
        "print(\"\\n✓ All folds verified: no student overlap, no test leakage\")\n",
        "print(f\"✓ TEST set ({len(test_students)} students) completely isolated\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "id": "fiDbwzUto-pm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3020bdc6-c43e-4624-c47b-0a1926f0af84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "✓ ALL PIPELINE FUNCTIONS DEFINED (M3 VERSION)\n",
            "============================================================\n",
            "  - build_entity_mappings()\n",
            "  - build_graph()\n",
            "  - compute_node_features()\n",
            "  - GraphKTMinimal (RGCN + Dual Propagation)\n",
            "  - MasteryMessagePassing (mastery-weighted edges)\n",
            "  - KTDatasetPure\n",
            "  - train_epoch() / evaluate()\n",
            "  - run_single_fold()\n",
            "============================================================\n",
            "Ready for 5-Fold Cross-Validation! 🚀\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Cell 5: Complete Pipeline Functions (Reusable Per Fold) — M3\n",
        "# =============================================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.nn import GCNConv, RGCNConv, MessagePassing\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "from collections import defaultdict\n",
        "import time\n",
        "\n",
        "NUM_FEATURES = 5\n",
        "\n",
        "# ============================================================\n",
        "# FUNCTION 1: Build Entity Mappings (UNCHANGED)\n",
        "# ============================================================\n",
        "def build_entity_mappings(df_train):\n",
        "    train_students = sorted(df_train['student_id'].unique())\n",
        "    train_questions = sorted(df_train['question_id'].unique())\n",
        "    train_steps = sorted(df_train['step_id'].unique())\n",
        "    train_kcs = sorted(df_train['kc_id'].unique())\n",
        "\n",
        "    stu2idx = {s: i for i, s in enumerate(train_students)}\n",
        "    q2idx = {q: i for i, q in enumerate(train_questions)}\n",
        "    t2idx = {t: i for i, t in enumerate(train_steps)}\n",
        "    c2idx = {c: i for i, c in enumerate(train_kcs)}\n",
        "\n",
        "    unk_indices = {\n",
        "        'student': len(train_students),\n",
        "        'question': len(train_questions),\n",
        "        'step': len(train_steps),\n",
        "        'kc': len(train_kcs)\n",
        "    }\n",
        "\n",
        "    entity_counts = {\n",
        "        'num_students': len(train_students) + 1,\n",
        "        'num_questions': len(train_questions) + 1,\n",
        "        'num_steps': len(train_steps) + 1,\n",
        "        'num_kcs': len(train_kcs) + 1,\n",
        "    }\n",
        "\n",
        "    mappings = {\n",
        "        'stu2idx': stu2idx, 'q2idx': q2idx,\n",
        "        't2idx': t2idx, 'c2idx': c2idx\n",
        "    }\n",
        "\n",
        "    return mappings, entity_counts, unk_indices\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# FUNCTION 2: Build Heterogeneous Graph (UNCHANGED)\n",
        "# ============================================================\n",
        "def build_graph(df_train, mappings, entity_counts, unk_indices):\n",
        "    stu2idx = mappings['stu2idx']\n",
        "    q2idx = mappings['q2idx']\n",
        "    t2idx = mappings['t2idx']\n",
        "    c2idx = mappings['c2idx']\n",
        "\n",
        "    data = HeteroData()\n",
        "\n",
        "    data['student'].num_nodes = entity_counts['num_students']\n",
        "    data['question'].num_nodes = entity_counts['num_questions']\n",
        "    data['step'].num_nodes = entity_counts['num_steps']\n",
        "    data['kc'].num_nodes = entity_counts['num_kcs']\n",
        "\n",
        "    qt_pairs = df_train[['question_id', 'step_id']].drop_duplicates()\n",
        "    q_idx_list = [q2idx[r['question_id']] for _, r in qt_pairs.iterrows()]\n",
        "    t_idx_list = [t2idx[r['step_id']] for _, r in qt_pairs.iterrows()]\n",
        "\n",
        "    data['question', 'contains', 'step'].edge_index = torch.tensor([q_idx_list, t_idx_list], dtype=torch.long)\n",
        "    data['step', 'belongs_to', 'question'].edge_index = torch.tensor([t_idx_list, q_idx_list], dtype=torch.long)\n",
        "\n",
        "    tc_pairs = df_train[['step_id', 'kc_id']].drop_duplicates()\n",
        "    t_idx_list2 = [t2idx[r['step_id']] for _, r in tc_pairs.iterrows()]\n",
        "    c_idx_list = [c2idx[r['kc_id']] for _, r in tc_pairs.iterrows()]\n",
        "\n",
        "    data['step', 'requires', 'kc'].edge_index = torch.tensor([t_idx_list2, c_idx_list], dtype=torch.long)\n",
        "    data['kc', 'required_by', 'step'].edge_index = torch.tensor([c_idx_list, t_idx_list2], dtype=torch.long)\n",
        "\n",
        "    sq_pairs = df_train[['student_id', 'question_id']].drop_duplicates()\n",
        "    s_idx_list = [stu2idx[r['student_id']] for _, r in sq_pairs.iterrows()]\n",
        "    q_idx_list2 = [q2idx[r['question_id']] for _, r in sq_pairs.iterrows()]\n",
        "\n",
        "    data['student', 'attempted', 'question'].edge_index = torch.tensor([s_idx_list, q_idx_list2], dtype=torch.long)\n",
        "    data['question', 'attempted_by', 'student'].edge_index = torch.tensor([q_idx_list2, s_idx_list], dtype=torch.long)\n",
        "\n",
        "    total_edges = sum(\n",
        "        data[et].edge_index.shape[1]\n",
        "        for et in data.edge_types\n",
        "    )\n",
        "\n",
        "    return data, total_edges\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# FUNCTION 3: Compute Node Features (UNCHANGED)\n",
        "# ============================================================\n",
        "def compute_node_features(df_train, mappings, entity_counts, unk_indices):\n",
        "    def compute_features_for_type(df, entity_col):\n",
        "        grouped = df.groupby(entity_col).agg({\n",
        "            'correct': ['count', 'mean'],\n",
        "            'log_duration': 'mean',\n",
        "            'Hints': 'mean',\n",
        "            'Incorrects': 'mean'\n",
        "        })\n",
        "        grouped.columns = ['freq', 'correct_rate', 'avg_log_dur', 'avg_hints', 'avg_incorrects']\n",
        "        grouped = grouped.reset_index()\n",
        "        grouped['difficulty'] = 1 - grouped['correct_rate']\n",
        "        grouped['log_freq'] = np.log1p(grouped['freq'])\n",
        "\n",
        "        features = {}\n",
        "        feat_cols = ['log_freq', 'difficulty', 'avg_log_dur', 'avg_hints', 'avg_incorrects']\n",
        "        for _, row in grouped.iterrows():\n",
        "            features[row[entity_col]] = row[feat_cols].values.astype(np.float32)\n",
        "        return features\n",
        "\n",
        "    def to_tensor(features_dict, idx_map, num_with_unk, unk_idx):\n",
        "        tensor = torch.zeros(num_with_unk, NUM_FEATURES, dtype=torch.float32)\n",
        "        all_feats = []\n",
        "        for entity_id, idx in idx_map.items():\n",
        "            if entity_id in features_dict:\n",
        "                tensor[idx] = torch.tensor(features_dict[entity_id])\n",
        "                all_feats.append(features_dict[entity_id])\n",
        "        if all_feats:\n",
        "            tensor[unk_idx] = torch.tensor(np.mean(all_feats, axis=0))\n",
        "        return tensor\n",
        "\n",
        "    def normalize(tensor):\n",
        "        mean = tensor.mean(dim=0, keepdim=True)\n",
        "        std = tensor.std(dim=0, keepdim=True) + 1e-8\n",
        "        return (tensor - mean) / std\n",
        "\n",
        "    stu_feats = compute_features_for_type(df_train, 'student_id')\n",
        "    q_feats = compute_features_for_type(df_train, 'question_id')\n",
        "    t_feats = compute_features_for_type(df_train, 'step_id')\n",
        "    c_feats = compute_features_for_type(df_train, 'kc_id')\n",
        "\n",
        "    feat_tensors = {\n",
        "        'student': normalize(to_tensor(stu_feats, mappings['stu2idx'], entity_counts['num_students'], unk_indices['student'])),\n",
        "        'question': normalize(to_tensor(q_feats, mappings['q2idx'], entity_counts['num_questions'], unk_indices['question'])),\n",
        "        'step': normalize(to_tensor(t_feats, mappings['t2idx'], entity_counts['num_steps'], unk_indices['step'])),\n",
        "        'kc': normalize(to_tensor(c_feats, mappings['c2idx'], entity_counts['num_kcs'], unk_indices['kc'])),\n",
        "    }\n",
        "\n",
        "    return feat_tensors\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# FUNCTION 4: Model Components\n",
        "# ============================================================\n",
        "\n",
        "class NodeEncoder(nn.Module):\n",
        "    \"\"\"Encode node features to embedding space\"\"\"\n",
        "    def __init__(self, input_dim, embed_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, embed_dim),\n",
        "            nn.LayerNorm(embed_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(embed_dim, embed_dim),\n",
        "            nn.LayerNorm(embed_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.encoder(x)\n",
        "\n",
        "\n",
        "class MasteryMessagePassing(MessagePassing):\n",
        "    \"\"\"\n",
        "    Message passing layer with mastery-weighted edges\n",
        "    Used for Student ↔ KC knowledge propagation\n",
        "    \"\"\"\n",
        "    def __init__(self, embed_dim, gating='identity'):\n",
        "        super().__init__(aggr='mean')\n",
        "        self.lin = nn.Linear(embed_dim, embed_dim)\n",
        "        self.gating = gating\n",
        "\n",
        "    def forward(self, h_nodes, edge_index, mastery_weights):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            h_nodes: [num_nodes, embed_dim] - all nodes (students + KCs)\n",
        "            edge_index: [2, num_edges] - S↔C edges\n",
        "            mastery_weights: [num_edges] - mastery weights ∈ [0,1]\n",
        "\n",
        "        Returns:\n",
        "            h_out: [num_nodes, embed_dim] - updated embeddings\n",
        "        \"\"\"\n",
        "        out = self.propagate(edge_index, x=h_nodes, mastery=mastery_weights)\n",
        "        return out\n",
        "\n",
        "    def message(self, x_j, mastery):\n",
        "        \"\"\"\n",
        "        x_j: neighbor features\n",
        "        mastery: edge weights\n",
        "        \"\"\"\n",
        "        return mastery.unsqueeze(-1) * self.lin(x_j)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# MODEL: GraphKT M3 (RGCN + Dual Propagation)\n",
        "# ============================================================\n",
        "\n",
        "class GraphKTMinimal(nn.Module):\n",
        "    \"\"\"\n",
        "    GraphKT M3 with:\n",
        "    - Block A: Structural Propagation (Q,T,C via RGCN)\n",
        "    - Block B: Knowledge Propagation (S↔C weighted by mastery)\n",
        "    - NO event features (prevents leakage)\n",
        "    \"\"\"\n",
        "\n",
        "    NUM_RELATIONS_STRUCT = 4  # Q↔T, T↔C (4 relation types)\n",
        "\n",
        "    def __init__(self, num_students, num_questions, num_steps, num_kcs,\n",
        "                 feature_dim=5, embed_dim=32, hidden_dim=64,\n",
        "                 num_gnn_layers=2, dropout=0.2,\n",
        "                 mastery_init=0.5, mastery_gating='identity'):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_students = num_students\n",
        "        self.num_questions = num_questions\n",
        "        self.num_steps = num_steps\n",
        "        self.num_kcs = num_kcs\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "        # === Node Encoders (5D → embed_dim) ===\n",
        "        self.student_encoder = NodeEncoder(feature_dim, embed_dim, dropout)\n",
        "        self.question_encoder = NodeEncoder(feature_dim, embed_dim, dropout)\n",
        "        self.step_encoder = NodeEncoder(feature_dim, embed_dim, dropout)\n",
        "        self.kc_encoder = NodeEncoder(feature_dim, embed_dim, dropout)\n",
        "\n",
        "        # === BLOCK A: Structural Propagation (Q,T,C) ===\n",
        "        self.structural_rgcn = nn.ModuleList([\n",
        "            RGCNConv(\n",
        "                embed_dim, embed_dim,\n",
        "                num_relations=self.NUM_RELATIONS_STRUCT,\n",
        "                num_bases=2\n",
        "            )\n",
        "            for _ in range(num_gnn_layers)\n",
        "        ])\n",
        "        self.struct_norms = nn.ModuleList([\n",
        "            nn.LayerNorm(embed_dim) for _ in range(num_gnn_layers)\n",
        "        ])\n",
        "        self.struct_dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # === BLOCK B: Knowledge Propagation (S↔C with mastery) ===\n",
        "        self.knowledge_conv = MasteryMessagePassing(\n",
        "            embed_dim,\n",
        "            gating=mastery_gating\n",
        "        )\n",
        "\n",
        "        # === Fusion Layers ===\n",
        "        # Student: [h_s_base, h_s_knowledge] → embed_dim\n",
        "        self.fusion_student = nn.Sequential(\n",
        "            nn.Linear(embed_dim * 2, embed_dim),\n",
        "            nn.LayerNorm(embed_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        # KC: [h_c_structural, h_c_knowledge] → embed_dim\n",
        "        self.fusion_kc = nn.Sequential(\n",
        "            nn.Linear(embed_dim * 2, embed_dim),\n",
        "            nn.LayerNorm(embed_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        # === Prediction Head ===\n",
        "        pred_input_dim = embed_dim * 3  # [h_s*, h_t_struct, h_c*]\n",
        "        self.prediction_head = nn.Sequential(\n",
        "            nn.Linear(pred_input_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim // 2, 1)\n",
        "        )\n",
        "\n",
        "        # === Mastery Matrix ===\n",
        "        self.mastery_init = mastery_init\n",
        "        self.mastery_gating = mastery_gating\n",
        "        self.register_buffer('mastery_matrix', None)\n",
        "\n",
        "        # Gating parameter for sigmoid\n",
        "        if mastery_gating == 'sigmoid':\n",
        "            self.gating_alpha = nn.Parameter(torch.tensor(2.0))\n",
        "\n",
        "        # Cache\n",
        "        self._cached_struct_edges = None\n",
        "        self._cached_struct_types = None\n",
        "\n",
        "    def init_mastery_matrix(self, device):\n",
        "        \"\"\"Initialize mastery matrix (call once per fold)\"\"\"\n",
        "        self.mastery_matrix = torch.full(\n",
        "            (self.num_students, self.num_kcs),\n",
        "            self.mastery_init,\n",
        "            dtype=torch.float32,\n",
        "            device=device\n",
        "        )\n",
        "        print(f\"  ✓ Mastery matrix initialized: [{self.num_students}, {self.num_kcs}] with value={self.mastery_init}\")\n",
        "\n",
        "    def _build_structural_edges(self, hetero_data, device):\n",
        "        \"\"\"Build edge_index and edge_type for Q,T,C (BLOCK A)\"\"\"\n",
        "        if self._cached_struct_edges is not None:\n",
        "            return self._cached_struct_edges, self._cached_struct_types\n",
        "\n",
        "        all_edges = []\n",
        "        all_types = []\n",
        "\n",
        "        # ✓ LOCAL offsets for H_struct = [Q, T, C]\n",
        "        question_offset_local = 0\n",
        "        step_offset_local = self.num_questions\n",
        "        kc_offset_local = self.num_questions + self.num_steps\n",
        "\n",
        "        # Relation 0: Q → T (contains)\n",
        "        q_t = hetero_data['question', 'contains', 'step'].edge_index.clone()\n",
        "        q_t[0] += question_offset_local\n",
        "        q_t[1] += step_offset_local\n",
        "        all_edges.append(q_t)\n",
        "        all_types.append(torch.zeros(q_t.size(1), dtype=torch.long))\n",
        "\n",
        "        # Relation 1: T → Q (belongs_to)\n",
        "        t_q = hetero_data['step', 'belongs_to', 'question'].edge_index.clone()\n",
        "        t_q[0] += step_offset_local\n",
        "        t_q[1] += question_offset_local\n",
        "        all_edges.append(t_q)\n",
        "        all_types.append(torch.ones(t_q.size(1), dtype=torch.long))\n",
        "\n",
        "        # Relation 2: T → C (requires)\n",
        "        t_c = hetero_data['step', 'requires', 'kc'].edge_index.clone()\n",
        "        t_c[0] += step_offset_local\n",
        "        t_c[1] += kc_offset_local\n",
        "        all_edges.append(t_c)\n",
        "        all_types.append(torch.full((t_c.size(1),), 2, dtype=torch.long))\n",
        "\n",
        "        # Relation 3: C → T (required_by)\n",
        "        c_t = hetero_data['kc', 'required_by', 'step'].edge_index.clone()\n",
        "        c_t[0] += kc_offset_local\n",
        "        c_t[1] += step_offset_local\n",
        "        all_edges.append(c_t)\n",
        "        all_types.append(torch.full((c_t.size(1),), 3, dtype=torch.long))\n",
        "\n",
        "        self._cached_struct_edges = torch.cat(all_edges, dim=1).to(device)\n",
        "        self._cached_struct_types = torch.cat(all_types, dim=0).to(device)\n",
        "\n",
        "        return self._cached_struct_edges, self._cached_struct_types\n",
        "\n",
        "    def _build_sc_edges_batch(self, student_idx, kc_idx, device):\n",
        "        \"\"\"\n",
        "        Build S↔C edge_index for batch with mastery weights\n",
        "\n",
        "        Returns:\n",
        "            edge_index: [2, 2*batch_size]\n",
        "            mastery_weights: [2*batch_size]\n",
        "        \"\"\"\n",
        "        # ✓ LOCAL offset for H_know = [S, C]\n",
        "        kc_offset_local = self.num_students\n",
        "\n",
        "        # S → C edges\n",
        "        edge_index_sc = torch.stack([student_idx, kc_idx + kc_offset_local], dim=0)\n",
        "        # C → S edges (reverse)\n",
        "        edge_index_cs = torch.stack([kc_idx + kc_offset_local, student_idx], dim=0)\n",
        "\n",
        "        # Concatenate\n",
        "        edge_index = torch.cat([edge_index_sc, edge_index_cs], dim=1).to(device)\n",
        "\n",
        "        # Lookup mastery weights (VECTORIZED)\n",
        "        mastery_weights_sc = self.mastery_matrix[student_idx, kc_idx]\n",
        "        mastery_weights_cs = mastery_weights_sc.clone()\n",
        "\n",
        "        mastery_weights = torch.cat([mastery_weights_sc, mastery_weights_cs])\n",
        "\n",
        "        # Apply gating function\n",
        "        if self.mastery_gating == 'sigmoid':\n",
        "            mastery_weights = torch.sigmoid(\n",
        "                self.gating_alpha * (mastery_weights - 0.5)\n",
        "            )\n",
        "\n",
        "        return edge_index, mastery_weights\n",
        "\n",
        "    def forward(self, hetero_data, student_idx, step_idx, kc_idx, device):\n",
        "        \"\"\"\n",
        "        Forward pass with Structural + Knowledge propagation\n",
        "        NO event features to prevent leakage\n",
        "        \"\"\"\n",
        "        # === 1. Encode Nodes ===\n",
        "        h_s_base = self.student_encoder(hetero_data['student'].x.to(device))\n",
        "        h_q = self.question_encoder(hetero_data['question'].x.to(device))\n",
        "        h_t = self.step_encoder(hetero_data['step'].x.to(device))\n",
        "        h_c_base = self.kc_encoder(hetero_data['kc'].x.to(device))\n",
        "\n",
        "        # === 2. BLOCK A: Structural Propagation (Q,T,C) ===\n",
        "        H_struct = torch.cat([h_q, h_t, h_c_base], dim=0)\n",
        "        edge_index_struct, edge_type_struct = self._build_structural_edges(\n",
        "            hetero_data, device\n",
        "        )\n",
        "\n",
        "        for layer, norm in zip(self.structural_rgcn, self.struct_norms):\n",
        "            H_new = layer(H_struct, edge_index_struct, edge_type_struct)\n",
        "            H_new = norm(H_new)\n",
        "            H_new = F.relu(H_new)\n",
        "            H_new = self.struct_dropout(H_new)\n",
        "            H_struct = H_struct + H_new  # Residual connection\n",
        "\n",
        "        # Extract h_t^struct, h_c^struct\n",
        "        num_questions = h_q.size(0)\n",
        "        num_steps = h_t.size(0)\n",
        "        h_t_struct = H_struct[num_questions : num_questions + num_steps]\n",
        "        h_c_struct = H_struct[num_questions + num_steps :]\n",
        "\n",
        "        # === 3. BLOCK B: Knowledge Propagation (S↔C with mastery) ===\n",
        "        edge_index_sc, mastery_weights = self._build_sc_edges_batch(\n",
        "            student_idx, kc_idx, device\n",
        "        )\n",
        "\n",
        "        # Combine S + C nodes\n",
        "        H_know = torch.cat([h_s_base, h_c_base], dim=0)\n",
        "\n",
        "        # Message passing with mastery weighting\n",
        "        H_know = self.knowledge_conv(H_know, edge_index_sc, mastery_weights)\n",
        "\n",
        "        # Split back\n",
        "        h_s_know = H_know[:self.num_students]\n",
        "        h_c_know = H_know[self.num_students:]\n",
        "\n",
        "        # === 4. Fusion ===\n",
        "        # Student: [h_s_base, h_s_knowledge]\n",
        "        h_s_batch = h_s_base[student_idx]\n",
        "        h_s_know_batch = h_s_know[student_idx]\n",
        "        h_s_fused = self.fusion_student(\n",
        "            torch.cat([h_s_batch, h_s_know_batch], dim=-1)\n",
        "        )\n",
        "\n",
        "        # Step: structural only\n",
        "        h_t_batch = h_t_struct[step_idx]\n",
        "\n",
        "        # KC: [h_c_structural, h_c_knowledge]\n",
        "        h_c_struct_batch = h_c_struct[kc_idx]\n",
        "        h_c_know_batch = h_c_know[kc_idx]\n",
        "        h_c_fused = self.fusion_kc(\n",
        "            torch.cat([h_c_struct_batch, h_c_know_batch], dim=-1)\n",
        "        )\n",
        "\n",
        "        # === 5. Prediction ===\n",
        "        combined = torch.cat([h_s_fused, h_t_batch, h_c_fused], dim=-1)\n",
        "        logits = self.prediction_head(combined).squeeze(-1)\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def update_mastery_online(self, student_idx, kc_idx, y_true, lambda_ema):\n",
        "        \"\"\"\n",
        "        Update mastery AFTER observing outcome (prevents leakage)\n",
        "\n",
        "        Args:\n",
        "            student_idx: [batch] student indices\n",
        "            kc_idx: [batch] KC indices\n",
        "            y_true: [batch] outcomes (0 or 1)\n",
        "            lambda_ema: learning rate for EMA update\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            # EMA update: M ← (1-λ)M + λy\n",
        "            old_mastery = self.mastery_matrix[student_idx, kc_idx]\n",
        "            new_mastery = (1 - lambda_ema) * old_mastery + lambda_ema * y_true\n",
        "            self.mastery_matrix[student_idx, kc_idx] = new_mastery\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# FUNCTION 5: Dataset\n",
        "# ============================================================\n",
        "\n",
        "class KTDatasetPure(Dataset):\n",
        "    \"\"\"Dataset for Knowledge Tracing\"\"\"\n",
        "    def __init__(self, df, stu2idx, t2idx, c2idx,\n",
        "                 unk_student_idx, unk_step_idx, unk_kc_idx):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.stu2idx = stu2idx\n",
        "        self.t2idx = t2idx\n",
        "        self.c2idx = c2idx\n",
        "        self.unk_student_idx = unk_student_idx\n",
        "        self.unk_step_idx = unk_step_idx\n",
        "        self.unk_kc_idx = unk_kc_idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        student_idx = self.stu2idx.get(row['student_id'], self.unk_student_idx)\n",
        "        step_idx = self.t2idx.get(row['step_id'], self.unk_step_idx)\n",
        "        kc_idx = self.c2idx.get(row['kc_id'], self.unk_kc_idx)\n",
        "        label = torch.tensor(row['correct'], dtype=torch.float32)\n",
        "        return student_idx, step_idx, kc_idx, label\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# FUNCTION 6: Training & Evaluation\n",
        "# ============================================================\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stopping with model state saving\"\"\"\n",
        "    def __init__(self, patience=10, min_delta=0.001):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.best_state = None\n",
        "\n",
        "    def __call__(self, score, model):\n",
        "        if self.best_score is None or score > self.best_score + self.min_delta:\n",
        "            self.best_score = score\n",
        "            self.best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "\n",
        "    def load_best(self, model):\n",
        "        if self.best_state:\n",
        "            model.load_state_dict(self.best_state)\n",
        "\n",
        "\n",
        "def train_epoch(model, loader, optimizer, criterion, hetero_data, device,\n",
        "                config, grad_clip=1.0):\n",
        "    \"\"\"Train for one epoch with mastery update\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    for batch in loader:\n",
        "        student_idx, step_idx, kc_idx, labels = batch\n",
        "        student_idx = student_idx.to(device)\n",
        "        step_idx = step_idx.to(device)\n",
        "        kc_idx = kc_idx.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # 1. FORWARD (with current mastery - history up to t-1)\n",
        "        logits = model(hetero_data, student_idx, step_idx, kc_idx, device)\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        # 2. BACKWARD (update model weights)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        # 3. UPDATE MASTERY (AFTER backward, no gradient)\n",
        "        #    ⚠️ CRITICAL: This order prevents leakage\n",
        "        if hasattr(model, 'update_mastery_online'):\n",
        "            model.update_mastery_online(\n",
        "                student_idx, kc_idx, labels,\n",
        "                lambda_ema=config.LAMBDA_EMA\n",
        "            )\n",
        "\n",
        "        # Metrics\n",
        "        total_loss += loss.item() * len(labels)\n",
        "        all_preds.extend(torch.sigmoid(logits).detach().cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / len(loader.dataset)\n",
        "    auc = roc_auc_score(all_labels, all_preds) if len(set(all_labels)) > 1 else 0.5\n",
        "    acc = accuracy_score(all_labels, np.array(all_preds) > 0.5)\n",
        "\n",
        "    return avg_loss, auc, acc\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, criterion, hetero_data, device):\n",
        "    \"\"\"Evaluate without mastery update\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    for batch in loader:\n",
        "        student_idx, step_idx, kc_idx, labels = batch\n",
        "        student_idx = student_idx.to(device)\n",
        "        step_idx = step_idx.to(device)\n",
        "        kc_idx = kc_idx.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        logits = model(hetero_data, student_idx, step_idx, kc_idx, device)\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        total_loss += loss.item() * len(labels)\n",
        "        all_preds.extend(torch.sigmoid(logits).cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / len(loader.dataset)\n",
        "    auc = roc_auc_score(all_labels, all_preds) if len(set(all_labels)) > 1 else 0.5\n",
        "    acc = accuracy_score(all_labels, np.array(all_preds) > 0.5)\n",
        "\n",
        "    return avg_loss, auc, acc\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# FUNCTION 7: Full Single-Fold Pipeline\n",
        "# ============================================================\n",
        "\n",
        "def run_single_fold(df_train_fold, df_val_fold, config, fold_num=None, verbose=True):\n",
        "    \"\"\"Run complete training pipeline for one fold\"\"\"\n",
        "    device = config.DEVICE\n",
        "    prefix = f\"[Fold {fold_num}] \" if fold_num is not None else \"\"\n",
        "\n",
        "    # --- Step 1: Entity mappings ---\n",
        "    mappings, entity_counts, unk_indices = build_entity_mappings(df_train_fold)\n",
        "    if verbose:\n",
        "        print(f\"{prefix}Entities: S={entity_counts['num_students']}, \"\n",
        "              f\"Q={entity_counts['num_questions']}, \"\n",
        "              f\"T={entity_counts['num_steps']}, \"\n",
        "              f\"C={entity_counts['num_kcs']}\")\n",
        "\n",
        "    # --- Step 2: Build graph ---\n",
        "    hetero_data, total_edges = build_graph(df_train_fold, mappings, entity_counts, unk_indices)\n",
        "    if verbose:\n",
        "        print(f\"{prefix}Graph edges: {total_edges:,}\")\n",
        "\n",
        "    # --- Step 3: Node features ---\n",
        "    feat_tensors = compute_node_features(df_train_fold, mappings, entity_counts, unk_indices)\n",
        "    hetero_data['student'].x = feat_tensors['student']\n",
        "    hetero_data['question'].x = feat_tensors['question']\n",
        "    hetero_data['step'].x = feat_tensors['step']\n",
        "    hetero_data['kc'].x = feat_tensors['kc']\n",
        "\n",
        "    # --- Step 4: DataLoaders ---\n",
        "    train_dataset = KTDatasetPure(\n",
        "        df_train_fold, mappings['stu2idx'], mappings['t2idx'], mappings['c2idx'],\n",
        "        unk_indices['student'], unk_indices['step'], unk_indices['kc']\n",
        "    )\n",
        "    val_dataset = KTDatasetPure(\n",
        "        df_val_fold, mappings['stu2idx'], mappings['t2idx'], mappings['c2idx'],\n",
        "        unk_indices['student'], unk_indices['step'], unk_indices['kc']\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True,\n",
        "                              pin_memory=True, num_workers=0)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=512, shuffle=False,\n",
        "                            pin_memory=True, num_workers=0)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"{prefix}Train: {len(train_loader.dataset):,} samples, \"\n",
        "              f\"Val: {len(val_loader.dataset):,} samples\")\n",
        "\n",
        "    # --- Step 5: Model ---\n",
        "    model = GraphKTMinimal(\n",
        "        num_students=entity_counts['num_students'],\n",
        "        num_questions=entity_counts['num_questions'],\n",
        "        num_steps=entity_counts['num_steps'],\n",
        "        num_kcs=entity_counts['num_kcs'],\n",
        "        feature_dim=NUM_FEATURES,\n",
        "        embed_dim=config.EMBED_DIM,\n",
        "        hidden_dim=config.HIDDEN_DIM,\n",
        "        num_gnn_layers=config.NUM_GNN_LAYERS,\n",
        "        dropout=config.DROPOUT,\n",
        "        mastery_init=config.MASTERY_INIT,\n",
        "        mastery_gating=config.MASTERY_GATING\n",
        "    ).to(device)\n",
        "\n",
        "    # Initialize mastery matrix\n",
        "    model.init_mastery_matrix(device)\n",
        "\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    if verbose:\n",
        "        print(f\"{prefix}Model params: {total_params:,}\")\n",
        "\n",
        "    # --- Step 6: Training setup ---\n",
        "    n_correct = df_train_fold['correct'].sum()\n",
        "    n_incorrect = len(df_train_fold) - n_correct\n",
        "    pos_weight = torch.tensor([n_incorrect / n_correct], dtype=torch.float32).to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=config.LEARNING_RATE,\n",
        "                                   weight_decay=config.WEIGHT_DECAY)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='max', factor=0.5, patience=5\n",
        "    )\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "    early_stopping = EarlyStopping(patience=config.PATIENCE)\n",
        "\n",
        "    # --- Step 7: Training loop ---\n",
        "    history = defaultdict(list)\n",
        "    best_val_auc = 0\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"{prefix}Training (pos_weight={pos_weight.item():.4f})...\")\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "    for epoch in range(config.EPOCHS):\n",
        "        epoch_start = time.time()\n",
        "\n",
        "        train_loss, train_auc, train_acc = train_epoch(\n",
        "            model, train_loader, optimizer, criterion, hetero_data, device, config, config.GRAD_CLIP\n",
        "        )\n",
        "        val_loss, val_auc, val_acc = evaluate(\n",
        "            model, val_loader, criterion, hetero_data, device\n",
        "        )\n",
        "\n",
        "        epoch_time = time.time() - epoch_start\n",
        "\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_auc'].append(train_auc)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_auc'].append(val_auc)\n",
        "        history['val_acc'].append(val_acc)\n",
        "\n",
        "        marker = \" ★\" if val_auc > best_val_auc else \"\"\n",
        "        if val_auc > best_val_auc:\n",
        "            best_val_auc = val_auc\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"{prefix}Epoch {epoch+1:3d}/{config.EPOCHS} | \"\n",
        "                  f\"Train AUC: {train_auc:.4f} | Val AUC: {val_auc:.4f} | \"\n",
        "                  f\"Val Acc: {val_acc:.4f} | Time: {epoch_time:.1f}s{marker}\")\n",
        "\n",
        "        scheduler.step(val_auc)\n",
        "        early_stopping(val_auc, model)\n",
        "\n",
        "        if early_stopping.early_stop:\n",
        "            if verbose:\n",
        "                print(f\"{prefix}Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "    early_stopping.load_best(model)\n",
        "\n",
        "    final_val_loss, final_val_auc, final_val_acc = evaluate(\n",
        "        model, val_loader, criterion, hetero_data, device\n",
        "    )\n",
        "\n",
        "    stopped_epoch = len(history['train_loss'])\n",
        "\n",
        "    if verbose:\n",
        "        print(\"-\" * 70)\n",
        "        print(f\"{prefix}Best Val AUC: {final_val_auc:.4f} | \"\n",
        "              f\"Val Acc: {final_val_acc:.4f} | Stopped at epoch: {stopped_epoch}\")\n",
        "\n",
        "    return {\n",
        "        'val_auc': final_val_auc,\n",
        "        'val_acc': final_val_acc,\n",
        "        'val_loss': final_val_loss,\n",
        "        'train_auc': history['train_auc'][-1],\n",
        "        'stopped_epoch': stopped_epoch,\n",
        "        'total_params': total_params,\n",
        "        'history': dict(history),\n",
        "        'model_state': early_stopping.best_state,\n",
        "        'hetero_data': hetero_data,\n",
        "        'mappings': mappings,\n",
        "        'entity_counts': entity_counts,\n",
        "        'unk_indices': unk_indices,\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Confirmation\n",
        "# ============================================================\n",
        "print(\"=\" * 60)\n",
        "print(\"✓ ALL PIPELINE FUNCTIONS DEFINED (M3 VERSION)\")\n",
        "print(\"=\" * 60)\n",
        "print(\"  - build_entity_mappings()\")\n",
        "print(\"  - build_graph()\")\n",
        "print(\"  - compute_node_features()\")\n",
        "print(\"  - GraphKTMinimal (RGCN + Dual Propagation)\")\n",
        "print(\"  - MasteryMessagePassing (mastery-weighted edges)\")\n",
        "print(\"  - KTDatasetPure\")\n",
        "print(\"  - train_epoch() / evaluate()\")\n",
        "print(\"  - run_single_fold()\")\n",
        "print(\"=\" * 60)\n",
        "print(\"Ready for 5-Fold Cross-Validation! 🚀\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWsbyFg-o-po",
        "collapsed": true,
        "outputId": "6b8eca92-5068-4d04-b907-81c0adbf80c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "5-FOLD STUDENT-LEVEL CROSS-VALIDATION\n",
            "============================================================\n",
            "\n",
            "Protocol:\n",
            "  - 487 non-test students split into 5 folds\n",
            "  - Each fold: full pipeline rebuild (mappings, graph, features, model)\n",
            "  - All design decisions FROZEN before CV\n",
            "  - TEST set (87 students) completely untouched\n",
            "\n",
            "Frozen hyperparameters:\n",
            "  EMBED_DIM=32, HIDDEN_DIM=64\n",
            "  NUM_GNN_LAYERS=2, DROPOUT=0.2\n",
            "  LR=0.001, WEIGHT_DECAY=0.01\n",
            "  BATCH_SIZE=512, PATIENCE=10\n",
            "\n",
            "\n",
            "============================================================\n",
            "FOLD 1 / 5\n",
            "============================================================\n",
            "Train students: 389, Val students: 98\n",
            "Train interactions: 524,961, Val interactions: 166,472\n",
            "[Fold 1] Entities: S=390, Q=1064, T=146327, C=397\n",
            "[Fold 1] Graph edges: 662,288\n",
            "[Fold 1] Train: 524,961 samples, Val: 166,472 samples\n",
            "  ✓ Mastery matrix initialized: [390, 397] with value=0.5\n",
            "[Fold 1] Model params: 25,649\n",
            "[Fold 1] Training (pos_weight=0.3041)...\n",
            "----------------------------------------------------------------------\n",
            "[Fold 1] Epoch   1/100 | Train AUC: 0.9035 | Val AUC: 0.7650 | Val Acc: 0.7026 | Time: 105.6s ★\n",
            "[Fold 1] Epoch   2/100 | Train AUC: 0.9149 | Val AUC: 0.7537 | Val Acc: 0.6825 | Time: 104.9s\n",
            "[Fold 1] Epoch   3/100 | Train AUC: 0.9173 | Val AUC: 0.7516 | Val Acc: 0.6947 | Time: 104.4s\n",
            "[Fold 1] Epoch   4/100 | Train AUC: 0.9188 | Val AUC: 0.7499 | Val Acc: 0.6560 | Time: 104.6s\n",
            "[Fold 1] Epoch   5/100 | Train AUC: 0.9195 | Val AUC: 0.7462 | Val Acc: 0.6737 | Time: 104.5s\n",
            "[Fold 1] Epoch   6/100 | Train AUC: 0.9201 | Val AUC: 0.7451 | Val Acc: 0.6880 | Time: 103.9s\n",
            "[Fold 1] Epoch   7/100 | Train AUC: 0.9206 | Val AUC: 0.7471 | Val Acc: 0.6784 | Time: 104.1s\n",
            "[Fold 1] Epoch   8/100 | Train AUC: 0.9214 | Val AUC: 0.7423 | Val Acc: 0.6337 | Time: 104.1s\n",
            "[Fold 1] Epoch   9/100 | Train AUC: 0.9217 | Val AUC: 0.7464 | Val Acc: 0.6496 | Time: 104.7s\n",
            "[Fold 1] Epoch  10/100 | Train AUC: 0.9219 | Val AUC: 0.7424 | Val Acc: 0.6332 | Time: 104.6s\n",
            "[Fold 1] Epoch  11/100 | Train AUC: 0.9220 | Val AUC: 0.7355 | Val Acc: 0.6539 | Time: 104.2s\n",
            "[Fold 1] Early stopping at epoch 11\n",
            "----------------------------------------------------------------------\n",
            "[Fold 1] Best Val AUC: 0.7650 | Val Acc: 0.7026 | Stopped at epoch: 11\n",
            "\n",
            "Fold 1 completed in 1240.8s\n",
            "\n",
            "============================================================\n",
            "FOLD 2 / 5\n",
            "============================================================\n",
            "Train students: 389, Val students: 98\n",
            "Train interactions: 579,228, Val interactions: 112,205\n",
            "[Fold 2] Entities: S=390, Q=1077, T=156768, C=406\n",
            "[Fold 2] Graph edges: 712,642\n",
            "[Fold 2] Train: 579,228 samples, Val: 112,205 samples\n",
            "  ✓ Mastery matrix initialized: [390, 406] with value=0.5\n",
            "[Fold 2] Model params: 25,649\n",
            "[Fold 2] Training (pos_weight=0.2926)...\n",
            "----------------------------------------------------------------------\n",
            "[Fold 2] Epoch   1/100 | Train AUC: 0.9033 | Val AUC: 0.7518 | Val Acc: 0.7199 | Time: 108.4s ★\n",
            "[Fold 2] Epoch   2/100 | Train AUC: 0.9133 | Val AUC: 0.7398 | Val Acc: 0.7056 | Time: 108.5s\n",
            "[Fold 2] Epoch   3/100 | Train AUC: 0.9159 | Val AUC: 0.7298 | Val Acc: 0.5633 | Time: 107.9s\n",
            "[Fold 2] Epoch   4/100 | Train AUC: 0.9168 | Val AUC: 0.7331 | Val Acc: 0.5341 | Time: 108.0s\n",
            "[Fold 2] Epoch   5/100 | Train AUC: 0.9179 | Val AUC: 0.7282 | Val Acc: 0.4504 | Time: 108.7s\n",
            "[Fold 2] Epoch   6/100 | Train AUC: 0.9182 | Val AUC: 0.7366 | Val Acc: 0.5149 | Time: 109.0s\n",
            "[Fold 2] Epoch   7/100 | Train AUC: 0.9187 | Val AUC: 0.7290 | Val Acc: 0.4728 | Time: 108.9s\n",
            "[Fold 2] Epoch   8/100 | Train AUC: 0.9196 | Val AUC: 0.7127 | Val Acc: 0.6402 | Time: 108.8s\n",
            "[Fold 2] Epoch   9/100 | Train AUC: 0.9198 | Val AUC: 0.7210 | Val Acc: 0.6577 | Time: 108.0s\n",
            "[Fold 2] Epoch  10/100 | Train AUC: 0.9199 | Val AUC: 0.7274 | Val Acc: 0.6614 | Time: 108.1s\n",
            "[Fold 2] Epoch  11/100 | Train AUC: 0.9203 | Val AUC: 0.7188 | Val Acc: 0.6320 | Time: 108.3s\n",
            "[Fold 2] Early stopping at epoch 11\n",
            "----------------------------------------------------------------------\n",
            "[Fold 2] Best Val AUC: 0.7518 | Val Acc: 0.7199 | Stopped at epoch: 11\n",
            "\n",
            "Fold 2 completed in 1282.6s\n",
            "\n",
            "============================================================\n",
            "FOLD 3 / 5\n",
            "============================================================\n",
            "Train students: 390, Val students: 97\n",
            "Train interactions: 537,828, Val interactions: 153,605\n",
            "[Fold 3] Entities: S=391, Q=1078, T=150244, C=415\n",
            "[Fold 3] Graph edges: 680,518\n",
            "[Fold 3] Train: 537,828 samples, Val: 153,605 samples\n",
            "  ✓ Mastery matrix initialized: [391, 415] with value=0.5\n",
            "[Fold 3] Model params: 25,649\n",
            "[Fold 3] Training (pos_weight=0.3030)...\n",
            "----------------------------------------------------------------------\n",
            "[Fold 3] Epoch   1/100 | Train AUC: 0.9065 | Val AUC: 0.7689 | Val Acc: 0.7243 | Time: 105.9s ★\n",
            "[Fold 3] Epoch   2/100 | Train AUC: 0.9164 | Val AUC: 0.7687 | Val Acc: 0.6909 | Time: 106.3s\n",
            "[Fold 3] Epoch   3/100 | Train AUC: 0.9189 | Val AUC: 0.7426 | Val Acc: 0.6830 | Time: 105.6s\n",
            "[Fold 3] Epoch   4/100 | Train AUC: 0.9203 | Val AUC: 0.7376 | Val Acc: 0.6656 | Time: 105.1s\n",
            "[Fold 3] Epoch   5/100 | Train AUC: 0.9211 | Val AUC: 0.7438 | Val Acc: 0.6317 | Time: 105.4s\n",
            "[Fold 3] Epoch   6/100 | Train AUC: 0.9215 | Val AUC: 0.7312 | Val Acc: 0.6520 | Time: 105.0s\n",
            "[Fold 3] Epoch   7/100 | Train AUC: 0.9221 | Val AUC: 0.7347 | Val Acc: 0.6817 | Time: 105.2s\n",
            "[Fold 3] Epoch   8/100 | Train AUC: 0.9228 | Val AUC: 0.7288 | Val Acc: 0.6412 | Time: 105.2s\n",
            "[Fold 3] Epoch   9/100 | Train AUC: 0.9231 | Val AUC: 0.7300 | Val Acc: 0.6553 | Time: 105.3s\n",
            "[Fold 3] Epoch  10/100 | Train AUC: 0.9232 | Val AUC: 0.7307 | Val Acc: 0.6453 | Time: 105.4s\n",
            "[Fold 3] Epoch  11/100 | Train AUC: 0.9236 | Val AUC: 0.7309 | Val Acc: 0.6449 | Time: 105.8s\n",
            "[Fold 3] Early stopping at epoch 11\n",
            "----------------------------------------------------------------------\n",
            "[Fold 3] Best Val AUC: 0.7689 | Val Acc: 0.7243 | Stopped at epoch: 11\n",
            "\n",
            "Fold 3 completed in 1251.9s\n",
            "\n",
            "============================================================\n",
            "FOLD 4 / 5\n",
            "============================================================\n",
            "Train students: 390, Val students: 97\n",
            "Train interactions: 557,654, Val interactions: 133,779\n",
            "[Fold 4] Entities: S=391, Q=1078, T=154760, C=415\n",
            "[Fold 4] Graph edges: 701,006\n",
            "[Fold 4] Train: 557,654 samples, Val: 133,779 samples\n",
            "  ✓ Mastery matrix initialized: [391, 415] with value=0.5\n",
            "[Fold 4] Model params: 25,649\n",
            "[Fold 4] Training (pos_weight=0.3031)...\n",
            "----------------------------------------------------------------------\n",
            "[Fold 4] Epoch   1/100 | Train AUC: 0.9064 | Val AUC: 0.7359 | Val Acc: 0.7618 | Time: 107.8s ★\n",
            "[Fold 4] Epoch   2/100 | Train AUC: 0.9159 | Val AUC: 0.7322 | Val Acc: 0.7241 | Time: 107.5s\n",
            "[Fold 4] Epoch   3/100 | Train AUC: 0.9182 | Val AUC: 0.7308 | Val Acc: 0.6905 | Time: 107.8s\n",
            "[Fold 4] Epoch   4/100 | Train AUC: 0.9194 | Val AUC: 0.7310 | Val Acc: 0.6931 | Time: 107.6s\n",
            "[Fold 4] Epoch   5/100 | Train AUC: 0.9203 | Val AUC: 0.7362 | Val Acc: 0.6823 | Time: 107.2s ★\n",
            "[Fold 4] Epoch   6/100 | Train AUC: 0.9210 | Val AUC: 0.7324 | Val Acc: 0.7124 | Time: 108.8s\n",
            "[Fold 4] Epoch   7/100 | Train AUC: 0.9213 | Val AUC: 0.7289 | Val Acc: 0.6385 | Time: 109.5s\n",
            "[Fold 4] Epoch   8/100 | Train AUC: 0.9217 | Val AUC: 0.7356 | Val Acc: 0.6820 | Time: 108.7s\n",
            "[Fold 4] Epoch   9/100 | Train AUC: 0.9221 | Val AUC: 0.7585 | Val Acc: 0.6669 | Time: 108.4s ★\n",
            "[Fold 4] Epoch  10/100 | Train AUC: 0.9222 | Val AUC: 0.7354 | Val Acc: 0.6855 | Time: 108.3s\n",
            "[Fold 4] Epoch  11/100 | Train AUC: 0.9224 | Val AUC: 0.7359 | Val Acc: 0.7074 | Time: 108.8s\n",
            "[Fold 4] Epoch  12/100 | Train AUC: 0.9227 | Val AUC: 0.7338 | Val Acc: 0.6759 | Time: 108.2s\n",
            "[Fold 4] Epoch  13/100 | Train AUC: 0.9231 | Val AUC: 0.7345 | Val Acc: 0.7259 | Time: 107.4s\n",
            "[Fold 4] Epoch  14/100 | Train AUC: 0.9231 | Val AUC: 0.7346 | Val Acc: 0.6726 | Time: 107.4s\n",
            "[Fold 4] Epoch  15/100 | Train AUC: 0.9232 | Val AUC: 0.7571 | Val Acc: 0.5454 | Time: 107.3s\n",
            "[Fold 4] Epoch  16/100 | Train AUC: 0.9238 | Val AUC: 0.7585 | Val Acc: 0.5463 | Time: 107.8s ★\n",
            "[Fold 4] Epoch  17/100 | Train AUC: 0.9241 | Val AUC: 0.7519 | Val Acc: 0.6850 | Time: 107.3s\n",
            "[Fold 4] Epoch  18/100 | Train AUC: 0.9242 | Val AUC: 0.7585 | Val Acc: 0.5288 | Time: 107.8s ★\n",
            "[Fold 4] Epoch  19/100 | Train AUC: 0.9242 | Val AUC: 0.7566 | Val Acc: 0.5443 | Time: 107.5s\n",
            "[Fold 4] Early stopping at epoch 19\n",
            "----------------------------------------------------------------------\n",
            "[Fold 4] Best Val AUC: 0.7585 | Val Acc: 0.6669 | Stopped at epoch: 19\n",
            "\n",
            "Fold 4 completed in 2141.9s\n",
            "\n",
            "============================================================\n",
            "FOLD 5 / 5\n",
            "============================================================\n",
            "Train students: 390, Val students: 97\n",
            "Train interactions: 566,061, Val interactions: 125,372\n",
            "[Fold 5] Entities: S=391, Q=1072, T=155983, C=414\n",
            "[Fold 5] Graph edges: 707,298\n",
            "[Fold 5] Train: 566,061 samples, Val: 125,372 samples\n",
            "  ✓ Mastery matrix initialized: [391, 414] with value=0.5\n",
            "[Fold 5] Model params: 25,649\n",
            "[Fold 5] Training (pos_weight=0.2975)...\n",
            "----------------------------------------------------------------------\n",
            "[Fold 5] Epoch   1/100 | Train AUC: 0.9050 | Val AUC: 0.7368 | Val Acc: 0.7524 | Time: 108.0s ★\n",
            "[Fold 5] Epoch   2/100 | Train AUC: 0.9158 | Val AUC: 0.7392 | Val Acc: 0.7082 | Time: 107.8s ★\n",
            "[Fold 5] Epoch   3/100 | Train AUC: 0.9181 | Val AUC: 0.7464 | Val Acc: 0.7024 | Time: 107.2s ★\n",
            "[Fold 5] Epoch   4/100 | Train AUC: 0.9196 | Val AUC: 0.7477 | Val Acc: 0.6976 | Time: 107.8s ★\n",
            "[Fold 5] Epoch   5/100 | Train AUC: 0.9201 | Val AUC: 0.7409 | Val Acc: 0.6593 | Time: 107.2s\n",
            "[Fold 5] Epoch   6/100 | Train AUC: 0.9208 | Val AUC: 0.7343 | Val Acc: 0.6800 | Time: 107.3s\n",
            "[Fold 5] Epoch   7/100 | Train AUC: 0.9214 | Val AUC: 0.7363 | Val Acc: 0.6741 | Time: 108.5s\n",
            "[Fold 5] Epoch   8/100 | Train AUC: 0.9215 | Val AUC: 0.7626 | Val Acc: 0.6605 | Time: 107.8s ★\n",
            "[Fold 5] Epoch   9/100 | Train AUC: 0.9221 | Val AUC: 0.7403 | Val Acc: 0.6811 | Time: 107.5s\n",
            "[Fold 5] Epoch  10/100 | Train AUC: 0.9223 | Val AUC: 0.7359 | Val Acc: 0.6665 | Time: 107.3s\n",
            "[Fold 5] Epoch  11/100 | Train AUC: 0.9223 | Val AUC: 0.7355 | Val Acc: 0.6672 | Time: 108.5s\n",
            "[Fold 5] Epoch  12/100 | Train AUC: 0.9227 | Val AUC: 0.7412 | Val Acc: 0.6795 | Time: 107.8s\n",
            "[Fold 5] Epoch  13/100 | Train AUC: 0.9229 | Val AUC: 0.7613 | Val Acc: 0.6950 | Time: 107.8s\n",
            "[Fold 5] Epoch  14/100 | Train AUC: 0.9228 | Val AUC: 0.7576 | Val Acc: 0.6859 | Time: 107.6s\n",
            "[Fold 5] Epoch  15/100 | Train AUC: 0.9237 | Val AUC: 0.7410 | Val Acc: 0.6629 | Time: 108.2s\n",
            "[Fold 5] Epoch  16/100 | Train AUC: 0.9238 | Val AUC: 0.7386 | Val Acc: 0.6571 | Time: 107.6s\n",
            "[Fold 5] Epoch  17/100 | Train AUC: 0.9239 | Val AUC: 0.7384 | Val Acc: 0.6575 | Time: 107.9s\n",
            "[Fold 5] Epoch  18/100 | Train AUC: 0.9240 | Val AUC: 0.7375 | Val Acc: 0.6580 | Time: 107.9s\n",
            "[Fold 5] Early stopping at epoch 18\n",
            "----------------------------------------------------------------------\n",
            "[Fold 5] Best Val AUC: 0.7626 | Val Acc: 0.6605 | Stopped at epoch: 18\n",
            "\n",
            "Fold 5 completed in 2030.2s\n",
            "\n",
            "============================================================\n",
            "5-FOLD CROSS-VALIDATION RESULTS\n",
            "============================================================\n",
            "\n",
            "Fold     Val AUC      Val Acc      Epochs    \n",
            "------------------------------------------\n",
            "Fold 1   0.7650       0.7026       11        \n",
            "Fold 2   0.7518       0.7199       11        \n",
            "Fold 3   0.7689       0.7243       11        \n",
            "Fold 4   0.7585       0.6669       19        \n",
            "Fold 5   0.7626       0.6605       18        \n",
            "------------------------------------------\n",
            "Mean     0.7614       0.6948       14.0      \n",
            "Std      0.0059       0.0265       3.7       \n",
            "Min      0.7518       0.6605       11        \n",
            "Max      0.7689       0.7243       19        \n",
            "\n",
            "╔══════════════════════════════════════════════╗\n",
            "║  CV Val AUC: 0.7614 ± 0.0059              ║\n",
            "║  CV Val Acc: 0.6948 ± 0.0265              ║\n",
            "╚══════════════════════════════════════════════╝\n",
            "\n",
            "Total CV time: 7947.3s (132.5 min)\n",
            "\n",
            "Average stopping epoch: 14 (will use for final training)\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Cell 6: Run 5-Fold Student-Level Cross-Validation\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"5-FOLD STUDENT-LEVEL CROSS-VALIDATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\"\"\n",
        "Protocol:\n",
        "  - {len(non_test_students)} non-test students split into 5 folds\n",
        "  - Each fold: full pipeline rebuild (mappings, graph, features, model)\n",
        "  - All design decisions FROZEN before CV\n",
        "  - TEST set ({len(test_students)} students) completely untouched\n",
        "\n",
        "Frozen hyperparameters:\n",
        "  EMBED_DIM={config.EMBED_DIM}, HIDDEN_DIM={config.HIDDEN_DIM}\n",
        "  NUM_GNN_LAYERS={config.NUM_GNN_LAYERS}, DROPOUT={config.DROPOUT}\n",
        "  LR={config.LEARNING_RATE}, WEIGHT_DECAY={config.WEIGHT_DECAY}\n",
        "  BATCH_SIZE=512, PATIENCE={config.PATIENCE}\n",
        "\"\"\")\n",
        "\n",
        "cv_results = []\n",
        "cv_start = time.time()\n",
        "\n",
        "for fold_idx in range(5):\n",
        "    fold_start = time.time()\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"FOLD {fold_idx + 1} / 5\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Get this fold's students\n",
        "    train_students_fold = fold_assignments[fold_idx]['train_students']\n",
        "    val_students_fold = fold_assignments[fold_idx]['val_students']\n",
        "\n",
        "    # Create dataframes for this fold\n",
        "    df_train_fold = df_non_test[df_non_test['student_id'].isin(train_students_fold)].copy()\n",
        "    df_val_fold = df_non_test[df_non_test['student_id'].isin(val_students_fold)].copy()\n",
        "\n",
        "    print(f\"Train students: {len(train_students_fold)}, \"\n",
        "          f\"Val students: {len(val_students_fold)}\")\n",
        "    print(f\"Train interactions: {len(df_train_fold):,}, \"\n",
        "          f\"Val interactions: {len(df_val_fold):,}\")\n",
        "\n",
        "    # Run full pipeline for this fold\n",
        "    result = run_single_fold(\n",
        "        df_train_fold, df_val_fold, config,\n",
        "        fold_num=fold_idx + 1, verbose=True\n",
        "    )\n",
        "\n",
        "    fold_time = time.time() - fold_start\n",
        "    result['fold_time'] = fold_time\n",
        "    cv_results.append(result)\n",
        "\n",
        "    print(f\"\\nFold {fold_idx + 1} completed in {fold_time:.1f}s\")\n",
        "\n",
        "total_cv_time = time.time() - cv_start\n",
        "\n",
        "# ============================================================\n",
        "# CV Summary\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"5-FOLD CROSS-VALIDATION RESULTS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "val_aucs = [r['val_auc'] for r in cv_results]\n",
        "val_accs = [r['val_acc'] for r in cv_results]\n",
        "stopped_epochs = [r['stopped_epoch'] for r in cv_results]\n",
        "\n",
        "print(f\"\\n{'Fold':<8} {'Val AUC':<12} {'Val Acc':<12} {'Epochs':<10}\")\n",
        "print(\"-\" * 42)\n",
        "for i, r in enumerate(cv_results):\n",
        "    print(f\"Fold {i+1:<3} {r['val_auc']:<12.4f} {r['val_acc']:<12.4f} {r['stopped_epoch']:<10}\")\n",
        "\n",
        "print(\"-\" * 42)\n",
        "print(f\"{'Mean':<8} {np.mean(val_aucs):<12.4f} {np.mean(val_accs):<12.4f} {np.mean(stopped_epochs):<10.1f}\")\n",
        "print(f\"{'Std':<8} {np.std(val_aucs):<12.4f} {np.std(val_accs):<12.4f} {np.std(stopped_epochs):<10.1f}\")\n",
        "print(f\"{'Min':<8} {np.min(val_aucs):<12.4f} {np.min(val_accs):<12.4f} {np.min(stopped_epochs):<10}\")\n",
        "print(f\"{'Max':<8} {np.max(val_aucs):<12.4f} {np.max(val_accs):<12.4f} {np.max(stopped_epochs):<10}\")\n",
        "\n",
        "print(f\"\\n╔══════════════════════════════════════════════╗\")\n",
        "print(f\"║  CV Val AUC: {np.mean(val_aucs):.4f} ± {np.std(val_aucs):.4f}              ║\")\n",
        "print(f\"║  CV Val Acc: {np.mean(val_accs):.4f} ± {np.std(val_accs):.4f}              ║\")\n",
        "print(f\"╚══════════════════════════════════════════════╝\")\n",
        "\n",
        "print(f\"\\nTotal CV time: {total_cv_time:.1f}s ({total_cv_time/60:.1f} min)\")\n",
        "\n",
        "# Store average epochs for final training\n",
        "avg_epochs_cv = int(np.mean(stopped_epochs))\n",
        "print(f\"\\nAverage stopping epoch: {avg_epochs_cv} (will use for final training)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "id": "RDUnF4Kto-pp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d318b57-e834-406b-ab5b-70ddba01bd64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "FINAL TEST EVALUATION\n",
            "============================================================\n",
            "\n",
            "Protocol:\n",
            "  - Train on ALL 487 non-test students (no validation split)\n",
            "  - Train for 14 epochs (average from CV, no early stopping)\n",
            "  - Evaluate on held-out TEST set (87 students)\n",
            "  - This number appears in the paper as TEST performance\n",
            "\n",
            "[1/5] Building entity mappings from all non-test data...\n",
            "  S=488, Q=1081, T=184307, C=428\n",
            "[2/5] Building graph...\n",
            "  Edges: 839,032\n",
            "[3/5] Computing node features...\n",
            "[4/5] Creating dataloaders...\n",
            "  Train: 691,433 samples\n",
            "  Test:  118,261 samples\n",
            "[5/5] Training final model...\n",
            "  ✓ Mastery matrix initialized: [488, 428] with value=0.5\n",
            "\n",
            "Training for 14 epochs (CV average)...\n",
            "----------------------------------------------------------------------\n",
            "Epoch   1/14 | Train Loss: 0.1784 | Train AUC: 0.9026 | Train Acc: 0.8083 | Time: 120.6s\n",
            "Epoch   5/14 | Train Loss: 0.1630 | Train AUC: 0.9175 | Train Acc: 0.8224 | Time: 118.1s\n",
            "Epoch  10/14 | Train Loss: 0.1612 | Train AUC: 0.9193 | Train Acc: 0.8236 | Time: 118.0s\n",
            "Epoch  14/14 | Train Loss: 0.1602 | Train AUC: 0.9203 | Train Acc: 0.8254 | Time: 117.9s\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Evaluating on TEST set...\n",
            "\n",
            "============================================================\n",
            "FINAL RESULTS\n",
            "============================================================\n",
            "\n",
            "╔══════════════════════════════════════════════════════════════╗\n",
            "║              GraphKT M3 (RGCN + Dual Propagation)            ║\n",
            "║                    Algebra 2005-2006 Dataset                 ║\n",
            "╠══════════════════════════════════════════════════════════════╣\n",
            "║                                                              ║\n",
            "║  5-Fold CV Validation:                                       ║\n",
            "║    AUC:      0.7614 ± 0.0059                              ║\n",
            "║    Accuracy: 0.6948 ± 0.0265                              ║\n",
            "║                                                              ║\n",
            "║  Test Set (held-out, 87 students):                          ║\n",
            "║    AUC:      0.7543                                        ║\n",
            "║    Accuracy: 0.6778                                        ║\n",
            "║                                                              ║\n",
            "║  Model: 25,649 parameters                              ║\n",
            "║  Training: 14 epochs (CV average)                           ║\n",
            "║  Split: Student-level (Split B), no leakage                  ║\n",
            "║                                                              ║\n",
            "╚══════════════════════════════════════════════════════════════╝\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Cell 7: Final TEST Set Evaluation\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"FINAL TEST EVALUATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\"\"\n",
        "Protocol:\n",
        "  - Train on ALL {len(non_test_students)} non-test students (no validation split)\n",
        "  - Train for {avg_epochs_cv} epochs (average from CV, no early stopping)\n",
        "  - Evaluate on held-out TEST set ({len(test_students)} students)\n",
        "  - This number appears in the paper as TEST performance\n",
        "\"\"\")\n",
        "\n",
        "# --- Train on all non-test data ---\n",
        "df_train_final = df_non_test.copy()\n",
        "\n",
        "print(\"[1/5] Building entity mappings from all non-test data...\")\n",
        "mappings_final, entity_counts_final, unk_indices_final = build_entity_mappings(df_train_final)\n",
        "print(f\"  S={entity_counts_final['num_students']}, \"\n",
        "      f\"Q={entity_counts_final['num_questions']}, \"\n",
        "      f\"T={entity_counts_final['num_steps']}, \"\n",
        "      f\"C={entity_counts_final['num_kcs']}\")\n",
        "\n",
        "print(\"[2/5] Building graph...\")\n",
        "hetero_data_final, total_edges_final = build_graph(\n",
        "    df_train_final, mappings_final, entity_counts_final, unk_indices_final\n",
        ")\n",
        "print(f\"  Edges: {total_edges_final:,}\")\n",
        "\n",
        "print(\"[3/5] Computing node features...\")\n",
        "feat_tensors_final = compute_node_features(\n",
        "    df_train_final, mappings_final, entity_counts_final, unk_indices_final\n",
        ")\n",
        "hetero_data_final['student'].x = feat_tensors_final['student']\n",
        "hetero_data_final['question'].x = feat_tensors_final['question']\n",
        "hetero_data_final['step'].x = feat_tensors_final['step']\n",
        "hetero_data_final['kc'].x = feat_tensors_final['kc']\n",
        "\n",
        "print(\"[4/5] Creating dataloaders...\")\n",
        "train_dataset_final = KTDatasetPure(\n",
        "    df_train_final,\n",
        "    mappings_final['stu2idx'], mappings_final['t2idx'], mappings_final['c2idx'],\n",
        "    unk_indices_final['student'], unk_indices_final['step'], unk_indices_final['kc']\n",
        ")\n",
        "test_dataset_final = KTDatasetPure(\n",
        "    df_test_final,\n",
        "    mappings_final['stu2idx'], mappings_final['t2idx'], mappings_final['c2idx'],\n",
        "    unk_indices_final['student'], unk_indices_final['step'], unk_indices_final['kc']\n",
        ")\n",
        "\n",
        "train_loader_final = DataLoader(train_dataset_final, batch_size=512, shuffle=True,\n",
        "                                 pin_memory=True, num_workers=0)\n",
        "test_loader_final = DataLoader(test_dataset_final, batch_size=512, shuffle=False,\n",
        "                                pin_memory=True, num_workers=0)\n",
        "\n",
        "print(f\"  Train: {len(train_dataset_final):,} samples\")\n",
        "print(f\"  Test:  {len(test_dataset_final):,} samples\")\n",
        "\n",
        "print(\"[5/5] Training final model...\")\n",
        "device = config.DEVICE\n",
        "\n",
        "# 🔧 CHANGEMENT 1: RGCNPure → GraphKTMinimal\n",
        "model_final = GraphKTMinimal(\n",
        "    num_students=entity_counts_final['num_students'],\n",
        "    num_questions=entity_counts_final['num_questions'],\n",
        "    num_steps=entity_counts_final['num_steps'],\n",
        "    num_kcs=entity_counts_final['num_kcs'],\n",
        "    feature_dim=NUM_FEATURES,\n",
        "    embed_dim=config.EMBED_DIM,\n",
        "    hidden_dim=config.HIDDEN_DIM,\n",
        "    num_gnn_layers=config.NUM_GNN_LAYERS,\n",
        "    dropout=config.DROPOUT,\n",
        "    mastery_init=config.MASTERY_INIT,      # ← AJOUT\n",
        "    mastery_gating=config.MASTERY_GATING   # ← AJOUT\n",
        ").to(device)\n",
        "\n",
        "# 🔧 CHANGEMENT 2: Init mastery matrix\n",
        "model_final.init_mastery_matrix(device)  # ← AJOUT CRITIQUE\n",
        "\n",
        "# Class weights from full training set\n",
        "n_correct = df_train_final['correct'].sum()\n",
        "n_incorrect = len(df_train_final) - n_correct\n",
        "pos_weight_final = torch.tensor([n_incorrect / n_correct], dtype=torch.float32).to(device)\n",
        "\n",
        "optimizer_final = torch.optim.AdamW(model_final.parameters(), lr=config.LEARNING_RATE,\n",
        "                                      weight_decay=config.WEIGHT_DECAY)\n",
        "scheduler_final = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer_final, mode='min', factor=0.5, patience=5\n",
        ")\n",
        "criterion_final = nn.BCEWithLogitsLoss(pos_weight=pos_weight_final)\n",
        "\n",
        "# Train for fixed number of epochs (from CV average)\n",
        "print(f\"\\nTraining for {avg_epochs_cv} epochs (CV average)...\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "for epoch in range(avg_epochs_cv):\n",
        "    epoch_start = time.time()\n",
        "\n",
        "    # 🔧 CHANGEMENT 3: Passer config au lieu de config.GRAD_CLIP\n",
        "    train_loss, train_auc, train_acc = train_epoch(\n",
        "        model_final, train_loader_final, optimizer_final, criterion_final,\n",
        "        hetero_data_final, device, config, config.GRAD_CLIP\n",
        "    )\n",
        "\n",
        "    epoch_time = time.time() - epoch_start\n",
        "\n",
        "    if (epoch + 1) % 5 == 0 or epoch == 0 or (epoch + 1) == avg_epochs_cv:\n",
        "        print(f\"Epoch {epoch+1:3d}/{avg_epochs_cv} | \"\n",
        "              f\"Train Loss: {train_loss:.4f} | Train AUC: {train_auc:.4f} | \"\n",
        "              f\"Train Acc: {train_acc:.4f} | Time: {epoch_time:.1f}s\")\n",
        "\n",
        "    scheduler_final.step(train_loss)\n",
        "\n",
        "print(\"-\" * 70)\n",
        "\n",
        "# --- Final TEST evaluation ---\n",
        "print(\"\\nEvaluating on TEST set...\")\n",
        "test_loss, test_auc, test_acc = evaluate(\n",
        "    model_final, test_loader_final, criterion_final,\n",
        "    hetero_data_final, device\n",
        ")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"FINAL RESULTS\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"\"\"\n",
        "╔══════════════════════════════════════════════════════════════╗\n",
        "║              GraphKT M3 (RGCN + Dual Propagation)            ║\n",
        "║                    Algebra 2005-2006 Dataset                 ║\n",
        "╠══════════════════════════════════════════════════════════════╣\n",
        "║                                                              ║\n",
        "║  5-Fold CV Validation:                                       ║\n",
        "║    AUC:      {np.mean(val_aucs):.4f} ± {np.std(val_aucs):.4f}                              ║\n",
        "║    Accuracy: {np.mean(val_accs):.4f} ± {np.std(val_accs):.4f}                              ║\n",
        "║                                                              ║\n",
        "║  Test Set (held-out, {len(test_students)} students):                          ║\n",
        "║    AUC:      {test_auc:.4f}                                        ║\n",
        "║    Accuracy: {test_acc:.4f}                                        ║\n",
        "║                                                              ║\n",
        "║  Model: {sum(p.numel() for p in model_final.parameters()):,} parameters                              ║\n",
        "║  Training: {avg_epochs_cv} epochs (CV average)                           ║\n",
        "║  Split: Student-level (Split B), no leakage                  ║\n",
        "║                                                              ║\n",
        "╚══════════════════════════════════════════════════════════════╝\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9qu-TFRao-pp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70bf8f0d-aefe-430f-f385-1c823fcc9a63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "DETAILED RESULTS FOR PAPER\n",
            "============================================================\n",
            "\n",
            "Table 1: Per-Fold Cross-Validation Results\n",
            "-------------------------------------------------------\n",
            "Fold   Students   Interactions   Val AUC    Val Acc    Epochs  \n",
            "-------------------------------------------------------\n",
            "1      98         166,472        0.7650     0.7026     11      \n",
            "2      98         112,205        0.7518     0.7199     11      \n",
            "3      97         153,605        0.7689     0.7243     11      \n",
            "4      97         133,779        0.7585     0.6669     19      \n",
            "5      97         125,372        0.7626     0.6605     18      \n",
            "-------------------------------------------------------\n",
            "Mean                             0.7614     0.6948     14.0    \n",
            "±Std                             0.0059     0.0265     3.7     \n",
            "\n",
            "\n",
            "Table 2: Model Comparison (for paper)\n",
            "-----------------------------------------------------------------\n",
            "Model                Val AUC          Test AUC     Params    \n",
            "-----------------------------------------------------------------\n",
            "GraphKT M3           0.7614 ± 0.0059   0.7543       25,649\n",
            "\n",
            "\n",
            "Consistency Analysis:\n",
            "  AUC range across folds: 0.0172\n",
            "  ✓ Highly consistent (range < 0.03)\n",
            "\n",
            "  Coefficient of variation: 0.77%\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Cell 8: Paper-Ready Results Summary & Per-Fold Analysis\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"DETAILED RESULTS FOR PAPER\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Per-fold table\n",
        "print(\"\\nTable 1: Per-Fold Cross-Validation Results\")\n",
        "print(\"-\" * 55)\n",
        "print(f\"{'Fold':<6} {'Students':<10} {'Interactions':<14} {'Val AUC':<10} {'Val Acc':<10} {'Epochs':<8}\")\n",
        "print(\"-\" * 55)\n",
        "for i, r in enumerate(cv_results):\n",
        "    n_val_stu = len(fold_assignments[i]['val_students'])\n",
        "    df_val_f = df_non_test[df_non_test['student_id'].isin(fold_assignments[i]['val_students'])]\n",
        "    n_val_int = len(df_val_f)\n",
        "    print(f\"{i+1:<6} {n_val_stu:<10} {n_val_int:<14,} {r['val_auc']:<10.4f} {r['val_acc']:<10.4f} {r['stopped_epoch']:<8}\")\n",
        "\n",
        "print(\"-\" * 55)\n",
        "print(f\"{'Mean':<6} {'':10} {'':14} {np.mean(val_aucs):<10.4f} {np.mean(val_accs):<10.4f} {np.mean(stopped_epochs):<8.1f}\")\n",
        "print(f\"{'±Std':<6} {'':10} {'':14} {np.std(val_aucs):<10.4f} {np.std(val_accs):<10.4f} {np.std(stopped_epochs):<8.1f}\")\n",
        "\n",
        "# Summary table for paper\n",
        "print(f\"\\n\\nTable 2: Model Comparison (for paper)\")\n",
        "print(\"-\" * 65)\n",
        "print(f\"{'Model':<20} {'Val AUC':<16} {'Test AUC':<12} {'Params':<10}\")\n",
        "print(\"-\" * 65)\n",
        "# 🔧 CHANGEMENT: \"RGCN\" → \"GraphKT M3\"\n",
        "print(f\"{'GraphKT M3':<20} {np.mean(val_aucs):.4f} ± {np.std(val_aucs):.4f}   {test_auc:<12.4f} {sum(p.numel() for p in model_final.parameters()):,}\")\n",
        "\n",
        "# Consistency check\n",
        "auc_range = np.max(val_aucs) - np.min(val_aucs)\n",
        "print(f\"\\n\\nConsistency Analysis:\")\n",
        "print(f\"  AUC range across folds: {auc_range:.4f}\")\n",
        "if auc_range < 0.03:\n",
        "    print(f\"  ✓ Highly consistent (range < 0.03)\")\n",
        "elif auc_range < 0.05:\n",
        "    print(f\"  ~ Moderately consistent (range < 0.05)\")\n",
        "else:\n",
        "    print(f\"  ⚠ High variance across folds - investigate fold differences\")\n",
        "\n",
        "print(f\"\\n  Coefficient of variation: {np.std(val_aucs)/np.mean(val_aucs)*100:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}