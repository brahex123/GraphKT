{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OXYhnccdXdKY",
        "outputId": "2c04a129-683d-4311-efca-46c216e34a05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.12/dist-packages (2.7.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2026.1.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11hq0iBhW7Kb",
        "outputId": "c53d15fb-d080-4801-f4f3-a9fd62b747a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "PyTorch version: 2.9.0+cu128\n",
            "Configuration loaded successfully (M3a - Mastery as Features)\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Cell 1: Imports and Configuration\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.nn import GCNConv, RGCNConv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "from collections import defaultdict\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configuration\n",
        "class Config:\n",
        "    # Data\n",
        "    SEED = 42\n",
        "    TEST_STUDENT_RATIO = 0.15      # 15% students for TEST (Split B)\n",
        "    VAL_STUDENT_RATIO = 0.15       # 15% of TRAIN students for VAL\n",
        "\n",
        "    # Model Architecture\n",
        "    FEATURE_DIM = 5                # 5D statistical features (base for all nodes)\n",
        "    EMBED_DIM = 32\n",
        "    HIDDEN_DIM = 64\n",
        "    NUM_GNN_LAYERS = 2\n",
        "    DROPOUT = 0.2\n",
        "    NUM_BASES = 2                  # For RGCN basis decomposition\n",
        "\n",
        "    # Training\n",
        "    BATCH_SIZE = 512               # Larger batch for efficiency\n",
        "    LEARNING_RATE = 1e-3\n",
        "    WEIGHT_DECAY = 0.01\n",
        "    EPOCHS = 100\n",
        "    PATIENCE = 10\n",
        "    GRAD_CLIP = 1.0\n",
        "\n",
        "    # Mastery (M3a specific)\n",
        "    MASTERY_INIT = 0.5             # Initial mastery value [0.5 or 'global_mean']\n",
        "    LAMBDA_EMA = 0.1               # Mastery update learning rate (0.05, 0.1, 0.2)\n",
        "\n",
        "    # Device\n",
        "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "config = Config()\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "np.random.seed(config.SEED)\n",
        "torch.manual_seed(config.SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(config.SEED)\n",
        "\n",
        "print(f\"Device: {config.DEVICE}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Configuration loaded successfully (M3a - Mastery as Features)\")  # ← MODIFIÉ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "g3UDZq76XawB",
        "outputId": "0151c977-53a4-43e7-f83c-53b3aa69deb0",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "DATASET OVERVIEW\n",
            "============================================================\n",
            "Shape: (809694, 19)\n",
            "\n",
            "Columns (19):\n",
            "   1. Row\n",
            "   2. Anon Student Id\n",
            "   3. Problem Hierarchy\n",
            "   4. Problem Name\n",
            "   5. Problem View\n",
            "   6. Step Name\n",
            "   7. Step Start Time\n",
            "   8. First Transaction Time\n",
            "   9. Correct Transaction Time\n",
            "  10. Step End Time\n",
            "  11. Step Duration (sec)\n",
            "  12. Correct Step Duration (sec)\n",
            "  13. Error Step Duration (sec)\n",
            "  14. Correct First Attempt\n",
            "  15. Incorrects\n",
            "  16. Hints\n",
            "  17. Corrects\n",
            "  18. KC(Default)\n",
            "  19. Opportunity(Default)\n",
            "\n",
            "============================================================\n",
            "FIRST 3 ROWS\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Row Anon Student Id            Problem Hierarchy Problem Name  \\\n",
              "0    1      0BrbPbwCMz  Unit ES_04, Section ES_04-1    EG4-FIXED   \n",
              "1    2      0BrbPbwCMz  Unit ES_04, Section ES_04-1    EG4-FIXED   \n",
              "2    3      0BrbPbwCMz  Unit ES_04, Section ES_04-1         EG40   \n",
              "\n",
              "   Problem View    Step Name        Step Start Time First Transaction Time  \\\n",
              "0             1  3(x+2) = 15  2005-09-09 12:24:35.0  2005-09-09 12:24:49.0   \n",
              "1             1      x+2 = 5  2005-09-09 12:25:15.0  2005-09-09 12:25:31.0   \n",
              "2             1    2-8y = -4  2005-09-09 12:25:36.0  2005-09-09 12:25:43.0   \n",
              "\n",
              "  Correct Transaction Time          Step End Time  Step Duration (sec)  \\\n",
              "0    2005-09-09 12:25:15.0  2005-09-09 12:25:15.0                 40.0   \n",
              "1    2005-09-09 12:25:31.0  2005-09-09 12:25:31.0                 16.0   \n",
              "2    2005-09-09 12:26:12.0  2005-09-09 12:26:12.0                 36.0   \n",
              "\n",
              "   Correct Step Duration (sec)  Error Step Duration (sec)  \\\n",
              "0                          NaN                       40.0   \n",
              "1                         16.0                        NaN   \n",
              "2                          NaN                       36.0   \n",
              "\n",
              "   Correct First Attempt  Incorrects  Hints  Corrects  \\\n",
              "0                      0           2      3         1   \n",
              "1                      1           0      0         1   \n",
              "2                      0           2      3         1   \n",
              "\n",
              "                                         KC(Default) Opportunity(Default)  \n",
              "0  [SkillRule: Eliminate Parens; {CLT nested; CLT...                    1  \n",
              "1  [SkillRule: Remove constant; {ax+b=c, positive...                 1~~1  \n",
              "2  [SkillRule: Remove constant; {ax+b=c, positive...                    2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-39531494-8f64-4916-8b68-a93fcf8583c6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Row</th>\n",
              "      <th>Anon Student Id</th>\n",
              "      <th>Problem Hierarchy</th>\n",
              "      <th>Problem Name</th>\n",
              "      <th>Problem View</th>\n",
              "      <th>Step Name</th>\n",
              "      <th>Step Start Time</th>\n",
              "      <th>First Transaction Time</th>\n",
              "      <th>Correct Transaction Time</th>\n",
              "      <th>Step End Time</th>\n",
              "      <th>Step Duration (sec)</th>\n",
              "      <th>Correct Step Duration (sec)</th>\n",
              "      <th>Error Step Duration (sec)</th>\n",
              "      <th>Correct First Attempt</th>\n",
              "      <th>Incorrects</th>\n",
              "      <th>Hints</th>\n",
              "      <th>Corrects</th>\n",
              "      <th>KC(Default)</th>\n",
              "      <th>Opportunity(Default)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0BrbPbwCMz</td>\n",
              "      <td>Unit ES_04, Section ES_04-1</td>\n",
              "      <td>EG4-FIXED</td>\n",
              "      <td>1</td>\n",
              "      <td>3(x+2) = 15</td>\n",
              "      <td>2005-09-09 12:24:35.0</td>\n",
              "      <td>2005-09-09 12:24:49.0</td>\n",
              "      <td>2005-09-09 12:25:15.0</td>\n",
              "      <td>2005-09-09 12:25:15.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>[SkillRule: Eliminate Parens; {CLT nested; CLT...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0BrbPbwCMz</td>\n",
              "      <td>Unit ES_04, Section ES_04-1</td>\n",
              "      <td>EG4-FIXED</td>\n",
              "      <td>1</td>\n",
              "      <td>x+2 = 5</td>\n",
              "      <td>2005-09-09 12:25:15.0</td>\n",
              "      <td>2005-09-09 12:25:31.0</td>\n",
              "      <td>2005-09-09 12:25:31.0</td>\n",
              "      <td>2005-09-09 12:25:31.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[SkillRule: Remove constant; {ax+b=c, positive...</td>\n",
              "      <td>1~~1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0BrbPbwCMz</td>\n",
              "      <td>Unit ES_04, Section ES_04-1</td>\n",
              "      <td>EG40</td>\n",
              "      <td>1</td>\n",
              "      <td>2-8y = -4</td>\n",
              "      <td>2005-09-09 12:25:36.0</td>\n",
              "      <td>2005-09-09 12:25:43.0</td>\n",
              "      <td>2005-09-09 12:26:12.0</td>\n",
              "      <td>2005-09-09 12:26:12.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>[SkillRule: Remove constant; {ax+b=c, positive...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39531494-8f64-4916-8b68-a93fcf8583c6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-39531494-8f64-4916-8b68-a93fcf8583c6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-39531494-8f64-4916-8b68-a93fcf8583c6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(df_raw['Correct First Attempt']\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Row\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Anon Student Id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"0BrbPbwCMz\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Problem Hierarchy\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Unit ES_04, Section ES_04-1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Problem Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"EG40\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Problem View\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Step Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"3(x+2) = 15\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Step Start Time\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"2005-09-09 12:24:35.0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"First Transaction Time\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"2005-09-09 12:24:49.0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Correct Transaction Time\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"2005-09-09 12:25:15.0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Step End Time\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"2005-09-09 12:25:15.0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Step Duration (sec)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.858201014657274,\n        \"min\": 16.0,\n        \"max\": 40.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          40.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Correct Step Duration (sec)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 16.0,\n        \"max\": 16.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          16.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Error Step Duration (sec)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.8284271247461903,\n        \"min\": 36.0,\n        \"max\": 40.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          36.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Correct First Attempt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Incorrects\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hints\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Corrects\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"KC(Default)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"[SkillRule: Eliminate Parens; {CLT nested; CLT nested, parens; Distribute Mult right; Distribute Mult left; (+/-x +/-a)/b=c, mult; (+/-x +/-a)*b=c, div; [var expr]/[const expr] = [const expr], multiply; Distribute Division left; Distribute Division right; Distribute both mult left; Distribute both mult right; Distribute both divide left; Distribute both divide right; Distribute subex}]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Opportunity(Default)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "DATA TYPES\n",
            "============================================================\n",
            "Row                              int64\n",
            "Anon Student Id                 object\n",
            "Problem Hierarchy               object\n",
            "Problem Name                    object\n",
            "Problem View                     int64\n",
            "Step Name                       object\n",
            "Step Start Time                 object\n",
            "First Transaction Time          object\n",
            "Correct Transaction Time        object\n",
            "Step End Time                   object\n",
            "Step Duration (sec)            float64\n",
            "Correct Step Duration (sec)    float64\n",
            "Error Step Duration (sec)      float64\n",
            "Correct First Attempt            int64\n",
            "Incorrects                       int64\n",
            "Hints                            int64\n",
            "Corrects                         int64\n",
            "KC(Default)                     object\n",
            "Opportunity(Default)            object\n",
            "dtype: object\n",
            "\n",
            "============================================================\n",
            "MISSING VALUES\n",
            "============================================================\n",
            "                             Missing  Percent\n",
            "Step Start Time                  919     0.11\n",
            "Correct Transaction Time       25851     3.19\n",
            "Step Duration (sec)              919     0.11\n",
            "Correct Step Duration (sec)   189565    23.41\n",
            "Error Step Duration (sec)     621048    76.70\n",
            "KC(Default)                   202669    25.03\n",
            "Opportunity(Default)          202669    25.03\n",
            "\n",
            "============================================================\n",
            "KEY STATISTICS\n",
            "============================================================\n",
            "Total interactions: 809,694\n",
            "Unique students: 574\n",
            "Unique problems (questions): 1,084\n",
            "Unique steps: 210,710\n",
            "Unique KC(Default): 436\n",
            "KC(Default) missing: 202,669 (25.03%)\n",
            "\n",
            "============================================================\n",
            "TARGET DISTRIBUTION (Correct First Attempt)\n",
            "============================================================\n",
            "Correct First Attempt\n",
            "1    0.7665\n",
            "0    0.2335\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Cell 2: Load and Explore Dataset\n",
        "# =============================================================================\n",
        "\n",
        "# Load the Algebra 2005-2006 dataset\n",
        "DATA_PATH = \"algebra_2005_2006_train.txt\"\n",
        "\n",
        "# Load with tab separator (standard format for this dataset)\n",
        "df_raw = pd.read_csv(DATA_PATH, sep='\\t', low_memory=False)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"DATASET OVERVIEW\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Shape: {df_raw.shape}\")\n",
        "print(f\"\\nColumns ({len(df_raw.columns)}):\")\n",
        "for i, col in enumerate(df_raw.columns):\n",
        "    print(f\"  {i+1:2d}. {col}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"FIRST 3 ROWS\")\n",
        "print(\"=\" * 60)\n",
        "display(df_raw.head(3))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"DATA TYPES\")\n",
        "print(\"=\" * 60)\n",
        "print(df_raw.dtypes)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"MISSING VALUES\")\n",
        "print(\"=\" * 60)\n",
        "missing = df_raw.isnull().sum()\n",
        "missing_pct = (missing / len(df_raw) * 100).round(2)\n",
        "missing_df = pd.DataFrame({'Missing': missing, 'Percent': missing_pct})\n",
        "print(missing_df[missing_df['Missing'] > 0])\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"KEY STATISTICS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Total interactions: {len(df_raw):,}\")\n",
        "print(f\"Unique students: {df_raw['Anon Student Id'].nunique():,}\")\n",
        "print(f\"Unique problems (questions): {df_raw['Problem Name'].nunique():,}\")\n",
        "print(f\"Unique steps: {df_raw[['Problem Name', 'Step Name']].drop_duplicates().shape[0]:,}\")\n",
        "print(f\"Unique KC(Default): {df_raw['KC(Default)'].nunique():,}\")\n",
        "print(f\"KC(Default) missing: {df_raw['KC(Default)'].isnull().sum():,} ({df_raw['KC(Default)'].isnull().mean()*100:.2f}%)\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TARGET DISTRIBUTION (Correct First Attempt)\")\n",
        "print(\"=\" * 60)\n",
        "print(df_raw['Correct First Attempt'].value_counts(normalize=True).round(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "id": "4X0IrVL6X5Du",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f9ed6705-df48-4572-e22d-df945915a0e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "STEP 1: Drop rows with missing critical fields (NOT KC)\n",
            "============================================================\n",
            "Dropped 0 rows (0.00%)\n",
            "Remaining: 809,694 rows\n",
            "\n",
            "============================================================\n",
            "STEP 2: Handle missing KC(Default)\n",
            "============================================================\n",
            "Missing KC(Default): 202,669 (25.03%)\n",
            "Filled with 'UNKNOWN_KC' token\n",
            "\n",
            "============================================================\n",
            "STEP 3: Create canonical identifiers\n",
            "============================================================\n",
            "Unique students: 574\n",
            "Unique questions: 1,084\n",
            "Unique steps: 210,710\n",
            "Unique KCs (including UNKNOWN): 437\n",
            "\n",
            "============================================================\n",
            "STEP 4: Parse timestamps and create temporal ordering\n",
            "============================================================\n",
            "Rows with missing timestamp after fallback: 0\n",
            "Final dataset size: 809,694 rows\n",
            "\n",
            "============================================================\n",
            "STEP 5: Process behavioral features\n",
            "============================================================\n",
            "Median duration: 11.00 sec\n",
            "Log duration range: [0.00, 7.90]\n",
            "\n",
            "============================================================\n",
            "STEP 6: Final dataset summary\n",
            "============================================================\n",
            "Total interactions: 809,694\n",
            "Unique students: 574\n",
            "Unique questions: 1,084\n",
            "Unique steps: 210,710\n",
            "Unique KCs: 437\n",
            "  - Real KCs: 607,025 interactions\n",
            "  - UNKNOWN_KC: 202,669 interactions\n",
            "\n",
            "Target distribution:\n",
            "correct\n",
            "1    0.7665\n",
            "0    0.2335\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "============================================================\n",
            "STEP 7: Verify temporal ordering\n",
            "============================================================\n",
            "Sample student '02ZjVTxC34' first 5 interactions:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   time_idx           timestamp question_id  \\\n",
              "0         0 2005-09-06 13:00:23  LDEMO_WKST   \n",
              "1         1 2005-09-06 13:00:44  LDEMO_WKST   \n",
              "2         2 2005-09-06 13:01:12  LDEMO_WKST   \n",
              "3         3 2005-09-06 13:01:46  LDEMO_WKST   \n",
              "4         4 2005-09-06 13:02:27  LDEMO_WKST   \n",
              "\n",
              "                                        kc_id  correct  \n",
              "0                                  UNKNOWN_KC        1  \n",
              "1                           Identifying units        1  \n",
              "2                                  UNKNOWN_KC        1  \n",
              "3                           Identifying units        1  \n",
              "4  Entering a given~~Convert unit, multiplier        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c34cc5c2-c9e0-41e4-ba84-11b953e826e2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time_idx</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>question_id</th>\n",
              "      <th>kc_id</th>\n",
              "      <th>correct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2005-09-06 13:00:23</td>\n",
              "      <td>LDEMO_WKST</td>\n",
              "      <td>UNKNOWN_KC</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2005-09-06 13:00:44</td>\n",
              "      <td>LDEMO_WKST</td>\n",
              "      <td>Identifying units</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2005-09-06 13:01:12</td>\n",
              "      <td>LDEMO_WKST</td>\n",
              "      <td>UNKNOWN_KC</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2005-09-06 13:01:46</td>\n",
              "      <td>LDEMO_WKST</td>\n",
              "      <td>Identifying units</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2005-09-06 13:02:27</td>\n",
              "      <td>LDEMO_WKST</td>\n",
              "      <td>Entering a given~~Convert unit, multiplier</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c34cc5c2-c9e0-41e4-ba84-11b953e826e2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c34cc5c2-c9e0-41e4-ba84-11b953e826e2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c34cc5c2-c9e0-41e4-ba84-11b953e826e2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_65cf35f6-8e1f-4579-9160-38c4509b3510\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('sample_seq')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_65cf35f6-8e1f-4579-9160-38c4509b3510 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('sample_seq');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "sample_seq",
              "summary": "{\n  \"name\": \"sample_seq\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"time_idx\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2005-09-06 13:00:23\",\n        \"max\": \"2005-09-06 13:02:27\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2005-09-06 13:00:44\",\n          \"2005-09-06 13:02:27\",\n          \"2005-09-06 13:01:12\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"LDEMO_WKST\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"kc_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"UNKNOWN_KC\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"correct\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Cell 3 (Corrected): Data Cleaning - Keep Missing KC as UNKNOWN\n",
        "# =============================================================================\n",
        "\n",
        "# Start with a copy\n",
        "df = df_raw.copy()\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"STEP 1: Drop rows with missing critical fields (NOT KC)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Critical fields: student, step, target (NOT KC - we'll handle separately)\n",
        "critical_cols = ['Anon Student Id', 'Problem Name', 'Step Name', 'Correct First Attempt']\n",
        "before_drop = len(df)\n",
        "df = df.dropna(subset=critical_cols)\n",
        "after_drop = len(df)\n",
        "print(f\"Dropped {before_drop - after_drop:,} rows ({(before_drop - after_drop)/before_drop*100:.2f}%)\")\n",
        "print(f\"Remaining: {after_drop:,} rows\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 2: Handle missing KC(Default)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "kc_missing_before = df['KC(Default)'].isnull().sum()\n",
        "print(f\"Missing KC(Default): {kc_missing_before:,} ({kc_missing_before/len(df)*100:.2f}%)\")\n",
        "\n",
        "# Fill missing KC with special token\n",
        "df['KC(Default)'] = df['KC(Default)'].fillna('UNKNOWN_KC')\n",
        "print(f\"Filled with 'UNKNOWN_KC' token\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 3: Create canonical identifiers\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Student ID\n",
        "df['student_id'] = df['Anon Student Id'].astype(str).str.strip()\n",
        "\n",
        "# Question ID (Problem Name)\n",
        "df['question_id'] = df['Problem Name'].astype(str).str.strip()\n",
        "\n",
        "# Step ID (Problem Name + Step Name)\n",
        "df['step_id'] = df['Problem Name'].astype(str).str.strip() + \"||\" + df['Step Name'].astype(str).str.strip()\n",
        "\n",
        "# KC ID (KC(Default) as composite string)\n",
        "df['kc_id'] = df['KC(Default)'].astype(str).str.strip()\n",
        "\n",
        "# Target\n",
        "df['correct'] = df['Correct First Attempt'].astype(int)\n",
        "\n",
        "print(f\"Unique students: {df['student_id'].nunique():,}\")\n",
        "print(f\"Unique questions: {df['question_id'].nunique():,}\")\n",
        "print(f\"Unique steps: {df['step_id'].nunique():,}\")\n",
        "print(f\"Unique KCs (including UNKNOWN): {df['kc_id'].nunique():,}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 4: Parse timestamps and create temporal ordering\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Parse First Transaction Time (primary timestamp)\n",
        "df['timestamp'] = pd.to_datetime(df['First Transaction Time'], errors='coerce')\n",
        "\n",
        "# Fallback to Step Start Time\n",
        "mask_missing_ts = df['timestamp'].isnull()\n",
        "df.loc[mask_missing_ts, 'timestamp'] = pd.to_datetime(\n",
        "    df.loc[mask_missing_ts, 'Step Start Time'], errors='coerce'\n",
        ")\n",
        "\n",
        "# Check remaining missing timestamps\n",
        "ts_missing = df['timestamp'].isnull().sum()\n",
        "print(f\"Rows with missing timestamp after fallback: {ts_missing}\")\n",
        "\n",
        "if ts_missing > 0:\n",
        "    # Drop only these (should be minimal)\n",
        "    df = df.dropna(subset=['timestamp'])\n",
        "    print(f\"Dropped {ts_missing} rows with no valid timestamp\")\n",
        "\n",
        "# Sort by student and timestamp\n",
        "df = df.sort_values(['student_id', 'timestamp']).reset_index(drop=True)\n",
        "\n",
        "# Create time index within each student\n",
        "df['time_idx'] = df.groupby('student_id').cumcount()\n",
        "\n",
        "print(f\"Final dataset size: {len(df):,} rows\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 5: Process behavioral features\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Fill missing durations with median\n",
        "duration_col = 'Step Duration (sec)'\n",
        "median_duration = df[duration_col].median()\n",
        "df[duration_col] = df[duration_col].fillna(median_duration)\n",
        "\n",
        "# Log transform duration\n",
        "df['log_duration'] = np.log1p(df[duration_col].clip(lower=0))\n",
        "\n",
        "# Clip extreme values\n",
        "df['Incorrects'] = df['Incorrects'].clip(upper=10)\n",
        "df['Hints'] = df['Hints'].clip(upper=10)\n",
        "\n",
        "print(f\"Median duration: {median_duration:.2f} sec\")\n",
        "print(f\"Log duration range: [{df['log_duration'].min():.2f}, {df['log_duration'].max():.2f}]\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 6: Final dataset summary\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"Total interactions: {len(df):,}\")\n",
        "print(f\"Unique students: {df['student_id'].nunique():,}\")\n",
        "print(f\"Unique questions: {df['question_id'].nunique():,}\")\n",
        "print(f\"Unique steps: {df['step_id'].nunique():,}\")\n",
        "print(f\"Unique KCs: {df['kc_id'].nunique():,}\")\n",
        "print(f\"  - Real KCs: {(df['kc_id'] != 'UNKNOWN_KC').sum():,} interactions\")\n",
        "print(f\"  - UNKNOWN_KC: {(df['kc_id'] == 'UNKNOWN_KC').sum():,} interactions\")\n",
        "\n",
        "print(f\"\\nTarget distribution:\")\n",
        "print(df['correct'].value_counts(normalize=True).round(4))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 7: Verify temporal ordering\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "sample_student = df['student_id'].iloc[0]\n",
        "sample_seq = df[df['student_id'] == sample_student][['time_idx', 'timestamp', 'question_id', 'kc_id', 'correct']].head(5)\n",
        "print(f\"Sample student '{sample_student}' first 5 interactions:\")\n",
        "display(sample_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LvLbzcxFo-pm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "1c4d2860-ebd4-43b7-e6a0-1388a20544ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "STEP 1: SEPARATE TEST STUDENTS (HELD OUT ENTIRELY)\n",
            "============================================================\n",
            "Total students: 574\n",
            "\n",
            "TEST set (held out):\n",
            "  Students: 87 (15.2%)\n",
            "  Interactions: 118,261\n",
            "\n",
            "Non-test (enters K-Fold CV):\n",
            "  Students: 487 (84.8%)\n",
            "  Interactions: 691,433\n",
            "\n",
            "============================================================\n",
            "STEP 2: DEFINE 5-FOLD STUDENT-LEVEL SPLITS\n",
            "============================================================\n",
            "\n",
            "Fold 1:\n",
            "  TRAIN: 389 students\n",
            "  VAL:   98 students\n",
            "\n",
            "Fold 2:\n",
            "  TRAIN: 389 students\n",
            "  VAL:   98 students\n",
            "\n",
            "Fold 3:\n",
            "  TRAIN: 390 students\n",
            "  VAL:   97 students\n",
            "\n",
            "Fold 4:\n",
            "  TRAIN: 390 students\n",
            "  VAL:   97 students\n",
            "\n",
            "Fold 5:\n",
            "  TRAIN: 390 students\n",
            "  VAL:   97 students\n",
            "\n",
            "✓ All folds verified: no student overlap, no test leakage\n",
            "✓ TEST set (87 students) completely isolated\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Cell 4: Separate TEST Set + 5-Fold Student-Level CV Setup\n",
        "# =============================================================================\n",
        "\n",
        "import time\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from collections import defaultdict\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"STEP 1: SEPARATE TEST STUDENTS (HELD OUT ENTIRELY)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "all_students = df['student_id'].unique()\n",
        "n_students = len(all_students)\n",
        "print(f\"Total students: {n_students}\")\n",
        "\n",
        "# Hold out 15% of students as TEST - NEVER touched during CV\n",
        "non_test_students, test_students = train_test_split(\n",
        "    all_students,\n",
        "    test_size=config.TEST_STUDENT_RATIO,\n",
        "    random_state=config.SEED\n",
        ")\n",
        "\n",
        "df_test_final = df[df['student_id'].isin(test_students)].copy()\n",
        "df_non_test = df[df['student_id'].isin(non_test_students)].copy()\n",
        "\n",
        "print(f\"\\nTEST set (held out):\")\n",
        "print(f\"  Students: {len(test_students)} ({len(test_students)/n_students*100:.1f}%)\")\n",
        "print(f\"  Interactions: {len(df_test_final):,}\")\n",
        "\n",
        "print(f\"\\nNon-test (enters K-Fold CV):\")\n",
        "print(f\"  Students: {len(non_test_students)} ({len(non_test_students)/n_students*100:.1f}%)\")\n",
        "print(f\"  Interactions: {len(df_non_test):,}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 2: DEFINE 5-FOLD STUDENT-LEVEL SPLITS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=config.SEED)\n",
        "\n",
        "fold_assignments = {}\n",
        "for fold_idx, (train_indices, val_indices) in enumerate(kf.split(non_test_students)):\n",
        "    train_studs = non_test_students[train_indices]\n",
        "    val_studs = non_test_students[val_indices]\n",
        "    fold_assignments[fold_idx] = {\n",
        "        'train_students': train_studs,\n",
        "        'val_students': val_studs\n",
        "    }\n",
        "    print(f\"\\nFold {fold_idx+1}:\")\n",
        "    print(f\"  TRAIN: {len(train_studs)} students\")\n",
        "    print(f\"  VAL:   {len(val_studs)} students\")\n",
        "\n",
        "    # Verify no overlap\n",
        "    overlap = set(train_studs) & set(val_studs)\n",
        "    assert len(overlap) == 0, f\"LEAK in fold {fold_idx+1}!\"\n",
        "\n",
        "    # Verify no test leakage\n",
        "    test_leak = set(train_studs) & set(test_students)\n",
        "    assert len(test_leak) == 0, f\"TEST LEAK in fold {fold_idx+1}!\"\n",
        "\n",
        "print(\"\\n✓ All folds verified: no student overlap, no test leakage\")\n",
        "print(f\"✓ TEST set ({len(test_students)} students) completely isolated\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fiDbwzUto-pm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "c1774e8d-ba53-4f36-9fa1-5170f85962c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "✓ ALL PIPELINE FUNCTIONS DEFINED (M3a VERSION)\n",
            "============================================================\n",
            "  - build_entity_mappings()\n",
            "  - build_graph()\n",
            "  - compute_node_features()\n",
            "  - compute_node_features_with_mastery() [NEW]\n",
            "  - RGCNWithMasteryFeatures (Mastery as Features)\n",
            "  - KTDatasetPure\n",
            "  - train_epoch() / evaluate()\n",
            "  - run_single_fold() [MODIFIED for M3a]\n",
            "============================================================\n",
            "Ready for 5-Fold Cross-Validation! 🚀\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Cell 5: Complete Pipeline Functions (Reusable Per Fold) — M3a\n",
        "# =============================================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.nn import GCNConv, RGCNConv\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "from collections import defaultdict\n",
        "import time\n",
        "\n",
        "NUM_FEATURES = 5\n",
        "\n",
        "# ============================================================\n",
        "# FUNCTION 1: Build Entity Mappings (UNCHANGED)\n",
        "# ============================================================\n",
        "def build_entity_mappings(df_train):\n",
        "    train_students = sorted(df_train['student_id'].unique())\n",
        "    train_questions = sorted(df_train['question_id'].unique())\n",
        "    train_steps = sorted(df_train['step_id'].unique())\n",
        "    train_kcs = sorted(df_train['kc_id'].unique())\n",
        "\n",
        "    stu2idx = {s: i for i, s in enumerate(train_students)}\n",
        "    q2idx = {q: i for i, q in enumerate(train_questions)}\n",
        "    t2idx = {t: i for i, t in enumerate(train_steps)}\n",
        "    c2idx = {c: i for i, c in enumerate(train_kcs)}\n",
        "\n",
        "    unk_indices = {\n",
        "        'student': len(train_students),\n",
        "        'question': len(train_questions),\n",
        "        'step': len(train_steps),\n",
        "        'kc': len(train_kcs)\n",
        "    }\n",
        "\n",
        "    entity_counts = {\n",
        "        'num_students': len(train_students) + 1,\n",
        "        'num_questions': len(train_questions) + 1,\n",
        "        'num_steps': len(train_steps) + 1,\n",
        "        'num_kcs': len(train_kcs) + 1,\n",
        "    }\n",
        "\n",
        "    mappings = {\n",
        "        'stu2idx': stu2idx, 'q2idx': q2idx,\n",
        "        't2idx': t2idx, 'c2idx': c2idx\n",
        "    }\n",
        "\n",
        "    return mappings, entity_counts, unk_indices\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# FUNCTION 2: Build Heterogeneous Graph (UNCHANGED)\n",
        "# ============================================================\n",
        "def build_graph(df_train, mappings, entity_counts, unk_indices):\n",
        "    stu2idx = mappings['stu2idx']\n",
        "    q2idx = mappings['q2idx']\n",
        "    t2idx = mappings['t2idx']\n",
        "    c2idx = mappings['c2idx']\n",
        "\n",
        "    data = HeteroData()\n",
        "\n",
        "    data['student'].num_nodes = entity_counts['num_students']\n",
        "    data['question'].num_nodes = entity_counts['num_questions']\n",
        "    data['step'].num_nodes = entity_counts['num_steps']\n",
        "    data['kc'].num_nodes = entity_counts['num_kcs']\n",
        "\n",
        "    qt_pairs = df_train[['question_id', 'step_id']].drop_duplicates()\n",
        "    q_idx_list = [q2idx[r['question_id']] for _, r in qt_pairs.iterrows()]\n",
        "    t_idx_list = [t2idx[r['step_id']] for _, r in qt_pairs.iterrows()]\n",
        "\n",
        "    data['question', 'contains', 'step'].edge_index = torch.tensor([q_idx_list, t_idx_list], dtype=torch.long)\n",
        "    data['step', 'belongs_to', 'question'].edge_index = torch.tensor([t_idx_list, q_idx_list], dtype=torch.long)\n",
        "\n",
        "    tc_pairs = df_train[['step_id', 'kc_id']].drop_duplicates()\n",
        "    t_idx_list2 = [t2idx[r['step_id']] for _, r in tc_pairs.iterrows()]\n",
        "    c_idx_list = [c2idx[r['kc_id']] for _, r in tc_pairs.iterrows()]\n",
        "\n",
        "    data['step', 'requires', 'kc'].edge_index = torch.tensor([t_idx_list2, c_idx_list], dtype=torch.long)\n",
        "    data['kc', 'required_by', 'step'].edge_index = torch.tensor([c_idx_list, t_idx_list2], dtype=torch.long)\n",
        "\n",
        "    sq_pairs = df_train[['student_id', 'question_id']].drop_duplicates()\n",
        "    s_idx_list = [stu2idx[r['student_id']] for _, r in sq_pairs.iterrows()]\n",
        "    q_idx_list2 = [q2idx[r['question_id']] for _, r in sq_pairs.iterrows()]\n",
        "\n",
        "    data['student', 'attempted', 'question'].edge_index = torch.tensor([s_idx_list, q_idx_list2], dtype=torch.long)\n",
        "    data['question', 'attempted_by', 'student'].edge_index = torch.tensor([q_idx_list2, s_idx_list], dtype=torch.long)\n",
        "\n",
        "    total_edges = sum(\n",
        "        data[et].edge_index.shape[1]\n",
        "        for et in data.edge_types\n",
        "    )\n",
        "\n",
        "    return data, total_edges\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# FUNCTION 3: Compute Node Features (Base 5D)\n",
        "# ============================================================\n",
        "def compute_node_features(df_train, mappings, entity_counts, unk_indices):\n",
        "    \"\"\"Compute 5D features for all entities (WITHOUT mastery)\"\"\"\n",
        "    def compute_features_for_type(df, entity_col):\n",
        "        grouped = df.groupby(entity_col).agg({\n",
        "            'correct': ['count', 'mean'],\n",
        "            'log_duration': 'mean',\n",
        "            'Hints': 'mean',\n",
        "            'Incorrects': 'mean'\n",
        "        })\n",
        "        grouped.columns = ['freq', 'correct_rate', 'avg_log_dur', 'avg_hints', 'avg_incorrects']\n",
        "        grouped = grouped.reset_index()\n",
        "        grouped['difficulty'] = 1 - grouped['correct_rate']\n",
        "        grouped['log_freq'] = np.log1p(grouped['freq'])\n",
        "\n",
        "        features = {}\n",
        "        feat_cols = ['log_freq', 'difficulty', 'avg_log_dur', 'avg_hints', 'avg_incorrects']\n",
        "        for _, row in grouped.iterrows():\n",
        "            features[row[entity_col]] = row[feat_cols].values.astype(np.float32)\n",
        "        return features\n",
        "\n",
        "    def to_tensor(features_dict, idx_map, num_with_unk, unk_idx):\n",
        "        tensor = torch.zeros(num_with_unk, NUM_FEATURES, dtype=torch.float32)\n",
        "        all_feats = []\n",
        "        for entity_id, idx in idx_map.items():\n",
        "            if entity_id in features_dict:\n",
        "                tensor[idx] = torch.tensor(features_dict[entity_id])\n",
        "                all_feats.append(features_dict[entity_id])\n",
        "        if all_feats:\n",
        "            tensor[unk_idx] = torch.tensor(np.mean(all_feats, axis=0))\n",
        "        return tensor\n",
        "\n",
        "    def normalize(tensor):\n",
        "        mean = tensor.mean(dim=0, keepdim=True)\n",
        "        std = tensor.std(dim=0, keepdim=True) + 1e-8\n",
        "        return (tensor - mean) / std\n",
        "\n",
        "    stu_feats = compute_features_for_type(df_train, 'student_id')\n",
        "    q_feats = compute_features_for_type(df_train, 'question_id')\n",
        "    t_feats = compute_features_for_type(df_train, 'step_id')\n",
        "    c_feats = compute_features_for_type(df_train, 'kc_id')\n",
        "\n",
        "    feat_tensors = {\n",
        "        'student': normalize(to_tensor(stu_feats, mappings['stu2idx'], entity_counts['num_students'], unk_indices['student'])),\n",
        "        'question': normalize(to_tensor(q_feats, mappings['q2idx'], entity_counts['num_questions'], unk_indices['question'])),\n",
        "        'step': normalize(to_tensor(t_feats, mappings['t2idx'], entity_counts['num_steps'], unk_indices['step'])),\n",
        "        'kc': normalize(to_tensor(c_feats, mappings['c2idx'], entity_counts['num_kcs'], unk_indices['kc'])),\n",
        "    }\n",
        "\n",
        "    return feat_tensors\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 🆕 FUNCTION 3b: Compute Features WITH Mastery for Students\n",
        "# ============================================================\n",
        "def compute_node_features_with_mastery(df_train, mappings, entity_counts, unk_indices, mastery_matrix):\n",
        "    \"\"\"\n",
        "    Compute features WITH mastery for students\n",
        "    Students: [5D_stats + num_kcs mastery values]\n",
        "    Others: [5D_stats] (unchanged)\n",
        "    \"\"\"\n",
        "    # Get base 5D features\n",
        "    base_features = compute_node_features(df_train, mappings, entity_counts, unk_indices)\n",
        "\n",
        "    # For students: concatenate 5D + mastery\n",
        "    student_features_5d = base_features['student']  # [num_students, 5]\n",
        "\n",
        "    # Concatenate with mastery matrix\n",
        "    student_features_with_mastery = torch.cat([\n",
        "        student_features_5d,\n",
        "        mastery_matrix  # [num_students, num_kcs]\n",
        "    ], dim=-1)\n",
        "    # Shape: [num_students, 5 + num_kcs]\n",
        "\n",
        "    return {\n",
        "        'student': student_features_with_mastery,  # [num_students, 5 + num_kcs]\n",
        "        'question': base_features['question'],      # [num_questions, 5]\n",
        "        'step': base_features['step'],              # [num_steps, 5]\n",
        "        'kc': base_features['kc'],                  # [num_kcs, 5]\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# FUNCTION 4: Model Components\n",
        "# ============================================================\n",
        "\n",
        "class NodeEncoder(nn.Module):\n",
        "    \"\"\"Encode node features to embedding space\"\"\"\n",
        "    def __init__(self, input_dim, embed_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, embed_dim),\n",
        "            nn.LayerNorm(embed_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(embed_dim, embed_dim),\n",
        "            nn.LayerNorm(embed_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.encoder(x)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 🆕 MODEL: M3a - RGCN with Mastery as Features\n",
        "# ============================================================\n",
        "\n",
        "class RGCNWithMasteryFeatures(nn.Module):\n",
        "    \"\"\"\n",
        "    M3a: RGCN with mastery as student features\n",
        "    - Single RGCN (like M2) on full graph (S,Q,T,C)\n",
        "    - Students have mastery features concatenated\n",
        "    - 6 relations (S↔Q, Q↔T, T↔C)\n",
        "    \"\"\"\n",
        "\n",
        "    NUM_RELATIONS = 6  # Like M2\n",
        "\n",
        "    def __init__(self, num_students, num_questions, num_steps, num_kcs,\n",
        "                 feature_dim_base=5, embed_dim=32, hidden_dim=64,\n",
        "                 num_gnn_layers=2, dropout=0.2,\n",
        "                 mastery_init=0.5):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_students = num_students\n",
        "        self.num_questions = num_questions\n",
        "        self.num_steps = num_steps\n",
        "        self.num_kcs = num_kcs\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "        # Global offsets (like M2)\n",
        "        self.student_offset = 0\n",
        "        self.question_offset = num_students\n",
        "        self.step_offset = num_students + num_questions\n",
        "        self.kc_offset = num_students + num_questions + num_steps\n",
        "\n",
        "        # === Node Encoders ===\n",
        "        # Students: 5 + num_kcs features\n",
        "        self.student_encoder = NodeEncoder(\n",
        "            feature_dim_base + num_kcs,  # ← Mastery as features\n",
        "            embed_dim,\n",
        "            dropout\n",
        "        )\n",
        "        # Others: 5 features\n",
        "        self.question_encoder = NodeEncoder(feature_dim_base, embed_dim, dropout)\n",
        "        self.step_encoder = NodeEncoder(feature_dim_base, embed_dim, dropout)\n",
        "        self.kc_encoder = NodeEncoder(feature_dim_base, embed_dim, dropout)\n",
        "\n",
        "        # === SINGLE RGCN (6 relations like M2) ===\n",
        "        self.gnn_layers = nn.ModuleList([\n",
        "            RGCNConv(\n",
        "                embed_dim, embed_dim,\n",
        "                num_relations=self.NUM_RELATIONS,\n",
        "                num_bases=2\n",
        "            )\n",
        "            for _ in range(num_gnn_layers)\n",
        "        ])\n",
        "        self.gnn_norms = nn.ModuleList([\n",
        "            nn.LayerNorm(embed_dim) for _ in range(num_gnn_layers)\n",
        "        ])\n",
        "        self.gnn_dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # === Prediction Head ===\n",
        "        pred_input_dim = embed_dim * 3  # [h_s, h_t, h_c]\n",
        "        self.prediction_head = nn.Sequential(\n",
        "            nn.Linear(pred_input_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim // 2, 1)\n",
        "        )\n",
        "\n",
        "        # === Mastery Matrix ===\n",
        "        self.mastery_init = mastery_init\n",
        "        self.register_buffer('mastery_matrix', None)\n",
        "\n",
        "        # Cache\n",
        "        self._cached_edge_index = None\n",
        "        self._cached_edge_type = None\n",
        "\n",
        "    def init_mastery_matrix(self, device):\n",
        "        \"\"\"Initialize mastery matrix\"\"\"\n",
        "        self.mastery_matrix = torch.full(\n",
        "            (self.num_students, self.num_kcs),\n",
        "            self.mastery_init,\n",
        "            dtype=torch.float32,\n",
        "            device=device\n",
        "        )\n",
        "        print(f\"  ✓ Mastery matrix initialized: [{self.num_students}, {self.num_kcs}] with value={self.mastery_init}\")\n",
        "\n",
        "    def _build_edge_index(self, hetero_data, device):\n",
        "        \"\"\"Build unified edge_index for all 6 relations (like M2)\"\"\"\n",
        "        if self._cached_edge_index is not None:\n",
        "            return self._cached_edge_index, self._cached_edge_type\n",
        "\n",
        "        all_edges = []\n",
        "        all_types = []\n",
        "\n",
        "        # Relation 0: Q → T\n",
        "        q_t = hetero_data['question', 'contains', 'step'].edge_index.clone()\n",
        "        q_t[0] += self.question_offset\n",
        "        q_t[1] += self.step_offset\n",
        "        all_edges.append(q_t)\n",
        "        all_types.append(torch.zeros(q_t.size(1), dtype=torch.long))\n",
        "\n",
        "        # Relation 1: T → Q\n",
        "        t_q = hetero_data['step', 'belongs_to', 'question'].edge_index.clone()\n",
        "        t_q[0] += self.step_offset\n",
        "        t_q[1] += self.question_offset\n",
        "        all_edges.append(t_q)\n",
        "        all_types.append(torch.ones(t_q.size(1), dtype=torch.long))\n",
        "\n",
        "        # Relation 2: T → C\n",
        "        t_c = hetero_data['step', 'requires', 'kc'].edge_index.clone()\n",
        "        t_c[0] += self.step_offset\n",
        "        t_c[1] += self.kc_offset\n",
        "        all_edges.append(t_c)\n",
        "        all_types.append(torch.full((t_c.size(1),), 2, dtype=torch.long))\n",
        "\n",
        "        # Relation 3: C → T\n",
        "        c_t = hetero_data['kc', 'required_by', 'step'].edge_index.clone()\n",
        "        c_t[0] += self.kc_offset\n",
        "        c_t[1] += self.step_offset\n",
        "        all_edges.append(c_t)\n",
        "        all_types.append(torch.full((c_t.size(1),), 3, dtype=torch.long))\n",
        "\n",
        "        # Relation 4: S → Q\n",
        "        s_q = hetero_data['student', 'attempted', 'question'].edge_index.clone()\n",
        "        s_q[1] += self.question_offset\n",
        "        all_edges.append(s_q)\n",
        "        all_types.append(torch.full((s_q.size(1),), 4, dtype=torch.long))\n",
        "\n",
        "        # Relation 5: Q → S\n",
        "        q_s = hetero_data['question', 'attempted_by', 'student'].edge_index.clone()\n",
        "        q_s[0] += self.question_offset\n",
        "        all_edges.append(q_s)\n",
        "        all_types.append(torch.full((q_s.size(1),), 5, dtype=torch.long))\n",
        "\n",
        "        self._cached_edge_index = torch.cat(all_edges, dim=1).to(device)\n",
        "        self._cached_edge_type = torch.cat(all_types, dim=0).to(device)\n",
        "\n",
        "        return self._cached_edge_index, self._cached_edge_type\n",
        "\n",
        "    def forward(self, hetero_data, student_idx, step_idx, kc_idx, device):\n",
        "        \"\"\"\n",
        "        Forward pass: Simple RGCN (like M2)\n",
        "        Mastery is in student features\n",
        "        \"\"\"\n",
        "        # === 1. Encode Nodes ===\n",
        "        h_s = self.student_encoder(hetero_data['student'].x.to(device))\n",
        "        h_q = self.question_encoder(hetero_data['question'].x.to(device))\n",
        "        h_t = self.step_encoder(hetero_data['step'].x.to(device))\n",
        "        h_c = self.kc_encoder(hetero_data['kc'].x.to(device))\n",
        "\n",
        "        # === 2. Unified RGCN ===\n",
        "        H = torch.cat([h_s, h_q, h_t, h_c], dim=0)\n",
        "        edge_index, edge_type = self._build_edge_index(hetero_data, device)\n",
        "\n",
        "        for layer, norm in zip(self.gnn_layers, self.gnn_norms):\n",
        "            H_new = layer(H, edge_index, edge_type)\n",
        "            H_new = norm(H_new)\n",
        "            H_new = F.relu(H_new)\n",
        "            H_new = self.gnn_dropout(H_new)\n",
        "            H = H + H_new  # Residual\n",
        "\n",
        "        # === 3. Extract embeddings ===\n",
        "        h_s = H[:self.num_students]\n",
        "        h_t_start = self.question_offset + self.num_questions\n",
        "        h_t_end = h_t_start + self.num_steps\n",
        "        h_t = H[h_t_start:h_t_end]\n",
        "        h_c = H[self.kc_offset:]\n",
        "\n",
        "        # === 4. Batch select ===\n",
        "        h_s_batch = h_s[student_idx]\n",
        "        h_t_batch = h_t[step_idx]\n",
        "        h_c_batch = h_c[kc_idx]\n",
        "\n",
        "        # === 5. Prediction ===\n",
        "        combined = torch.cat([h_s_batch, h_t_batch, h_c_batch], dim=-1)\n",
        "        logits = self.prediction_head(combined).squeeze(-1)\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def update_mastery_online(self, student_idx, kc_idx, y_true, lambda_ema):\n",
        "        \"\"\"Update mastery after observation\"\"\"\n",
        "        with torch.no_grad():\n",
        "            old_mastery = self.mastery_matrix[student_idx, kc_idx]\n",
        "            new_mastery = (1 - lambda_ema) * old_mastery + lambda_ema * y_true\n",
        "            self.mastery_matrix[student_idx, kc_idx] = new_mastery\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# FUNCTION 5: Dataset (UNCHANGED)\n",
        "# ============================================================\n",
        "\n",
        "class KTDatasetPure(Dataset):\n",
        "    \"\"\"Dataset for Knowledge Tracing\"\"\"\n",
        "    def __init__(self, df, stu2idx, t2idx, c2idx,\n",
        "                 unk_student_idx, unk_step_idx, unk_kc_idx):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.stu2idx = stu2idx\n",
        "        self.t2idx = t2idx\n",
        "        self.c2idx = c2idx\n",
        "        self.unk_student_idx = unk_student_idx\n",
        "        self.unk_step_idx = unk_step_idx\n",
        "        self.unk_kc_idx = unk_kc_idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        student_idx = self.stu2idx.get(row['student_id'], self.unk_student_idx)\n",
        "        step_idx = self.t2idx.get(row['step_id'], self.unk_step_idx)\n",
        "        kc_idx = self.c2idx.get(row['kc_id'], self.unk_kc_idx)\n",
        "        label = torch.tensor(row['correct'], dtype=torch.float32)\n",
        "        return student_idx, step_idx, kc_idx, label\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# FUNCTION 6: Training & Evaluation\n",
        "# ============================================================\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stopping with model state saving\"\"\"\n",
        "    def __init__(self, patience=10, min_delta=0.001):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.best_state = None\n",
        "\n",
        "    def __call__(self, score, model):\n",
        "        if self.best_score is None or score > self.best_score + self.min_delta:\n",
        "            self.best_score = score\n",
        "            self.best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "\n",
        "    def load_best(self, model):\n",
        "        if self.best_state:\n",
        "            model.load_state_dict(self.best_state)\n",
        "\n",
        "\n",
        "def train_epoch(model, loader, optimizer, criterion, hetero_data, device,\n",
        "                config, grad_clip=1.0):\n",
        "    \"\"\"Train for one epoch with mastery update\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    for batch in loader:\n",
        "        student_idx, step_idx, kc_idx, labels = batch\n",
        "        student_idx = student_idx.to(device)\n",
        "        step_idx = step_idx.to(device)\n",
        "        kc_idx = kc_idx.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # 1. FORWARD (with current mastery in features - history up to t-1)\n",
        "        logits = model(hetero_data, student_idx, step_idx, kc_idx, device)\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        # 2. BACKWARD (update model weights)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        # 3. UPDATE MASTERY (AFTER backward, no gradient)\n",
        "        #    ⚠️ CRITICAL: This order prevents leakage\n",
        "        if hasattr(model, 'update_mastery_online'):\n",
        "            model.update_mastery_online(\n",
        "                student_idx, kc_idx, labels,\n",
        "                lambda_ema=config.LAMBDA_EMA\n",
        "            )\n",
        "\n",
        "        # Metrics\n",
        "        total_loss += loss.item() * len(labels)\n",
        "        all_preds.extend(torch.sigmoid(logits).detach().cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / len(loader.dataset)\n",
        "    auc = roc_auc_score(all_labels, all_preds) if len(set(all_labels)) > 1 else 0.5\n",
        "    acc = accuracy_score(all_labels, np.array(all_preds) > 0.5)\n",
        "\n",
        "    return avg_loss, auc, acc\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, criterion, hetero_data, device):\n",
        "    \"\"\"Evaluate without mastery update\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    for batch in loader:\n",
        "        student_idx, step_idx, kc_idx, labels = batch\n",
        "        student_idx = student_idx.to(device)\n",
        "        step_idx = step_idx.to(device)\n",
        "        kc_idx = kc_idx.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        logits = model(hetero_data, student_idx, step_idx, kc_idx, device)\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        total_loss += loss.item() * len(labels)\n",
        "        all_preds.extend(torch.sigmoid(logits).cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / len(loader.dataset)\n",
        "    auc = roc_auc_score(all_labels, all_preds) if len(set(all_labels)) > 1 else 0.5\n",
        "    acc = accuracy_score(all_labels, np.array(all_preds) > 0.5)\n",
        "\n",
        "    return avg_loss, auc, acc\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 🆕 FUNCTION 7: Full Single-Fold Pipeline (MODIFIED for M3a)\n",
        "# ============================================================\n",
        "\n",
        "def run_single_fold(df_train_fold, df_val_fold, config, fold_num=None, verbose=True):\n",
        "    \"\"\"Run complete training pipeline for one fold - M3a version\"\"\"\n",
        "    device = config.DEVICE\n",
        "    prefix = f\"[Fold {fold_num}] \" if fold_num is not None else \"\"\n",
        "\n",
        "    # --- Step 1: Entity mappings ---\n",
        "    mappings, entity_counts, unk_indices = build_entity_mappings(df_train_fold)\n",
        "    if verbose:\n",
        "        print(f\"{prefix}Entities: S={entity_counts['num_students']}, \"\n",
        "              f\"Q={entity_counts['num_questions']}, \"\n",
        "              f\"T={entity_counts['num_steps']}, \"\n",
        "              f\"C={entity_counts['num_kcs']}\")\n",
        "\n",
        "    # --- Step 2: Build graph ---\n",
        "    hetero_data, total_edges = build_graph(df_train_fold, mappings, entity_counts, unk_indices)\n",
        "    if verbose:\n",
        "        print(f\"{prefix}Graph edges: {total_edges:,}\")\n",
        "\n",
        "    # --- Step 3: Initialize mastery BEFORE computing features ---\n",
        "    mastery_matrix_cpu = torch.full(\n",
        "        (entity_counts['num_students'], entity_counts['num_kcs']),\n",
        "        config.MASTERY_INIT,\n",
        "        dtype=torch.float32\n",
        "    )\n",
        "\n",
        "    # --- Step 4: Node features WITH mastery ---\n",
        "    feat_tensors = compute_node_features_with_mastery(\n",
        "        df_train_fold, mappings, entity_counts, unk_indices,\n",
        "        mastery_matrix_cpu  # ← NEW\n",
        "    )\n",
        "    hetero_data['student'].x = feat_tensors['student']  # [num_students, 5+num_kcs]\n",
        "    hetero_data['question'].x = feat_tensors['question']\n",
        "    hetero_data['step'].x = feat_tensors['step']\n",
        "    hetero_data['kc'].x = feat_tensors['kc']\n",
        "\n",
        "    # --- Step 5: DataLoaders ---\n",
        "    train_dataset = KTDatasetPure(\n",
        "        df_train_fold, mappings['stu2idx'], mappings['t2idx'], mappings['c2idx'],\n",
        "        unk_indices['student'], unk_indices['step'], unk_indices['kc']\n",
        "    )\n",
        "    val_dataset = KTDatasetPure(\n",
        "        df_val_fold, mappings['stu2idx'], mappings['t2idx'], mappings['c2idx'],\n",
        "        unk_indices['student'], unk_indices['step'], unk_indices['kc']\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True,\n",
        "                              pin_memory=True, num_workers=0)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=512, shuffle=False,\n",
        "                            pin_memory=True, num_workers=0)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"{prefix}Train: {len(train_loader.dataset):,} samples, \"\n",
        "              f\"Val: {len(val_loader.dataset):,} samples\")\n",
        "\n",
        "    # --- Step 6: Model ---\n",
        "    model = RGCNWithMasteryFeatures(  # ← NEW MODEL\n",
        "        num_students=entity_counts['num_students'],\n",
        "        num_questions=entity_counts['num_questions'],\n",
        "        num_steps=entity_counts['num_steps'],\n",
        "        num_kcs=entity_counts['num_kcs'],\n",
        "        feature_dim_base=NUM_FEATURES,\n",
        "        embed_dim=config.EMBED_DIM,\n",
        "        hidden_dim=config.HIDDEN_DIM,\n",
        "        num_gnn_layers=config.NUM_GNN_LAYERS,\n",
        "        dropout=config.DROPOUT,\n",
        "        mastery_init=config.MASTERY_INIT\n",
        "    ).to(device)\n",
        "\n",
        "    model.init_mastery_matrix(device)\n",
        "\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    if verbose:\n",
        "        print(f\"{prefix}Model params: {total_params:,}\")\n",
        "\n",
        "    # --- Step 7: Training setup ---\n",
        "    n_correct = df_train_fold['correct'].sum()\n",
        "    n_incorrect = len(df_train_fold) - n_correct\n",
        "    pos_weight = torch.tensor([n_incorrect / n_correct], dtype=torch.float32).to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=config.LEARNING_RATE,\n",
        "                                   weight_decay=config.WEIGHT_DECAY)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='max', factor=0.5, patience=5\n",
        "    )\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "    early_stopping = EarlyStopping(patience=config.PATIENCE)\n",
        "\n",
        "    # --- Step 8: Training loop ---\n",
        "    history = defaultdict(list)\n",
        "    best_val_auc = 0\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"{prefix}Training (pos_weight={pos_weight.item():.4f})...\")\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "    for epoch in range(config.EPOCHS):\n",
        "        epoch_start = time.time()\n",
        "\n",
        "        # 🆕 RECALCULATE student features with UPDATED mastery\n",
        "        if epoch > 0:  # Skip first epoch (already computed)\n",
        "            mastery_cpu = model.mastery_matrix.cpu()\n",
        "            feat_tensors = compute_node_features_with_mastery(\n",
        "                df_train_fold, mappings, entity_counts, unk_indices,\n",
        "                mastery_cpu  # ← Mastery from previous epoch\n",
        "            )\n",
        "            hetero_data['student'].x = feat_tensors['student']\n",
        "\n",
        "        train_loss, train_auc, train_acc = train_epoch(\n",
        "            model, train_loader, optimizer, criterion, hetero_data, device, config, config.GRAD_CLIP\n",
        "        )\n",
        "        val_loss, val_auc, val_acc = evaluate(\n",
        "            model, val_loader, criterion, hetero_data, device\n",
        "        )\n",
        "\n",
        "        epoch_time = time.time() - epoch_start\n",
        "\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_auc'].append(train_auc)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_auc'].append(val_auc)\n",
        "        history['val_acc'].append(val_acc)\n",
        "\n",
        "        marker = \" ★\" if val_auc > best_val_auc else \"\"\n",
        "        if val_auc > best_val_auc:\n",
        "            best_val_auc = val_auc\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"{prefix}Epoch {epoch+1:3d}/{config.EPOCHS} | \"\n",
        "                  f\"Train AUC: {train_auc:.4f} | Val AUC: {val_auc:.4f} | \"\n",
        "                  f\"Val Acc: {val_acc:.4f} | Time: {epoch_time:.1f}s{marker}\")\n",
        "\n",
        "        scheduler.step(val_auc)\n",
        "        early_stopping(val_auc, model)\n",
        "\n",
        "        if early_stopping.early_stop:\n",
        "            if verbose:\n",
        "                print(f\"{prefix}Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "    early_stopping.load_best(model)\n",
        "\n",
        "    final_val_loss, final_val_auc, final_val_acc = evaluate(\n",
        "        model, val_loader, criterion, hetero_data, device\n",
        "    )\n",
        "\n",
        "    stopped_epoch = len(history['train_loss'])\n",
        "\n",
        "    if verbose:\n",
        "        print(\"-\" * 70)\n",
        "        print(f\"{prefix}Best Val AUC: {final_val_auc:.4f} | \"\n",
        "              f\"Val Acc: {final_val_acc:.4f} | Stopped at epoch: {stopped_epoch}\")\n",
        "\n",
        "    return {\n",
        "        'val_auc': final_val_auc,\n",
        "        'val_acc': final_val_acc,\n",
        "        'val_loss': final_val_loss,\n",
        "        'train_auc': history['train_auc'][-1],\n",
        "        'stopped_epoch': stopped_epoch,\n",
        "        'total_params': total_params,\n",
        "        'history': dict(history),\n",
        "        'model_state': early_stopping.best_state,\n",
        "        'hetero_data': hetero_data,\n",
        "        'mappings': mappings,\n",
        "        'entity_counts': entity_counts,\n",
        "        'unk_indices': unk_indices,\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Confirmation\n",
        "# ============================================================\n",
        "print(\"=\" * 60)\n",
        "print(\"✓ ALL PIPELINE FUNCTIONS DEFINED (M3a VERSION)\")\n",
        "print(\"=\" * 60)\n",
        "print(\"  - build_entity_mappings()\")\n",
        "print(\"  - build_graph()\")\n",
        "print(\"  - compute_node_features()\")\n",
        "print(\"  - compute_node_features_with_mastery() [NEW]\")\n",
        "print(\"  - RGCNWithMasteryFeatures (Mastery as Features)\")\n",
        "print(\"  - KTDatasetPure\")\n",
        "print(\"  - train_epoch() / evaluate()\")\n",
        "print(\"  - run_single_fold() [MODIFIED for M3a]\")\n",
        "print(\"=\" * 60)\n",
        "print(\"Ready for 5-Fold Cross-Validation! 🚀\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "id": "cWsbyFg-o-po",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a59c99e1-467b-4e4f-ba1f-57782599486e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "5-FOLD STUDENT-LEVEL CROSS-VALIDATION\n",
            "============================================================\n",
            "\n",
            "Protocol:\n",
            "  - 487 non-test students split into 5 folds\n",
            "  - Each fold: full pipeline rebuild (mappings, graph, features, model)\n",
            "  - All design decisions FROZEN before CV\n",
            "  - TEST set (87 students) completely untouched\n",
            "\n",
            "Frozen hyperparameters:\n",
            "  EMBED_DIM=32, HIDDEN_DIM=64\n",
            "  NUM_GNN_LAYERS=2, DROPOUT=0.2\n",
            "  LR=0.001, WEIGHT_DECAY=0.01\n",
            "  BATCH_SIZE=512, PATIENCE=10\n",
            "\n",
            "\n",
            "============================================================\n",
            "FOLD 1 / 5\n",
            "============================================================\n",
            "Train students: 389, Val students: 98\n",
            "Train interactions: 524,961, Val interactions: 166,472\n",
            "[Fold 1] Entities: S=390, Q=1064, T=146327, C=397\n",
            "[Fold 1] Graph edges: 662,288\n",
            "[Fold 1] Train: 524,961 samples, Val: 166,472 samples\n",
            "  ✓ Mastery matrix initialized: [390, 397] with value=0.5\n",
            "[Fold 1] Model params: 33,017\n",
            "[Fold 1] Training (pos_weight=0.3041)...\n",
            "----------------------------------------------------------------------\n",
            "[Fold 1] Epoch   1/100 | Train AUC: 0.9027 | Val AUC: 0.7337 | Val Acc: 0.7771 | Time: 105.1s ★\n",
            "[Fold 1] Epoch   2/100 | Train AUC: 0.9127 | Val AUC: 0.7323 | Val Acc: 0.7489 | Time: 150.5s\n",
            "[Fold 1] Epoch   3/100 | Train AUC: 0.9142 | Val AUC: 0.7296 | Val Acc: 0.7535 | Time: 150.2s\n",
            "[Fold 1] Epoch   4/100 | Train AUC: 0.9151 | Val AUC: 0.7235 | Val Acc: 0.7609 | Time: 149.6s\n",
            "[Fold 1] Epoch   5/100 | Train AUC: 0.9157 | Val AUC: 0.7249 | Val Acc: 0.7685 | Time: 148.7s\n",
            "[Fold 1] Epoch   6/100 | Train AUC: 0.9157 | Val AUC: 0.7322 | Val Acc: 0.7566 | Time: 150.1s\n",
            "[Fold 1] Epoch   7/100 | Train AUC: 0.9163 | Val AUC: 0.7322 | Val Acc: 0.7612 | Time: 149.2s\n",
            "[Fold 1] Epoch   8/100 | Train AUC: 0.9169 | Val AUC: 0.7272 | Val Acc: 0.7543 | Time: 149.3s\n",
            "[Fold 1] Epoch   9/100 | Train AUC: 0.9172 | Val AUC: 0.7315 | Val Acc: 0.7473 | Time: 150.7s\n",
            "[Fold 1] Epoch  10/100 | Train AUC: 0.9174 | Val AUC: 0.7311 | Val Acc: 0.7324 | Time: 149.1s\n",
            "[Fold 1] Epoch  11/100 | Train AUC: 0.9176 | Val AUC: 0.7308 | Val Acc: 0.7363 | Time: 148.9s\n",
            "[Fold 1] Early stopping at epoch 11\n",
            "----------------------------------------------------------------------\n",
            "[Fold 1] Best Val AUC: 0.7337 | Val Acc: 0.7771 | Stopped at epoch: 11\n",
            "\n",
            "Fold 1 completed in 1696.6s\n",
            "\n",
            "============================================================\n",
            "FOLD 2 / 5\n",
            "============================================================\n",
            "Train students: 389, Val students: 98\n",
            "Train interactions: 579,228, Val interactions: 112,205\n",
            "[Fold 2] Entities: S=390, Q=1077, T=156768, C=406\n",
            "[Fold 2] Graph edges: 712,642\n",
            "[Fold 2] Train: 579,228 samples, Val: 112,205 samples\n",
            "  ✓ Mastery matrix initialized: [390, 406] with value=0.5\n",
            "[Fold 2] Model params: 33,305\n",
            "[Fold 2] Training (pos_weight=0.2926)...\n",
            "----------------------------------------------------------------------\n",
            "[Fold 2] Epoch   1/100 | Train AUC: 0.9010 | Val AUC: 0.7209 | Val Acc: 0.7200 | Time: 104.4s ★\n",
            "[Fold 2] Epoch   2/100 | Train AUC: 0.9111 | Val AUC: 0.7065 | Val Acc: 0.7211 | Time: 155.7s\n",
            "[Fold 2] Epoch   3/100 | Train AUC: 0.9122 | Val AUC: 0.7368 | Val Acc: 0.7178 | Time: 154.9s ★\n",
            "[Fold 2] Epoch   4/100 | Train AUC: 0.9129 | Val AUC: 0.7246 | Val Acc: 0.7389 | Time: 155.6s\n",
            "[Fold 2] Epoch   5/100 | Train AUC: 0.9135 | Val AUC: 0.7123 | Val Acc: 0.7357 | Time: 155.6s\n",
            "[Fold 2] Epoch   6/100 | Train AUC: 0.9138 | Val AUC: 0.7180 | Val Acc: 0.7181 | Time: 154.9s\n",
            "[Fold 2] Epoch   7/100 | Train AUC: 0.9142 | Val AUC: 0.7009 | Val Acc: 0.7193 | Time: 155.4s\n",
            "[Fold 2] Epoch   8/100 | Train AUC: 0.9146 | Val AUC: 0.7015 | Val Acc: 0.7372 | Time: 155.8s\n",
            "[Fold 2] Epoch   9/100 | Train AUC: 0.9147 | Val AUC: 0.6987 | Val Acc: 0.7347 | Time: 156.3s\n",
            "[Fold 2] Epoch  10/100 | Train AUC: 0.9155 | Val AUC: 0.7015 | Val Acc: 0.7273 | Time: 155.5s\n",
            "[Fold 2] Epoch  11/100 | Train AUC: 0.9155 | Val AUC: 0.6978 | Val Acc: 0.7268 | Time: 155.7s\n",
            "[Fold 2] Epoch  12/100 | Train AUC: 0.9157 | Val AUC: 0.7011 | Val Acc: 0.7101 | Time: 156.2s\n",
            "[Fold 2] Epoch  13/100 | Train AUC: 0.9158 | Val AUC: 0.6981 | Val Acc: 0.7290 | Time: 157.1s\n",
            "[Fold 2] Early stopping at epoch 13\n",
            "----------------------------------------------------------------------\n",
            "[Fold 2] Best Val AUC: 0.7368 | Val Acc: 0.7178 | Stopped at epoch: 13\n",
            "\n",
            "Fold 2 completed in 2064.8s\n",
            "\n",
            "============================================================\n",
            "FOLD 3 / 5\n",
            "============================================================\n",
            "Train students: 390, Val students: 97\n",
            "Train interactions: 537,828, Val interactions: 153,605\n",
            "[Fold 3] Entities: S=391, Q=1078, T=150244, C=415\n",
            "[Fold 3] Graph edges: 680,518\n",
            "[Fold 3] Train: 537,828 samples, Val: 153,605 samples\n",
            "  ✓ Mastery matrix initialized: [391, 415] with value=0.5\n",
            "[Fold 3] Model params: 33,593\n",
            "[Fold 3] Training (pos_weight=0.3030)...\n",
            "----------------------------------------------------------------------\n",
            "[Fold 3] Epoch   1/100 | Train AUC: 0.9041 | Val AUC: 0.7276 | Val Acc: 0.7404 | Time: 105.6s ★\n",
            "[Fold 3] Epoch   2/100 | Train AUC: 0.9140 | Val AUC: 0.7276 | Val Acc: 0.7524 | Time: 153.3s ★\n",
            "[Fold 3] Epoch   3/100 | Train AUC: 0.9155 | Val AUC: 0.7294 | Val Acc: 0.7352 | Time: 154.0s ★\n",
            "[Fold 3] Epoch   4/100 | Train AUC: 0.9164 | Val AUC: 0.7337 | Val Acc: 0.7545 | Time: 152.8s ★\n",
            "[Fold 3] Epoch   5/100 | Train AUC: 0.9170 | Val AUC: 0.7325 | Val Acc: 0.7391 | Time: 153.2s\n",
            "[Fold 3] Epoch   6/100 | Train AUC: 0.9174 | Val AUC: 0.7267 | Val Acc: 0.7353 | Time: 153.7s\n",
            "[Fold 3] Epoch   7/100 | Train AUC: 0.9177 | Val AUC: 0.7327 | Val Acc: 0.7543 | Time: 154.8s\n",
            "[Fold 3] Epoch   8/100 | Train AUC: 0.9179 | Val AUC: 0.7286 | Val Acc: 0.7490 | Time: 153.4s\n",
            "[Fold 3] Epoch   9/100 | Train AUC: 0.9184 | Val AUC: 0.7349 | Val Acc: 0.7507 | Time: 154.4s ★\n",
            "[Fold 3] Epoch  10/100 | Train AUC: 0.9187 | Val AUC: 0.7354 | Val Acc: 0.7314 | Time: 155.5s ★\n",
            "[Fold 3] Epoch  11/100 | Train AUC: 0.9187 | Val AUC: 0.7342 | Val Acc: 0.7453 | Time: 153.6s\n",
            "[Fold 3] Epoch  12/100 | Train AUC: 0.9188 | Val AUC: 0.7356 | Val Acc: 0.7440 | Time: 152.2s ★\n",
            "[Fold 3] Epoch  13/100 | Train AUC: 0.9191 | Val AUC: 0.7323 | Val Acc: 0.7369 | Time: 151.9s\n",
            "[Fold 3] Epoch  14/100 | Train AUC: 0.9193 | Val AUC: 0.7361 | Val Acc: 0.7193 | Time: 152.9s ★\n",
            "[Fold 3] Epoch  15/100 | Train AUC: 0.9197 | Val AUC: 0.7326 | Val Acc: 0.7446 | Time: 152.4s\n",
            "[Fold 3] Epoch  16/100 | Train AUC: 0.9196 | Val AUC: 0.7264 | Val Acc: 0.7393 | Time: 153.0s\n",
            "[Fold 3] Epoch  17/100 | Train AUC: 0.9197 | Val AUC: 0.7278 | Val Acc: 0.7353 | Time: 152.9s\n",
            "[Fold 3] Epoch  18/100 | Train AUC: 0.9199 | Val AUC: 0.7339 | Val Acc: 0.7322 | Time: 152.8s\n",
            "[Fold 3] Epoch  19/100 | Train AUC: 0.9200 | Val AUC: 0.7349 | Val Acc: 0.7336 | Time: 153.6s\n",
            "[Fold 3] Epoch  20/100 | Train AUC: 0.9203 | Val AUC: 0.7332 | Val Acc: 0.7188 | Time: 154.0s\n",
            "[Fold 3] Epoch  21/100 | Train AUC: 0.9208 | Val AUC: 0.7363 | Val Acc: 0.7259 | Time: 152.8s ★\n",
            "[Fold 3] Epoch  22/100 | Train AUC: 0.9211 | Val AUC: 0.7355 | Val Acc: 0.7334 | Time: 153.3s\n",
            "[Fold 3] Epoch  23/100 | Train AUC: 0.9213 | Val AUC: 0.7363 | Val Acc: 0.7519 | Time: 153.3s ★\n",
            "[Fold 3] Epoch  24/100 | Train AUC: 0.9211 | Val AUC: 0.7360 | Val Acc: 0.7230 | Time: 153.3s\n",
            "[Fold 3] Early stopping at epoch 24\n",
            "----------------------------------------------------------------------\n",
            "[Fold 3] Best Val AUC: 0.7362 | Val Acc: 0.7188 | Stopped at epoch: 24\n",
            "\n",
            "Fold 3 completed in 3727.5s\n",
            "\n",
            "============================================================\n",
            "FOLD 4 / 5\n",
            "============================================================\n",
            "Train students: 390, Val students: 97\n",
            "Train interactions: 557,654, Val interactions: 133,779\n",
            "[Fold 4] Entities: S=391, Q=1078, T=154760, C=415\n",
            "[Fold 4] Graph edges: 701,006\n",
            "[Fold 4] Train: 557,654 samples, Val: 133,779 samples\n",
            "  ✓ Mastery matrix initialized: [391, 415] with value=0.5\n",
            "[Fold 4] Model params: 33,593\n",
            "[Fold 4] Training (pos_weight=0.3031)...\n",
            "----------------------------------------------------------------------\n",
            "[Fold 4] Epoch   1/100 | Train AUC: 0.9050 | Val AUC: 0.7254 | Val Acc: 0.7260 | Time: 106.6s ★\n",
            "[Fold 4] Epoch   2/100 | Train AUC: 0.9140 | Val AUC: 0.7245 | Val Acc: 0.7486 | Time: 157.3s\n",
            "[Fold 4] Epoch   3/100 | Train AUC: 0.9154 | Val AUC: 0.7271 | Val Acc: 0.7482 | Time: 157.1s ★\n",
            "[Fold 4] Epoch   4/100 | Train AUC: 0.9160 | Val AUC: 0.7270 | Val Acc: 0.7536 | Time: 155.5s\n",
            "[Fold 4] Epoch   5/100 | Train AUC: 0.9164 | Val AUC: 0.7259 | Val Acc: 0.7378 | Time: 156.3s\n",
            "[Fold 4] Epoch   6/100 | Train AUC: 0.9168 | Val AUC: 0.7252 | Val Acc: 0.7413 | Time: 155.7s\n",
            "[Fold 4] Epoch   7/100 | Train AUC: 0.9170 | Val AUC: 0.7292 | Val Acc: 0.7430 | Time: 156.0s ★\n",
            "[Fold 4] Epoch   8/100 | Train AUC: 0.9173 | Val AUC: 0.7283 | Val Acc: 0.7403 | Time: 155.3s\n",
            "[Fold 4] Epoch   9/100 | Train AUC: 0.9176 | Val AUC: 0.7247 | Val Acc: 0.7539 | Time: 155.7s\n",
            "[Fold 4] Epoch  10/100 | Train AUC: 0.9176 | Val AUC: 0.7301 | Val Acc: 0.7439 | Time: 155.3s ★\n",
            "[Fold 4] Epoch  11/100 | Train AUC: 0.9181 | Val AUC: 0.7286 | Val Acc: 0.7333 | Time: 155.3s\n",
            "[Fold 4] Epoch  12/100 | Train AUC: 0.9180 | Val AUC: 0.7259 | Val Acc: 0.7556 | Time: 155.6s\n",
            "[Fold 4] Epoch  13/100 | Train AUC: 0.9182 | Val AUC: 0.7244 | Val Acc: 0.7539 | Time: 155.2s\n",
            "[Fold 4] Epoch  14/100 | Train AUC: 0.9184 | Val AUC: 0.7253 | Val Acc: 0.7503 | Time: 155.9s\n",
            "[Fold 4] Epoch  15/100 | Train AUC: 0.9186 | Val AUC: 0.7267 | Val Acc: 0.7272 | Time: 155.8s\n",
            "[Fold 4] Epoch  16/100 | Train AUC: 0.9187 | Val AUC: 0.7298 | Val Acc: 0.7471 | Time: 155.5s\n",
            "[Fold 4] Epoch  17/100 | Train AUC: 0.9192 | Val AUC: 0.7292 | Val Acc: 0.7399 | Time: 155.9s\n",
            "[Fold 4] Early stopping at epoch 17\n",
            "----------------------------------------------------------------------\n",
            "[Fold 4] Best Val AUC: 0.7292 | Val Acc: 0.7432 | Stopped at epoch: 17\n",
            "\n",
            "Fold 4 completed in 2693.7s\n",
            "\n",
            "============================================================\n",
            "FOLD 5 / 5\n",
            "============================================================\n",
            "Train students: 390, Val students: 97\n",
            "Train interactions: 566,061, Val interactions: 125,372\n",
            "[Fold 5] Entities: S=391, Q=1072, T=155983, C=414\n",
            "[Fold 5] Graph edges: 707,298\n",
            "[Fold 5] Train: 566,061 samples, Val: 125,372 samples\n",
            "  ✓ Mastery matrix initialized: [391, 414] with value=0.5\n",
            "[Fold 5] Model params: 33,561\n",
            "[Fold 5] Training (pos_weight=0.2975)...\n",
            "----------------------------------------------------------------------\n",
            "[Fold 5] Epoch   1/100 | Train AUC: 0.9037 | Val AUC: 0.7391 | Val Acc: 0.7373 | Time: 105.3s ★\n",
            "[Fold 5] Epoch   2/100 | Train AUC: 0.9137 | Val AUC: 0.7444 | Val Acc: 0.7707 | Time: 154.9s ★\n",
            "[Fold 5] Epoch   3/100 | Train AUC: 0.9153 | Val AUC: 0.7448 | Val Acc: 0.7639 | Time: 155.0s ★\n",
            "[Fold 5] Epoch   4/100 | Train AUC: 0.9159 | Val AUC: 0.7380 | Val Acc: 0.7589 | Time: 156.1s\n",
            "[Fold 5] Epoch   5/100 | Train AUC: 0.9166 | Val AUC: 0.7389 | Val Acc: 0.7227 | Time: 155.7s\n",
            "[Fold 5] Epoch   6/100 | Train AUC: 0.9168 | Val AUC: 0.7405 | Val Acc: 0.7430 | Time: 156.1s\n",
            "[Fold 5] Epoch   7/100 | Train AUC: 0.9170 | Val AUC: 0.7367 | Val Acc: 0.7361 | Time: 155.5s\n",
            "[Fold 5] Epoch   8/100 | Train AUC: 0.9173 | Val AUC: 0.7344 | Val Acc: 0.7486 | Time: 155.7s\n",
            "[Fold 5] Epoch   9/100 | Train AUC: 0.9175 | Val AUC: 0.7347 | Val Acc: 0.7292 | Time: 155.4s\n",
            "[Fold 5] Epoch  10/100 | Train AUC: 0.9182 | Val AUC: 0.7389 | Val Acc: 0.7481 | Time: 155.3s\n",
            "[Fold 5] Epoch  11/100 | Train AUC: 0.9185 | Val AUC: 0.7387 | Val Acc: 0.7440 | Time: 155.7s\n",
            "[Fold 5] Epoch  12/100 | Train AUC: 0.9185 | Val AUC: 0.7349 | Val Acc: 0.7356 | Time: 155.1s\n",
            "[Fold 5] Early stopping at epoch 12\n",
            "----------------------------------------------------------------------\n",
            "[Fold 5] Best Val AUC: 0.7444 | Val Acc: 0.7707 | Stopped at epoch: 12\n",
            "\n",
            "Fold 5 completed in 1908.5s\n",
            "\n",
            "============================================================\n",
            "5-FOLD CROSS-VALIDATION RESULTS\n",
            "============================================================\n",
            "\n",
            "Fold     Val AUC      Val Acc      Epochs    \n",
            "------------------------------------------\n",
            "Fold 1   0.7337       0.7771       11        \n",
            "Fold 2   0.7368       0.7178       13        \n",
            "Fold 3   0.7362       0.7188       24        \n",
            "Fold 4   0.7292       0.7432       17        \n",
            "Fold 5   0.7444       0.7707       12        \n",
            "------------------------------------------\n",
            "Mean     0.7361       0.7455       15.4      \n",
            "Std      0.0049       0.0250       4.8       \n",
            "Min      0.7292       0.7178       11        \n",
            "Max      0.7444       0.7771       24        \n",
            "\n",
            "╔══════════════════════════════════════════════╗\n",
            "║  CV Val AUC: 0.7361 ± 0.0049              ║\n",
            "║  CV Val Acc: 0.7455 ± 0.0250              ║\n",
            "╚══════════════════════════════════════════════╝\n",
            "\n",
            "Total CV time: 12091.0s (201.5 min)\n",
            "\n",
            "Average stopping epoch: 15 (will use for final training)\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Cell 6: Run 5-Fold Student-Level Cross-Validation\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"5-FOLD STUDENT-LEVEL CROSS-VALIDATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\"\"\n",
        "Protocol:\n",
        "  - {len(non_test_students)} non-test students split into 5 folds\n",
        "  - Each fold: full pipeline rebuild (mappings, graph, features, model)\n",
        "  - All design decisions FROZEN before CV\n",
        "  - TEST set ({len(test_students)} students) completely untouched\n",
        "\n",
        "Frozen hyperparameters:\n",
        "  EMBED_DIM={config.EMBED_DIM}, HIDDEN_DIM={config.HIDDEN_DIM}\n",
        "  NUM_GNN_LAYERS={config.NUM_GNN_LAYERS}, DROPOUT={config.DROPOUT}\n",
        "  LR={config.LEARNING_RATE}, WEIGHT_DECAY={config.WEIGHT_DECAY}\n",
        "  BATCH_SIZE=512, PATIENCE={config.PATIENCE}\n",
        "\"\"\")\n",
        "\n",
        "cv_results = []\n",
        "cv_start = time.time()\n",
        "\n",
        "for fold_idx in range(5):\n",
        "    fold_start = time.time()\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"FOLD {fold_idx + 1} / 5\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Get this fold's students\n",
        "    train_students_fold = fold_assignments[fold_idx]['train_students']\n",
        "    val_students_fold = fold_assignments[fold_idx]['val_students']\n",
        "\n",
        "    # Create dataframes for this fold\n",
        "    df_train_fold = df_non_test[df_non_test['student_id'].isin(train_students_fold)].copy()\n",
        "    df_val_fold = df_non_test[df_non_test['student_id'].isin(val_students_fold)].copy()\n",
        "\n",
        "    print(f\"Train students: {len(train_students_fold)}, \"\n",
        "          f\"Val students: {len(val_students_fold)}\")\n",
        "    print(f\"Train interactions: {len(df_train_fold):,}, \"\n",
        "          f\"Val interactions: {len(df_val_fold):,}\")\n",
        "\n",
        "    # Run full pipeline for this fold\n",
        "    result = run_single_fold(\n",
        "        df_train_fold, df_val_fold, config,\n",
        "        fold_num=fold_idx + 1, verbose=True\n",
        "    )\n",
        "\n",
        "    fold_time = time.time() - fold_start\n",
        "    result['fold_time'] = fold_time\n",
        "    cv_results.append(result)\n",
        "\n",
        "    print(f\"\\nFold {fold_idx + 1} completed in {fold_time:.1f}s\")\n",
        "\n",
        "total_cv_time = time.time() - cv_start\n",
        "\n",
        "# ============================================================\n",
        "# CV Summary\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"5-FOLD CROSS-VALIDATION RESULTS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "val_aucs = [r['val_auc'] for r in cv_results]\n",
        "val_accs = [r['val_acc'] for r in cv_results]\n",
        "stopped_epochs = [r['stopped_epoch'] for r in cv_results]\n",
        "\n",
        "print(f\"\\n{'Fold':<8} {'Val AUC':<12} {'Val Acc':<12} {'Epochs':<10}\")\n",
        "print(\"-\" * 42)\n",
        "for i, r in enumerate(cv_results):\n",
        "    print(f\"Fold {i+1:<3} {r['val_auc']:<12.4f} {r['val_acc']:<12.4f} {r['stopped_epoch']:<10}\")\n",
        "\n",
        "print(\"-\" * 42)\n",
        "print(f\"{'Mean':<8} {np.mean(val_aucs):<12.4f} {np.mean(val_accs):<12.4f} {np.mean(stopped_epochs):<10.1f}\")\n",
        "print(f\"{'Std':<8} {np.std(val_aucs):<12.4f} {np.std(val_accs):<12.4f} {np.std(stopped_epochs):<10.1f}\")\n",
        "print(f\"{'Min':<8} {np.min(val_aucs):<12.4f} {np.min(val_accs):<12.4f} {np.min(stopped_epochs):<10}\")\n",
        "print(f\"{'Max':<8} {np.max(val_aucs):<12.4f} {np.max(val_accs):<12.4f} {np.max(stopped_epochs):<10}\")\n",
        "\n",
        "print(f\"\\n╔══════════════════════════════════════════════╗\")\n",
        "print(f\"║  CV Val AUC: {np.mean(val_aucs):.4f} ± {np.std(val_aucs):.4f}              ║\")\n",
        "print(f\"║  CV Val Acc: {np.mean(val_accs):.4f} ± {np.std(val_accs):.4f}              ║\")\n",
        "print(f\"╚══════════════════════════════════════════════╝\")\n",
        "\n",
        "print(f\"\\nTotal CV time: {total_cv_time:.1f}s ({total_cv_time/60:.1f} min)\")\n",
        "\n",
        "# Store average epochs for final training\n",
        "avg_epochs_cv = int(np.mean(stopped_epochs))\n",
        "print(f\"\\nAverage stopping epoch: {avg_epochs_cv} (will use for final training)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "id": "RDUnF4Kto-pp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c4c131e-7b11-47d6-c974-e11d1471125e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "FINAL TEST EVALUATION\n",
            "============================================================\n",
            "\n",
            "Protocol:\n",
            "  - Train on ALL 487 non-test students (no validation split)\n",
            "  - Train for 15 epochs (average from CV, no early stopping)\n",
            "  - Evaluate on held-out TEST set (87 students)\n",
            "  - This number appears in the paper as TEST performance\n",
            "\n",
            "[1/5] Building entity mappings from all non-test data...\n",
            "  S=488, Q=1081, T=184307, C=428\n",
            "[2/5] Building graph...\n",
            "  Edges: 839,032\n",
            "[3/5] Initializing mastery matrix...\n",
            "[4/5] Computing node features with mastery...\n",
            "[5/5] Creating dataloaders...\n",
            "  Train: 691,433 samples\n",
            "  Test:  118,261 samples\n",
            "[6/6] Training final model...\n",
            "  ✓ Mastery matrix initialized: [488, 428] with value=0.5\n",
            "\n",
            "Training for 15 epochs (CV average)...\n",
            "----------------------------------------------------------------------\n",
            "Epoch   1/15 | Train Loss: 0.1794 | Train AUC: 0.9013 | Train Acc: 0.8068 | Time: 112.5s\n",
            "Epoch   5/15 | Train Loss: 0.1665 | Train AUC: 0.9135 | Train Acc: 0.8149 | Time: 171.7s\n",
            "Epoch  10/15 | Train Loss: 0.1651 | Train AUC: 0.9149 | Train Acc: 0.8179 | Time: 172.1s\n",
            "Epoch  15/15 | Train Loss: 0.1642 | Train AUC: 0.9159 | Train Acc: 0.8179 | Time: 171.9s\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Evaluating on TEST set...\n",
            "\n",
            "============================================================\n",
            "FINAL RESULTS\n",
            "============================================================\n",
            "\n",
            "╔══════════════════════════════════════════════════════════════╗\n",
            "║              GraphKT M3a (Mastery as Features)               ║\n",
            "║                    Algebra 2005-2006 Dataset                 ║\n",
            "╠══════════════════════════════════════════════════════════════╣\n",
            "║                                                              ║\n",
            "║  5-Fold CV Validation:                                       ║\n",
            "║    AUC:      0.7361 ± 0.0049                              ║\n",
            "║    Accuracy: 0.7455 ± 0.0250                              ║\n",
            "║                                                              ║\n",
            "║  Test Set (held-out, 87 students):                          ║\n",
            "║    AUC:      0.7466                                        ║\n",
            "║    Accuracy: 0.7434                                        ║\n",
            "║                                                              ║\n",
            "║  Model: 34,009 parameters                              ║\n",
            "║  Training: 15 epochs (CV average)                           ║\n",
            "║  Split: Student-level (Split B), no leakage                  ║\n",
            "║                                                              ║\n",
            "╚══════════════════════════════════════════════════════════════╝\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Cell 7: Final TEST Set Evaluation\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"FINAL TEST EVALUATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\"\"\n",
        "Protocol:\n",
        "  - Train on ALL {len(non_test_students)} non-test students (no validation split)\n",
        "  - Train for {avg_epochs_cv} epochs (average from CV, no early stopping)\n",
        "  - Evaluate on held-out TEST set ({len(test_students)} students)\n",
        "  - This number appears in the paper as TEST performance\n",
        "\"\"\")\n",
        "\n",
        "# --- Train on all non-test data ---\n",
        "df_train_final = df_non_test.copy()\n",
        "\n",
        "print(\"[1/5] Building entity mappings from all non-test data...\")\n",
        "mappings_final, entity_counts_final, unk_indices_final = build_entity_mappings(df_train_final)\n",
        "print(f\"  S={entity_counts_final['num_students']}, \"\n",
        "      f\"Q={entity_counts_final['num_questions']}, \"\n",
        "      f\"T={entity_counts_final['num_steps']}, \"\n",
        "      f\"C={entity_counts_final['num_kcs']}\")\n",
        "\n",
        "print(\"[2/5] Building graph...\")\n",
        "hetero_data_final, total_edges_final = build_graph(\n",
        "    df_train_final, mappings_final, entity_counts_final, unk_indices_final\n",
        ")\n",
        "print(f\"  Edges: {total_edges_final:,}\")\n",
        "\n",
        "# 🔧 CHANGEMENT 1: Initialize mastery BEFORE computing features\n",
        "print(\"[3/5] Initializing mastery matrix...\")\n",
        "mastery_matrix_cpu_final = torch.full(\n",
        "    (entity_counts_final['num_students'], entity_counts_final['num_kcs']),\n",
        "    config.MASTERY_INIT,\n",
        "    dtype=torch.float32\n",
        ")\n",
        "\n",
        "# 🔧 CHANGEMENT 2: Computing node features WITH mastery\n",
        "print(\"[4/5] Computing node features with mastery...\")\n",
        "feat_tensors_final = compute_node_features_with_mastery(\n",
        "    df_train_final, mappings_final, entity_counts_final, unk_indices_final,\n",
        "    mastery_matrix_cpu_final  # ← NEW\n",
        ")\n",
        "hetero_data_final['student'].x = feat_tensors_final['student']  # [num_students, 5+num_kcs]\n",
        "hetero_data_final['question'].x = feat_tensors_final['question']\n",
        "hetero_data_final['step'].x = feat_tensors_final['step']\n",
        "hetero_data_final['kc'].x = feat_tensors_final['kc']\n",
        "\n",
        "print(\"[5/5] Creating dataloaders...\")\n",
        "train_dataset_final = KTDatasetPure(\n",
        "    df_train_final,\n",
        "    mappings_final['stu2idx'], mappings_final['t2idx'], mappings_final['c2idx'],\n",
        "    unk_indices_final['student'], unk_indices_final['step'], unk_indices_final['kc']\n",
        ")\n",
        "test_dataset_final = KTDatasetPure(\n",
        "    df_test_final,\n",
        "    mappings_final['stu2idx'], mappings_final['t2idx'], mappings_final['c2idx'],\n",
        "    unk_indices_final['student'], unk_indices_final['step'], unk_indices_final['kc']\n",
        ")\n",
        "\n",
        "train_loader_final = DataLoader(train_dataset_final, batch_size=512, shuffle=True,\n",
        "                                 pin_memory=True, num_workers=0)\n",
        "test_loader_final = DataLoader(test_dataset_final, batch_size=512, shuffle=False,\n",
        "                                pin_memory=True, num_workers=0)\n",
        "\n",
        "print(f\"  Train: {len(train_dataset_final):,} samples\")\n",
        "print(f\"  Test:  {len(test_dataset_final):,} samples\")\n",
        "\n",
        "print(\"[6/6] Training final model...\")\n",
        "device = config.DEVICE\n",
        "\n",
        "# 🔧 CHANGEMENT 3: GraphKTMinimal → RGCNWithMasteryFeatures\n",
        "model_final = RGCNWithMasteryFeatures(\n",
        "    num_students=entity_counts_final['num_students'],\n",
        "    num_questions=entity_counts_final['num_questions'],\n",
        "    num_steps=entity_counts_final['num_steps'],\n",
        "    num_kcs=entity_counts_final['num_kcs'],\n",
        "    feature_dim_base=NUM_FEATURES,\n",
        "    embed_dim=config.EMBED_DIM,\n",
        "    hidden_dim=config.HIDDEN_DIM,\n",
        "    num_gnn_layers=config.NUM_GNN_LAYERS,\n",
        "    dropout=config.DROPOUT,\n",
        "    mastery_init=config.MASTERY_INIT\n",
        ").to(device)\n",
        "\n",
        "# Initialize mastery matrix\n",
        "model_final.init_mastery_matrix(device)\n",
        "\n",
        "# Class weights from full training set\n",
        "n_correct = df_train_final['correct'].sum()\n",
        "n_incorrect = len(df_train_final) - n_correct\n",
        "pos_weight_final = torch.tensor([n_incorrect / n_correct], dtype=torch.float32).to(device)\n",
        "\n",
        "optimizer_final = torch.optim.AdamW(model_final.parameters(), lr=config.LEARNING_RATE,\n",
        "                                      weight_decay=config.WEIGHT_DECAY)\n",
        "scheduler_final = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer_final, mode='min', factor=0.5, patience=5\n",
        ")\n",
        "criterion_final = nn.BCEWithLogitsLoss(pos_weight=pos_weight_final)\n",
        "\n",
        "# Train for fixed number of epochs (from CV average)\n",
        "print(f\"\\nTraining for {avg_epochs_cv} epochs (CV average)...\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "for epoch in range(avg_epochs_cv):\n",
        "    epoch_start = time.time()\n",
        "\n",
        "    # 🔧 CHANGEMENT 4: RECALCULATE student features with UPDATED mastery\n",
        "    if epoch > 0:  # Skip first epoch (already computed)\n",
        "        mastery_cpu = model_final.mastery_matrix.cpu()\n",
        "        feat_tensors_final = compute_node_features_with_mastery(\n",
        "            df_train_final, mappings_final, entity_counts_final, unk_indices_final,\n",
        "            mastery_cpu  # ← Mastery from previous epoch\n",
        "        )\n",
        "        hetero_data_final['student'].x = feat_tensors_final['student']\n",
        "\n",
        "    train_loss, train_auc, train_acc = train_epoch(\n",
        "        model_final, train_loader_final, optimizer_final, criterion_final,\n",
        "        hetero_data_final, device, config, config.GRAD_CLIP\n",
        "    )\n",
        "\n",
        "    epoch_time = time.time() - epoch_start\n",
        "\n",
        "    if (epoch + 1) % 5 == 0 or epoch == 0 or (epoch + 1) == avg_epochs_cv:\n",
        "        print(f\"Epoch {epoch+1:3d}/{avg_epochs_cv} | \"\n",
        "              f\"Train Loss: {train_loss:.4f} | Train AUC: {train_auc:.4f} | \"\n",
        "              f\"Train Acc: {train_acc:.4f} | Time: {epoch_time:.1f}s\")\n",
        "\n",
        "    scheduler_final.step(train_loss)\n",
        "\n",
        "print(\"-\" * 70)\n",
        "\n",
        "# --- Final TEST evaluation ---\n",
        "print(\"\\nEvaluating on TEST set...\")\n",
        "test_loss, test_auc, test_acc = evaluate(\n",
        "    model_final, test_loader_final, criterion_final,\n",
        "    hetero_data_final, device\n",
        ")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"FINAL RESULTS\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"\"\"\n",
        "╔══════════════════════════════════════════════════════════════╗\n",
        "║              GraphKT M3a (Mastery as Features)               ║\n",
        "║                    Algebra 2005-2006 Dataset                 ║\n",
        "╠══════════════════════════════════════════════════════════════╣\n",
        "║                                                              ║\n",
        "║  5-Fold CV Validation:                                       ║\n",
        "║    AUC:      {np.mean(val_aucs):.4f} ± {np.std(val_aucs):.4f}                              ║\n",
        "║    Accuracy: {np.mean(val_accs):.4f} ± {np.std(val_accs):.4f}                              ║\n",
        "║                                                              ║\n",
        "║  Test Set (held-out, {len(test_students)} students):                          ║\n",
        "║    AUC:      {test_auc:.4f}                                        ║\n",
        "║    Accuracy: {test_acc:.4f}                                        ║\n",
        "║                                                              ║\n",
        "║  Model: {sum(p.numel() for p in model_final.parameters()):,} parameters                              ║\n",
        "║  Training: {avg_epochs_cv} epochs (CV average)                           ║\n",
        "║  Split: Student-level (Split B), no leakage                  ║\n",
        "║                                                              ║\n",
        "╚══════════════════════════════════════════════════════════════╝\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9qu-TFRao-pp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37812dd4-d09d-4c68-f87a-f7f859adb033"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "DETAILED RESULTS FOR PAPER\n",
            "============================================================\n",
            "\n",
            "Table 1: Per-Fold Cross-Validation Results\n",
            "-------------------------------------------------------\n",
            "Fold   Students   Interactions   Val AUC    Val Acc    Epochs  \n",
            "-------------------------------------------------------\n",
            "1      98         166,472        0.7337     0.7771     11      \n",
            "2      98         112,205        0.7368     0.7178     13      \n",
            "3      97         153,605        0.7362     0.7188     24      \n",
            "4      97         133,779        0.7292     0.7432     17      \n",
            "5      97         125,372        0.7444     0.7707     12      \n",
            "-------------------------------------------------------\n",
            "Mean                             0.7361     0.7455     15.4    \n",
            "±Std                             0.0049     0.0250     4.8     \n",
            "\n",
            "\n",
            "Table 2: Model Comparison (for paper)\n",
            "-----------------------------------------------------------------\n",
            "Model                Val AUC          Test AUC     Params    \n",
            "-----------------------------------------------------------------\n",
            "GraphKT M3a          0.7361 ± 0.0049   0.7466       34,009\n",
            "\n",
            "\n",
            "Consistency Analysis:\n",
            "  AUC range across folds: 0.0152\n",
            "  ✓ Highly consistent (range < 0.03)\n",
            "\n",
            "  Coefficient of variation: 0.67%\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Cell 8: Paper-Ready Results Summary & Per-Fold Analysis\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"DETAILED RESULTS FOR PAPER\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Per-fold table\n",
        "print(\"\\nTable 1: Per-Fold Cross-Validation Results\")\n",
        "print(\"-\" * 55)\n",
        "print(f\"{'Fold':<6} {'Students':<10} {'Interactions':<14} {'Val AUC':<10} {'Val Acc':<10} {'Epochs':<8}\")\n",
        "print(\"-\" * 55)\n",
        "for i, r in enumerate(cv_results):\n",
        "    n_val_stu = len(fold_assignments[i]['val_students'])\n",
        "    df_val_f = df_non_test[df_non_test['student_id'].isin(fold_assignments[i]['val_students'])]\n",
        "    n_val_int = len(df_val_f)\n",
        "    print(f\"{i+1:<6} {n_val_stu:<10} {n_val_int:<14,} {r['val_auc']:<10.4f} {r['val_acc']:<10.4f} {r['stopped_epoch']:<8}\")\n",
        "\n",
        "print(\"-\" * 55)\n",
        "print(f\"{'Mean':<6} {'':10} {'':14} {np.mean(val_aucs):<10.4f} {np.mean(val_accs):<10.4f} {np.mean(stopped_epochs):<8.1f}\")\n",
        "print(f\"{'±Std':<6} {'':10} {'':14} {np.std(val_aucs):<10.4f} {np.std(val_accs):<10.4f} {np.std(stopped_epochs):<8.1f}\")\n",
        "\n",
        "# Summary table for paper\n",
        "print(f\"\\n\\nTable 2: Model Comparison (for paper)\")\n",
        "print(\"-\" * 65)\n",
        "print(f\"{'Model':<20} {'Val AUC':<16} {'Test AUC':<12} {'Params':<10}\")\n",
        "print(\"-\" * 65)\n",
        "# 🔧 CHANGEMENT: \"GraphKT M3\" → \"GraphKT M3a\"\n",
        "print(f\"{'GraphKT M3a':<20} {np.mean(val_aucs):.4f} ± {np.std(val_aucs):.4f}   {test_auc:<12.4f} {sum(p.numel() for p in model_final.parameters()):,}\")\n",
        "\n",
        "# Consistency check\n",
        "auc_range = np.max(val_aucs) - np.min(val_aucs)\n",
        "print(f\"\\n\\nConsistency Analysis:\")\n",
        "print(f\"  AUC range across folds: {auc_range:.4f}\")\n",
        "if auc_range < 0.03:\n",
        "    print(f\"  ✓ Highly consistent (range < 0.03)\")\n",
        "elif auc_range < 0.05:\n",
        "    print(f\"  ~ Moderately consistent (range < 0.05)\")\n",
        "else:\n",
        "    print(f\"  ⚠ High variance across folds - investigate fold differences\")\n",
        "\n",
        "print(f\"\\n  Coefficient of variation: {np.std(val_aucs)/np.mean(val_aucs)*100:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}