{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "OXYhnccdXdKY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fb46c93-485f-4fbd-9490-23095c1a8410"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.12/dist-packages (2.7.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2026.1.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "11hq0iBhW7Kb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfe46778-9b80-4aee-c1ae-026e2e7c1a76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "PyTorch version: 2.9.0+cu128\n",
            "Configuration loaded (M3 Final - Features + Weights + Dual Propagation)\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Cell 1: Imports and Configuration\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.nn import GCNConv, RGCNConv\n",
        "from torch_geometric.nn import MessagePassing  # ← Pour MasteryMessagePassing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "from collections import defaultdict\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configuration\n",
        "class Config:\n",
        "    # Data\n",
        "    SEED = 42\n",
        "    TEST_STUDENT_RATIO = 0.15      # 15% students for TEST (Split B)\n",
        "    VAL_STUDENT_RATIO = 0.15       # 15% of TRAIN students for VAL\n",
        "\n",
        "    # Model Architecture\n",
        "    FEATURE_DIM = 5                # Base features for Q, T, C (students: 5 + num_kcs)\n",
        "    EMBED_DIM = 32\n",
        "    HIDDEN_DIM = 64\n",
        "    NUM_GNN_LAYERS = 2\n",
        "    DROPOUT = 0.2\n",
        "    NUM_BASES = 2                  # For RGCN basis decomposition\n",
        "\n",
        "    # Training\n",
        "    BATCH_SIZE = 512               # Optimisé pour M3 Final\n",
        "    LEARNING_RATE = 1e-3\n",
        "    WEIGHT_DECAY = 0.01\n",
        "    EPOCHS = 100\n",
        "    PATIENCE = 10\n",
        "    GRAD_CLIP = 1.0\n",
        "\n",
        "    # Mastery (M3 Final specific)\n",
        "    MASTERY_INIT = 0.5             # Valeur init de mastery [0.5 ou 'global_mean']\n",
        "    LAMBDA_EMA = 0.1               # Learning rate mastery update (0.05, 0.1, 0.2)\n",
        "    MASTERY_GATING = 'identity'    # Gating function ['identity' ou 'sigmoid']\n",
        "    GATING_ALPHA = 2.0             # Si sigmoid, alpha parameter\n",
        "\n",
        "    # Device\n",
        "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "config = Config()\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "np.random.seed(config.SEED)\n",
        "torch.manual_seed(config.SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(config.SEED)\n",
        "\n",
        "print(f\"Device: {config.DEVICE}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Configuration loaded (M3 Final - Features + Weights + Dual Propagation)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "g3UDZq76XawB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3e9fd8c5-1f8a-478b-bcc0-071782d4590e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "DATASET OVERVIEW\n",
            "============================================================\n",
            "Shape: (809694, 19)\n",
            "\n",
            "Columns (19):\n",
            "   1. Row\n",
            "   2. Anon Student Id\n",
            "   3. Problem Hierarchy\n",
            "   4. Problem Name\n",
            "   5. Problem View\n",
            "   6. Step Name\n",
            "   7. Step Start Time\n",
            "   8. First Transaction Time\n",
            "   9. Correct Transaction Time\n",
            "  10. Step End Time\n",
            "  11. Step Duration (sec)\n",
            "  12. Correct Step Duration (sec)\n",
            "  13. Error Step Duration (sec)\n",
            "  14. Correct First Attempt\n",
            "  15. Incorrects\n",
            "  16. Hints\n",
            "  17. Corrects\n",
            "  18. KC(Default)\n",
            "  19. Opportunity(Default)\n",
            "\n",
            "============================================================\n",
            "FIRST 3 ROWS\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Row Anon Student Id            Problem Hierarchy Problem Name  \\\n",
              "0    1      0BrbPbwCMz  Unit ES_04, Section ES_04-1    EG4-FIXED   \n",
              "1    2      0BrbPbwCMz  Unit ES_04, Section ES_04-1    EG4-FIXED   \n",
              "2    3      0BrbPbwCMz  Unit ES_04, Section ES_04-1         EG40   \n",
              "\n",
              "   Problem View    Step Name        Step Start Time First Transaction Time  \\\n",
              "0             1  3(x+2) = 15  2005-09-09 12:24:35.0  2005-09-09 12:24:49.0   \n",
              "1             1      x+2 = 5  2005-09-09 12:25:15.0  2005-09-09 12:25:31.0   \n",
              "2             1    2-8y = -4  2005-09-09 12:25:36.0  2005-09-09 12:25:43.0   \n",
              "\n",
              "  Correct Transaction Time          Step End Time  Step Duration (sec)  \\\n",
              "0    2005-09-09 12:25:15.0  2005-09-09 12:25:15.0                 40.0   \n",
              "1    2005-09-09 12:25:31.0  2005-09-09 12:25:31.0                 16.0   \n",
              "2    2005-09-09 12:26:12.0  2005-09-09 12:26:12.0                 36.0   \n",
              "\n",
              "   Correct Step Duration (sec)  Error Step Duration (sec)  \\\n",
              "0                          NaN                       40.0   \n",
              "1                         16.0                        NaN   \n",
              "2                          NaN                       36.0   \n",
              "\n",
              "   Correct First Attempt  Incorrects  Hints  Corrects  \\\n",
              "0                      0           2      3         1   \n",
              "1                      1           0      0         1   \n",
              "2                      0           2      3         1   \n",
              "\n",
              "                                         KC(Default) Opportunity(Default)  \n",
              "0  [SkillRule: Eliminate Parens; {CLT nested; CLT...                    1  \n",
              "1  [SkillRule: Remove constant; {ax+b=c, positive...                 1~~1  \n",
              "2  [SkillRule: Remove constant; {ax+b=c, positive...                    2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-90749ed6-4671-4215-983a-3a7f26af73a8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Row</th>\n",
              "      <th>Anon Student Id</th>\n",
              "      <th>Problem Hierarchy</th>\n",
              "      <th>Problem Name</th>\n",
              "      <th>Problem View</th>\n",
              "      <th>Step Name</th>\n",
              "      <th>Step Start Time</th>\n",
              "      <th>First Transaction Time</th>\n",
              "      <th>Correct Transaction Time</th>\n",
              "      <th>Step End Time</th>\n",
              "      <th>Step Duration (sec)</th>\n",
              "      <th>Correct Step Duration (sec)</th>\n",
              "      <th>Error Step Duration (sec)</th>\n",
              "      <th>Correct First Attempt</th>\n",
              "      <th>Incorrects</th>\n",
              "      <th>Hints</th>\n",
              "      <th>Corrects</th>\n",
              "      <th>KC(Default)</th>\n",
              "      <th>Opportunity(Default)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0BrbPbwCMz</td>\n",
              "      <td>Unit ES_04, Section ES_04-1</td>\n",
              "      <td>EG4-FIXED</td>\n",
              "      <td>1</td>\n",
              "      <td>3(x+2) = 15</td>\n",
              "      <td>2005-09-09 12:24:35.0</td>\n",
              "      <td>2005-09-09 12:24:49.0</td>\n",
              "      <td>2005-09-09 12:25:15.0</td>\n",
              "      <td>2005-09-09 12:25:15.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>[SkillRule: Eliminate Parens; {CLT nested; CLT...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0BrbPbwCMz</td>\n",
              "      <td>Unit ES_04, Section ES_04-1</td>\n",
              "      <td>EG4-FIXED</td>\n",
              "      <td>1</td>\n",
              "      <td>x+2 = 5</td>\n",
              "      <td>2005-09-09 12:25:15.0</td>\n",
              "      <td>2005-09-09 12:25:31.0</td>\n",
              "      <td>2005-09-09 12:25:31.0</td>\n",
              "      <td>2005-09-09 12:25:31.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[SkillRule: Remove constant; {ax+b=c, positive...</td>\n",
              "      <td>1~~1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0BrbPbwCMz</td>\n",
              "      <td>Unit ES_04, Section ES_04-1</td>\n",
              "      <td>EG40</td>\n",
              "      <td>1</td>\n",
              "      <td>2-8y = -4</td>\n",
              "      <td>2005-09-09 12:25:36.0</td>\n",
              "      <td>2005-09-09 12:25:43.0</td>\n",
              "      <td>2005-09-09 12:26:12.0</td>\n",
              "      <td>2005-09-09 12:26:12.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>[SkillRule: Remove constant; {ax+b=c, positive...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90749ed6-4671-4215-983a-3a7f26af73a8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-90749ed6-4671-4215-983a-3a7f26af73a8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-90749ed6-4671-4215-983a-3a7f26af73a8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(df_raw['Correct First Attempt']\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Row\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Anon Student Id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"0BrbPbwCMz\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Problem Hierarchy\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Unit ES_04, Section ES_04-1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Problem Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"EG40\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Problem View\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Step Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"3(x+2) = 15\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Step Start Time\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"2005-09-09 12:24:35.0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"First Transaction Time\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"2005-09-09 12:24:49.0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Correct Transaction Time\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"2005-09-09 12:25:15.0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Step End Time\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"2005-09-09 12:25:15.0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Step Duration (sec)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.858201014657274,\n        \"min\": 16.0,\n        \"max\": 40.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          40.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Correct Step Duration (sec)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 16.0,\n        \"max\": 16.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          16.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Error Step Duration (sec)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.8284271247461903,\n        \"min\": 36.0,\n        \"max\": 40.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          36.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Correct First Attempt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Incorrects\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hints\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Corrects\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"KC(Default)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"[SkillRule: Eliminate Parens; {CLT nested; CLT nested, parens; Distribute Mult right; Distribute Mult left; (+/-x +/-a)/b=c, mult; (+/-x +/-a)*b=c, div; [var expr]/[const expr] = [const expr], multiply; Distribute Division left; Distribute Division right; Distribute both mult left; Distribute both mult right; Distribute both divide left; Distribute both divide right; Distribute subex}]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Opportunity(Default)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "DATA TYPES\n",
            "============================================================\n",
            "Row                              int64\n",
            "Anon Student Id                 object\n",
            "Problem Hierarchy               object\n",
            "Problem Name                    object\n",
            "Problem View                     int64\n",
            "Step Name                       object\n",
            "Step Start Time                 object\n",
            "First Transaction Time          object\n",
            "Correct Transaction Time        object\n",
            "Step End Time                   object\n",
            "Step Duration (sec)            float64\n",
            "Correct Step Duration (sec)    float64\n",
            "Error Step Duration (sec)      float64\n",
            "Correct First Attempt            int64\n",
            "Incorrects                       int64\n",
            "Hints                            int64\n",
            "Corrects                         int64\n",
            "KC(Default)                     object\n",
            "Opportunity(Default)            object\n",
            "dtype: object\n",
            "\n",
            "============================================================\n",
            "MISSING VALUES\n",
            "============================================================\n",
            "                             Missing  Percent\n",
            "Step Start Time                  919     0.11\n",
            "Correct Transaction Time       25851     3.19\n",
            "Step Duration (sec)              919     0.11\n",
            "Correct Step Duration (sec)   189565    23.41\n",
            "Error Step Duration (sec)     621048    76.70\n",
            "KC(Default)                   202669    25.03\n",
            "Opportunity(Default)          202669    25.03\n",
            "\n",
            "============================================================\n",
            "KEY STATISTICS\n",
            "============================================================\n",
            "Total interactions: 809,694\n",
            "Unique students: 574\n",
            "Unique problems (questions): 1,084\n",
            "Unique steps: 210,710\n",
            "Unique KC(Default): 436\n",
            "KC(Default) missing: 202,669 (25.03%)\n",
            "\n",
            "============================================================\n",
            "TARGET DISTRIBUTION (Correct First Attempt)\n",
            "============================================================\n",
            "Correct First Attempt\n",
            "1    0.7665\n",
            "0    0.2335\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Cell 2: Load and Explore Dataset\n",
        "# =============================================================================\n",
        "\n",
        "# Load the Algebra 2005-2006 dataset\n",
        "DATA_PATH = \"algebra_2005_2006_train.txt\"\n",
        "\n",
        "# Load with tab separator (standard format for this dataset)\n",
        "df_raw = pd.read_csv(DATA_PATH, sep='\\t', low_memory=False)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"DATASET OVERVIEW\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Shape: {df_raw.shape}\")\n",
        "print(f\"\\nColumns ({len(df_raw.columns)}):\")\n",
        "for i, col in enumerate(df_raw.columns):\n",
        "    print(f\"  {i+1:2d}. {col}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"FIRST 3 ROWS\")\n",
        "print(\"=\" * 60)\n",
        "display(df_raw.head(3))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"DATA TYPES\")\n",
        "print(\"=\" * 60)\n",
        "print(df_raw.dtypes)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"MISSING VALUES\")\n",
        "print(\"=\" * 60)\n",
        "missing = df_raw.isnull().sum()\n",
        "missing_pct = (missing / len(df_raw) * 100).round(2)\n",
        "missing_df = pd.DataFrame({'Missing': missing, 'Percent': missing_pct})\n",
        "print(missing_df[missing_df['Missing'] > 0])\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"KEY STATISTICS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Total interactions: {len(df_raw):,}\")\n",
        "print(f\"Unique students: {df_raw['Anon Student Id'].nunique():,}\")\n",
        "print(f\"Unique problems (questions): {df_raw['Problem Name'].nunique():,}\")\n",
        "print(f\"Unique steps: {df_raw[['Problem Name', 'Step Name']].drop_duplicates().shape[0]:,}\")\n",
        "print(f\"Unique KC(Default): {df_raw['KC(Default)'].nunique():,}\")\n",
        "print(f\"KC(Default) missing: {df_raw['KC(Default)'].isnull().sum():,} ({df_raw['KC(Default)'].isnull().mean()*100:.2f}%)\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TARGET DISTRIBUTION (Correct First Attempt)\")\n",
        "print(\"=\" * 60)\n",
        "print(df_raw['Correct First Attempt'].value_counts(normalize=True).round(4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "id": "4X0IrVL6X5Du",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "77703602-a76a-40ac-e7fd-c3fb41dfc934"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "STEP 1: Drop rows with missing critical fields (NOT KC)\n",
            "============================================================\n",
            "Dropped 0 rows (0.00%)\n",
            "Remaining: 809,694 rows\n",
            "\n",
            "============================================================\n",
            "STEP 2: Handle missing KC(Default)\n",
            "============================================================\n",
            "Missing KC(Default): 202,669 (25.03%)\n",
            "Filled with 'UNKNOWN_KC' token\n",
            "\n",
            "============================================================\n",
            "STEP 3: Create canonical identifiers\n",
            "============================================================\n",
            "Unique students: 574\n",
            "Unique questions: 1,084\n",
            "Unique steps: 210,710\n",
            "Unique KCs (including UNKNOWN): 437\n",
            "\n",
            "============================================================\n",
            "STEP 4: Parse timestamps and create temporal ordering\n",
            "============================================================\n",
            "Rows with missing timestamp after fallback: 0\n",
            "Final dataset size: 809,694 rows\n",
            "\n",
            "============================================================\n",
            "STEP 5: Process behavioral features\n",
            "============================================================\n",
            "Median duration: 11.00 sec\n",
            "Log duration range: [0.00, 7.90]\n",
            "\n",
            "============================================================\n",
            "STEP 6: Final dataset summary\n",
            "============================================================\n",
            "Total interactions: 809,694\n",
            "Unique students: 574\n",
            "Unique questions: 1,084\n",
            "Unique steps: 210,710\n",
            "Unique KCs: 437\n",
            "  - Real KCs: 607,025 interactions\n",
            "  - UNKNOWN_KC: 202,669 interactions\n",
            "\n",
            "Target distribution:\n",
            "correct\n",
            "1    0.7665\n",
            "0    0.2335\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "============================================================\n",
            "STEP 7: Verify temporal ordering\n",
            "============================================================\n",
            "Sample student '02ZjVTxC34' first 5 interactions:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   time_idx           timestamp question_id  \\\n",
              "0         0 2005-09-06 13:00:23  LDEMO_WKST   \n",
              "1         1 2005-09-06 13:00:44  LDEMO_WKST   \n",
              "2         2 2005-09-06 13:01:12  LDEMO_WKST   \n",
              "3         3 2005-09-06 13:01:46  LDEMO_WKST   \n",
              "4         4 2005-09-06 13:02:27  LDEMO_WKST   \n",
              "\n",
              "                                        kc_id  correct  \n",
              "0                                  UNKNOWN_KC        1  \n",
              "1                           Identifying units        1  \n",
              "2                                  UNKNOWN_KC        1  \n",
              "3                           Identifying units        1  \n",
              "4  Entering a given~~Convert unit, multiplier        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5d5949d4-dde2-46fe-b5cb-c6e1abb31352\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time_idx</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>question_id</th>\n",
              "      <th>kc_id</th>\n",
              "      <th>correct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2005-09-06 13:00:23</td>\n",
              "      <td>LDEMO_WKST</td>\n",
              "      <td>UNKNOWN_KC</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2005-09-06 13:00:44</td>\n",
              "      <td>LDEMO_WKST</td>\n",
              "      <td>Identifying units</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2005-09-06 13:01:12</td>\n",
              "      <td>LDEMO_WKST</td>\n",
              "      <td>UNKNOWN_KC</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2005-09-06 13:01:46</td>\n",
              "      <td>LDEMO_WKST</td>\n",
              "      <td>Identifying units</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2005-09-06 13:02:27</td>\n",
              "      <td>LDEMO_WKST</td>\n",
              "      <td>Entering a given~~Convert unit, multiplier</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d5949d4-dde2-46fe-b5cb-c6e1abb31352')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5d5949d4-dde2-46fe-b5cb-c6e1abb31352 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5d5949d4-dde2-46fe-b5cb-c6e1abb31352');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_9119b665-9072-48ae-a7d4-8fa12dd1501c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('sample_seq')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9119b665-9072-48ae-a7d4-8fa12dd1501c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('sample_seq');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "sample_seq",
              "summary": "{\n  \"name\": \"sample_seq\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"time_idx\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2005-09-06 13:00:23\",\n        \"max\": \"2005-09-06 13:02:27\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2005-09-06 13:00:44\",\n          \"2005-09-06 13:02:27\",\n          \"2005-09-06 13:01:12\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"LDEMO_WKST\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"kc_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"UNKNOWN_KC\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"correct\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Cell 3 (Corrected): Data Cleaning - Keep Missing KC as UNKNOWN\n",
        "# =============================================================================\n",
        "\n",
        "# Start with a copy\n",
        "df = df_raw.copy()\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"STEP 1: Drop rows with missing critical fields (NOT KC)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Critical fields: student, step, target (NOT KC - we'll handle separately)\n",
        "critical_cols = ['Anon Student Id', 'Problem Name', 'Step Name', 'Correct First Attempt']\n",
        "before_drop = len(df)\n",
        "df = df.dropna(subset=critical_cols)\n",
        "after_drop = len(df)\n",
        "print(f\"Dropped {before_drop - after_drop:,} rows ({(before_drop - after_drop)/before_drop*100:.2f}%)\")\n",
        "print(f\"Remaining: {after_drop:,} rows\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 2: Handle missing KC(Default)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "kc_missing_before = df['KC(Default)'].isnull().sum()\n",
        "print(f\"Missing KC(Default): {kc_missing_before:,} ({kc_missing_before/len(df)*100:.2f}%)\")\n",
        "\n",
        "# Fill missing KC with special token\n",
        "df['KC(Default)'] = df['KC(Default)'].fillna('UNKNOWN_KC')\n",
        "print(f\"Filled with 'UNKNOWN_KC' token\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 3: Create canonical identifiers\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Student ID\n",
        "df['student_id'] = df['Anon Student Id'].astype(str).str.strip()\n",
        "\n",
        "# Question ID (Problem Name)\n",
        "df['question_id'] = df['Problem Name'].astype(str).str.strip()\n",
        "\n",
        "# Step ID (Problem Name + Step Name)\n",
        "df['step_id'] = df['Problem Name'].astype(str).str.strip() + \"||\" + df['Step Name'].astype(str).str.strip()\n",
        "\n",
        "# KC ID (KC(Default) as composite string)\n",
        "df['kc_id'] = df['KC(Default)'].astype(str).str.strip()\n",
        "\n",
        "# Target\n",
        "df['correct'] = df['Correct First Attempt'].astype(int)\n",
        "\n",
        "print(f\"Unique students: {df['student_id'].nunique():,}\")\n",
        "print(f\"Unique questions: {df['question_id'].nunique():,}\")\n",
        "print(f\"Unique steps: {df['step_id'].nunique():,}\")\n",
        "print(f\"Unique KCs (including UNKNOWN): {df['kc_id'].nunique():,}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 4: Parse timestamps and create temporal ordering\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Parse First Transaction Time (primary timestamp)\n",
        "df['timestamp'] = pd.to_datetime(df['First Transaction Time'], errors='coerce')\n",
        "\n",
        "# Fallback to Step Start Time\n",
        "mask_missing_ts = df['timestamp'].isnull()\n",
        "df.loc[mask_missing_ts, 'timestamp'] = pd.to_datetime(\n",
        "    df.loc[mask_missing_ts, 'Step Start Time'], errors='coerce'\n",
        ")\n",
        "\n",
        "# Check remaining missing timestamps\n",
        "ts_missing = df['timestamp'].isnull().sum()\n",
        "print(f\"Rows with missing timestamp after fallback: {ts_missing}\")\n",
        "\n",
        "if ts_missing > 0:\n",
        "    # Drop only these (should be minimal)\n",
        "    df = df.dropna(subset=['timestamp'])\n",
        "    print(f\"Dropped {ts_missing} rows with no valid timestamp\")\n",
        "\n",
        "# Sort by student and timestamp\n",
        "df = df.sort_values(['student_id', 'timestamp']).reset_index(drop=True)\n",
        "\n",
        "# Create time index within each student\n",
        "df['time_idx'] = df.groupby('student_id').cumcount()\n",
        "\n",
        "print(f\"Final dataset size: {len(df):,} rows\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 5: Process behavioral features\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Fill missing durations with median\n",
        "duration_col = 'Step Duration (sec)'\n",
        "median_duration = df[duration_col].median()\n",
        "df[duration_col] = df[duration_col].fillna(median_duration)\n",
        "\n",
        "# Log transform duration\n",
        "df['log_duration'] = np.log1p(df[duration_col].clip(lower=0))\n",
        "\n",
        "# Clip extreme values\n",
        "df['Incorrects'] = df['Incorrects'].clip(upper=10)\n",
        "df['Hints'] = df['Hints'].clip(upper=10)\n",
        "\n",
        "print(f\"Median duration: {median_duration:.2f} sec\")\n",
        "print(f\"Log duration range: [{df['log_duration'].min():.2f}, {df['log_duration'].max():.2f}]\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 6: Final dataset summary\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"Total interactions: {len(df):,}\")\n",
        "print(f\"Unique students: {df['student_id'].nunique():,}\")\n",
        "print(f\"Unique questions: {df['question_id'].nunique():,}\")\n",
        "print(f\"Unique steps: {df['step_id'].nunique():,}\")\n",
        "print(f\"Unique KCs: {df['kc_id'].nunique():,}\")\n",
        "print(f\"  - Real KCs: {(df['kc_id'] != 'UNKNOWN_KC').sum():,} interactions\")\n",
        "print(f\"  - UNKNOWN_KC: {(df['kc_id'] == 'UNKNOWN_KC').sum():,} interactions\")\n",
        "\n",
        "print(f\"\\nTarget distribution:\")\n",
        "print(df['correct'].value_counts(normalize=True).round(4))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 7: Verify temporal ordering\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "sample_student = df['student_id'].iloc[0]\n",
        "sample_seq = df[df['student_id'] == sample_student][['time_idx', 'timestamp', 'question_id', 'kc_id', 'correct']].head(5)\n",
        "print(f\"Sample student '{sample_student}' first 5 interactions:\")\n",
        "display(sample_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "LvLbzcxFo-pm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfc4be0b-8932-4d4d-a0e7-a610b2cda0ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "STEP 1: SEPARATE TEST STUDENTS (HELD OUT ENTIRELY)\n",
            "============================================================\n",
            "Total students: 574\n",
            "\n",
            "TEST set (held out):\n",
            "  Students: 87 (15.2%)\n",
            "  Interactions: 118,261\n",
            "\n",
            "Non-test (enters K-Fold CV):\n",
            "  Students: 487 (84.8%)\n",
            "  Interactions: 691,433\n",
            "\n",
            "============================================================\n",
            "STEP 2: DEFINE 5-FOLD STUDENT-LEVEL SPLITS\n",
            "============================================================\n",
            "\n",
            "Fold 1:\n",
            "  TRAIN: 389 students\n",
            "  VAL:   98 students\n",
            "\n",
            "Fold 2:\n",
            "  TRAIN: 389 students\n",
            "  VAL:   98 students\n",
            "\n",
            "Fold 3:\n",
            "  TRAIN: 390 students\n",
            "  VAL:   97 students\n",
            "\n",
            "Fold 4:\n",
            "  TRAIN: 390 students\n",
            "  VAL:   97 students\n",
            "\n",
            "Fold 5:\n",
            "  TRAIN: 390 students\n",
            "  VAL:   97 students\n",
            "\n",
            "✓ All folds verified: no student overlap, no test leakage\n",
            "✓ TEST set (87 students) completely isolated\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Cell 4: Separate TEST Set + 5-Fold Student-Level CV Setup\n",
        "# =============================================================================\n",
        "\n",
        "import time\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from collections import defaultdict\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"STEP 1: SEPARATE TEST STUDENTS (HELD OUT ENTIRELY)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "all_students = df['student_id'].unique()\n",
        "n_students = len(all_students)\n",
        "print(f\"Total students: {n_students}\")\n",
        "\n",
        "# Hold out 15% of students as TEST - NEVER touched during CV\n",
        "non_test_students, test_students = train_test_split(\n",
        "    all_students,\n",
        "    test_size=config.TEST_STUDENT_RATIO,\n",
        "    random_state=config.SEED\n",
        ")\n",
        "\n",
        "df_test_final = df[df['student_id'].isin(test_students)].copy()\n",
        "df_non_test = df[df['student_id'].isin(non_test_students)].copy()\n",
        "\n",
        "print(f\"\\nTEST set (held out):\")\n",
        "print(f\"  Students: {len(test_students)} ({len(test_students)/n_students*100:.1f}%)\")\n",
        "print(f\"  Interactions: {len(df_test_final):,}\")\n",
        "\n",
        "print(f\"\\nNon-test (enters K-Fold CV):\")\n",
        "print(f\"  Students: {len(non_test_students)} ({len(non_test_students)/n_students*100:.1f}%)\")\n",
        "print(f\"  Interactions: {len(df_non_test):,}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STEP 2: DEFINE 5-FOLD STUDENT-LEVEL SPLITS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=config.SEED)\n",
        "\n",
        "fold_assignments = {}\n",
        "for fold_idx, (train_indices, val_indices) in enumerate(kf.split(non_test_students)):\n",
        "    train_studs = non_test_students[train_indices]\n",
        "    val_studs = non_test_students[val_indices]\n",
        "    fold_assignments[fold_idx] = {\n",
        "        'train_students': train_studs,\n",
        "        'val_students': val_studs\n",
        "    }\n",
        "    print(f\"\\nFold {fold_idx+1}:\")\n",
        "    print(f\"  TRAIN: {len(train_studs)} students\")\n",
        "    print(f\"  VAL:   {len(val_studs)} students\")\n",
        "\n",
        "    # Verify no overlap\n",
        "    overlap = set(train_studs) & set(val_studs)\n",
        "    assert len(overlap) == 0, f\"LEAK in fold {fold_idx+1}!\"\n",
        "\n",
        "    # Verify no test leakage\n",
        "    test_leak = set(train_studs) & set(test_students)\n",
        "    assert len(test_leak) == 0, f\"TEST LEAK in fold {fold_idx+1}!\"\n",
        "\n",
        "print(\"\\n✓ All folds verified: no student overlap, no test leakage\")\n",
        "print(f\"✓ TEST set ({len(test_students)} students) completely isolated\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "id": "fiDbwzUto-pm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a73040a2-98e5-484c-9264-df1e812518b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "✓ ALL PIPELINE FUNCTIONS DEFINED (M3 FINAL VERSION - FIXED)\n",
            "============================================================\n",
            "  - build_entity_mappings() (unchanged)\n",
            "  - build_graph() (unchanged)\n",
            "  - compute_node_features_with_mastery() ⭐ NEW + FIXED\n",
            "  - GraphKTMinimal ⭐ FIXED (student encoder + mastery matrix)\n",
            "  - MasteryMessagePassing (mastery-weighted edges)\n",
            "  - KTDatasetPure (unchanged)\n",
            "  - train_epoch() / evaluate() (unchanged)\n",
            "  - run_single_fold() ⭐ MODIFIED (recalc features each epoch)\n",
            "============================================================\n",
            "FIXES APPLIED:\n",
            "  ✅ mastery_matrix includes UNK KC: [num_students, num_kcs]\n",
            "  ✅ student_encoder input_dim: feature_dim + num_kcs\n",
            "  ✅ mastery moved to CPU before concatenation\n",
            "============================================================\n",
            "M3 FINAL = M3a Features + M3b Weights + Dual Propagation\n",
            "============================================================\n",
            "Ready for 5-Fold Cross-Validation! 🚀\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Cell 5: Complete Pipeline Functions (M3 FINAL - Features + Weights + Dual)\n",
        "# =============================================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.nn import GCNConv, RGCNConv, MessagePassing\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "from collections import defaultdict\n",
        "import time\n",
        "\n",
        "NUM_FEATURES = 5\n",
        "\n",
        "# ============================================================\n",
        "# FUNCTION 1: Build Entity Mappings (UNCHANGED)\n",
        "# ============================================================\n",
        "def build_entity_mappings(df_train):\n",
        "    train_students = sorted(df_train['student_id'].unique())\n",
        "    train_questions = sorted(df_train['question_id'].unique())\n",
        "    train_steps = sorted(df_train['step_id'].unique())\n",
        "    train_kcs = sorted(df_train['kc_id'].unique())\n",
        "\n",
        "    stu2idx = {s: i for i, s in enumerate(train_students)}\n",
        "    q2idx = {q: i for i, q in enumerate(train_questions)}\n",
        "    t2idx = {t: i for i, t in enumerate(train_steps)}\n",
        "    c2idx = {c: i for i, c in enumerate(train_kcs)}\n",
        "\n",
        "    unk_indices = {\n",
        "        'student': len(train_students),\n",
        "        'question': len(train_questions),\n",
        "        'step': len(train_steps),\n",
        "        'kc': len(train_kcs)\n",
        "    }\n",
        "\n",
        "    entity_counts = {\n",
        "        'num_students': len(train_students) + 1,\n",
        "        'num_questions': len(train_questions) + 1,\n",
        "        'num_steps': len(train_steps) + 1,\n",
        "        'num_kcs': len(train_kcs) + 1,\n",
        "    }\n",
        "\n",
        "    mappings = {\n",
        "        'stu2idx': stu2idx, 'q2idx': q2idx,\n",
        "        't2idx': t2idx, 'c2idx': c2idx\n",
        "    }\n",
        "\n",
        "    return mappings, entity_counts, unk_indices\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# FUNCTION 2: Build Heterogeneous Graph (UNCHANGED)\n",
        "# ============================================================\n",
        "def build_graph(df_train, mappings, entity_counts, unk_indices):\n",
        "    stu2idx = mappings['stu2idx']\n",
        "    q2idx = mappings['q2idx']\n",
        "    t2idx = mappings['t2idx']\n",
        "    c2idx = mappings['c2idx']\n",
        "\n",
        "    data = HeteroData()\n",
        "\n",
        "    data['student'].num_nodes = entity_counts['num_students']\n",
        "    data['question'].num_nodes = entity_counts['num_questions']\n",
        "    data['step'].num_nodes = entity_counts['num_steps']\n",
        "    data['kc'].num_nodes = entity_counts['num_kcs']\n",
        "\n",
        "    qt_pairs = df_train[['question_id', 'step_id']].drop_duplicates()\n",
        "    q_idx_list = [q2idx[r['question_id']] for _, r in qt_pairs.iterrows()]\n",
        "    t_idx_list = [t2idx[r['step_id']] for _, r in qt_pairs.iterrows()]\n",
        "\n",
        "    data['question', 'contains', 'step'].edge_index = torch.tensor([q_idx_list, t_idx_list], dtype=torch.long)\n",
        "    data['step', 'belongs_to', 'question'].edge_index = torch.tensor([t_idx_list, q_idx_list], dtype=torch.long)\n",
        "\n",
        "    tc_pairs = df_train[['step_id', 'kc_id']].drop_duplicates()\n",
        "    t_idx_list2 = [t2idx[r['step_id']] for _, r in tc_pairs.iterrows()]\n",
        "    c_idx_list = [c2idx[r['kc_id']] for _, r in tc_pairs.iterrows()]\n",
        "\n",
        "    data['step', 'requires', 'kc'].edge_index = torch.tensor([t_idx_list2, c_idx_list], dtype=torch.long)\n",
        "    data['kc', 'required_by', 'step'].edge_index = torch.tensor([c_idx_list, t_idx_list2], dtype=torch.long)\n",
        "\n",
        "    sq_pairs = df_train[['student_id', 'question_id']].drop_duplicates()\n",
        "    s_idx_list = [stu2idx[r['student_id']] for _, r in sq_pairs.iterrows()]\n",
        "    q_idx_list2 = [q2idx[r['question_id']] for _, r in sq_pairs.iterrows()]\n",
        "\n",
        "    data['student', 'attempted', 'question'].edge_index = torch.tensor([s_idx_list, q_idx_list2], dtype=torch.long)\n",
        "    data['question', 'attempted_by', 'student'].edge_index = torch.tensor([q_idx_list2, s_idx_list], dtype=torch.long)\n",
        "\n",
        "    total_edges = sum(\n",
        "        data[et].edge_index.shape[1]\n",
        "        for et in data.edge_types\n",
        "    )\n",
        "\n",
        "    return data, total_edges\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# FUNCTION 3: Compute Node Features WITH MASTERY (M3 FINAL - FIXED)\n",
        "# ============================================================\n",
        "def compute_node_features_with_mastery(df_train, mappings, entity_counts, unk_indices, mastery_matrix):\n",
        "    \"\"\"\n",
        "    M3 FINAL: Compute features with mastery for students\n",
        "\n",
        "    Students: [5D stats + mastery_vector] = (5 + num_kcs)D\n",
        "    Others (Q, T, C): 5D stats only\n",
        "\n",
        "    Args:\n",
        "        mastery_matrix: [num_students, num_kcs] tensor with current mastery values\n",
        "\n",
        "    Returns:\n",
        "        feat_tensors: Dict with tensors for each entity type\n",
        "            - student: [num_students, 5 + num_kcs]\n",
        "            - question, step, kc: [num_entities, 5]\n",
        "    \"\"\"\n",
        "    # ✅ FIX: Include UNK KC\n",
        "    num_kcs = entity_counts['num_kcs']\n",
        "\n",
        "    # ✅ FIX: Move mastery to CPU for feature computation\n",
        "    mastery_cpu = mastery_matrix.cpu() if mastery_matrix.is_cuda else mastery_matrix\n",
        "\n",
        "    def compute_features_for_type(df, entity_col):\n",
        "        grouped = df.groupby(entity_col).agg({\n",
        "            'correct': ['count', 'mean'],\n",
        "            'log_duration': 'mean',\n",
        "            'Hints': 'mean',\n",
        "            'Incorrects': 'mean'\n",
        "        })\n",
        "        grouped.columns = ['freq', 'correct_rate', 'avg_log_dur', 'avg_hints', 'avg_incorrects']\n",
        "        grouped = grouped.reset_index()\n",
        "        grouped['difficulty'] = 1 - grouped['correct_rate']\n",
        "        grouped['log_freq'] = np.log1p(grouped['freq'])\n",
        "\n",
        "        features = {}\n",
        "        feat_cols = ['log_freq', 'difficulty', 'avg_log_dur', 'avg_hints', 'avg_incorrects']\n",
        "        for _, row in grouped.iterrows():\n",
        "            features[row[entity_col]] = row[feat_cols].values.astype(np.float32)\n",
        "        return features\n",
        "\n",
        "    def to_tensor_5d(features_dict, idx_map, num_with_unk, unk_idx):\n",
        "        \"\"\"Create 5D tensor (original)\"\"\"\n",
        "        tensor = torch.zeros(num_with_unk, NUM_FEATURES, dtype=torch.float32)\n",
        "        all_feats = []\n",
        "        for entity_id, idx in idx_map.items():\n",
        "            if entity_id in features_dict:\n",
        "                tensor[idx] = torch.tensor(features_dict[entity_id])\n",
        "                all_feats.append(features_dict[entity_id])\n",
        "        if all_feats:\n",
        "            tensor[unk_idx] = torch.tensor(np.mean(all_feats, axis=0))\n",
        "        return tensor\n",
        "\n",
        "    def to_tensor_with_mastery(features_dict, idx_map, num_with_unk, unk_idx, mastery_matrix):\n",
        "        \"\"\"Create [5D + mastery] tensor for students\"\"\"\n",
        "        # 5D features\n",
        "        tensor_5d = to_tensor_5d(features_dict, idx_map, num_with_unk, unk_idx)\n",
        "\n",
        "        # Concatenate with mastery (already on CPU)\n",
        "        tensor_full = torch.cat([tensor_5d, mastery_matrix], dim=1)  # [num_students, 5 + num_kcs]\n",
        "\n",
        "        return tensor_full\n",
        "\n",
        "    def normalize(tensor):\n",
        "        mean = tensor.mean(dim=0, keepdim=True)\n",
        "        std = tensor.std(dim=0, keepdim=True) + 1e-8\n",
        "        return (tensor - mean) / std\n",
        "\n",
        "    # Compute 5D stats for all entity types\n",
        "    stu_feats = compute_features_for_type(df_train, 'student_id')\n",
        "    q_feats = compute_features_for_type(df_train, 'question_id')\n",
        "    t_feats = compute_features_for_type(df_train, 'step_id')\n",
        "    c_feats = compute_features_for_type(df_train, 'kc_id')\n",
        "\n",
        "    # Students: [5D + mastery] - use CPU version\n",
        "    student_features = to_tensor_with_mastery(\n",
        "        stu_feats, mappings['stu2idx'],\n",
        "        entity_counts['num_students'], unk_indices['student'],\n",
        "        mastery_cpu  # ← Use CPU version\n",
        "    )\n",
        "\n",
        "    # Others: 5D only\n",
        "    feat_tensors = {\n",
        "        'student': normalize(student_features),  # [num_students, 5 + num_kcs]\n",
        "        'question': normalize(to_tensor_5d(q_feats, mappings['q2idx'], entity_counts['num_questions'], unk_indices['question'])),\n",
        "        'step': normalize(to_tensor_5d(t_feats, mappings['t2idx'], entity_counts['num_steps'], unk_indices['step'])),\n",
        "        'kc': normalize(to_tensor_5d(c_feats, mappings['c2idx'], entity_counts['num_kcs'], unk_indices['kc'])),\n",
        "    }\n",
        "\n",
        "    return feat_tensors\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# FUNCTION 4: Model Components\n",
        "# ============================================================\n",
        "\n",
        "class NodeEncoder(nn.Module):\n",
        "    \"\"\"Encode node features to embedding space\"\"\"\n",
        "    def __init__(self, input_dim, embed_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, embed_dim),\n",
        "            nn.LayerNorm(embed_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(embed_dim, embed_dim),\n",
        "            nn.LayerNorm(embed_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.encoder(x)\n",
        "\n",
        "\n",
        "class MasteryMessagePassing(MessagePassing):\n",
        "    \"\"\"\n",
        "    Message passing layer with mastery-weighted edges\n",
        "    Used for Student ↔ KC knowledge propagation\n",
        "    \"\"\"\n",
        "    def __init__(self, embed_dim, gating='identity'):\n",
        "        super().__init__(aggr='mean')\n",
        "        self.lin = nn.Linear(embed_dim, embed_dim)\n",
        "        self.gating = gating\n",
        "\n",
        "    def forward(self, h_nodes, edge_index, mastery_weights):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            h_nodes: [num_nodes, embed_dim] - all nodes (students + KCs)\n",
        "            edge_index: [2, num_edges] - S↔C edges\n",
        "            mastery_weights: [num_edges] - mastery weights ∈ [0,1]\n",
        "\n",
        "        Returns:\n",
        "            h_out: [num_nodes, embed_dim] - updated embeddings\n",
        "        \"\"\"\n",
        "        out = self.propagate(edge_index, x=h_nodes, mastery=mastery_weights)\n",
        "        return out\n",
        "\n",
        "    def message(self, x_j, mastery):\n",
        "        \"\"\"\n",
        "        x_j: neighbor features\n",
        "        mastery: edge weights\n",
        "        \"\"\"\n",
        "        return mastery.unsqueeze(-1) * self.lin(x_j)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# MODEL: GraphKT M3 FINAL (Features + Weights + Dual Propagation)\n",
        "# ============================================================\n",
        "\n",
        "class GraphKTMinimal(nn.Module):\n",
        "    \"\"\"\n",
        "    GraphKT M3 FINAL with:\n",
        "    - Student features: [5D + mastery] (from M3a)\n",
        "    - Block A: Structural Propagation (Q,T,C via RGCN) (from M3b)\n",
        "    - Block B: Knowledge Propagation (S↔C weighted by mastery) (from M3b)\n",
        "    - Dynamic feature updates each epoch (from M3a)\n",
        "    \"\"\"\n",
        "\n",
        "    NUM_RELATIONS_STRUCT = 4  # Q↔T, T↔C (4 relation types)\n",
        "\n",
        "    def __init__(self, num_students, num_questions, num_steps, num_kcs,\n",
        "                 feature_dim=5, embed_dim=32, hidden_dim=64,\n",
        "                 num_gnn_layers=2, dropout=0.2,\n",
        "                 mastery_init=0.5, mastery_gating='identity'):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_students = num_students\n",
        "        self.num_questions = num_questions\n",
        "        self.num_steps = num_steps\n",
        "        self.num_kcs = num_kcs\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "        # === Node Encoders ===\n",
        "        # ✅ FIX: Student encoder includes UNK KC\n",
        "        self.student_encoder = NodeEncoder(feature_dim + num_kcs, embed_dim, dropout)  # 5 + num_kcs\n",
        "        self.question_encoder = NodeEncoder(feature_dim, embed_dim, dropout)  # 5D\n",
        "        self.step_encoder = NodeEncoder(feature_dim, embed_dim, dropout)  # 5D\n",
        "        self.kc_encoder = NodeEncoder(feature_dim, embed_dim, dropout)  # 5D\n",
        "\n",
        "        # === BLOCK A: Structural Propagation (Q,T,C) ===\n",
        "        self.structural_rgcn = nn.ModuleList([\n",
        "            RGCNConv(\n",
        "                embed_dim, embed_dim,\n",
        "                num_relations=self.NUM_RELATIONS_STRUCT,\n",
        "                num_bases=2\n",
        "            )\n",
        "            for _ in range(num_gnn_layers)\n",
        "        ])\n",
        "        self.struct_norms = nn.ModuleList([\n",
        "            nn.LayerNorm(embed_dim) for _ in range(num_gnn_layers)\n",
        "        ])\n",
        "        self.struct_dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # === BLOCK B: Knowledge Propagation (S↔C with mastery) ===\n",
        "        self.knowledge_conv = MasteryMessagePassing(\n",
        "            embed_dim,\n",
        "            gating=mastery_gating\n",
        "        )\n",
        "\n",
        "        # === Fusion Layers ===\n",
        "        # Student: [h_s_base, h_s_knowledge] → embed_dim\n",
        "        self.fusion_student = nn.Sequential(\n",
        "            nn.Linear(embed_dim * 2, embed_dim),\n",
        "            nn.LayerNorm(embed_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        # KC: [h_c_structural, h_c_knowledge] → embed_dim\n",
        "        self.fusion_kc = nn.Sequential(\n",
        "            nn.Linear(embed_dim * 2, embed_dim),\n",
        "            nn.LayerNorm(embed_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        # === Prediction Head ===\n",
        "        pred_input_dim = embed_dim * 3  # [h_s*, h_t_struct, h_c*]\n",
        "        self.prediction_head = nn.Sequential(\n",
        "            nn.Linear(pred_input_dim, hidden_dim),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim // 2, 1)\n",
        "        )\n",
        "\n",
        "        # === Mastery Matrix ===\n",
        "        self.mastery_init = mastery_init\n",
        "        self.mastery_gating = mastery_gating\n",
        "        self.register_buffer('mastery_matrix', None)\n",
        "\n",
        "        # Gating parameter for sigmoid\n",
        "        if mastery_gating == 'sigmoid':\n",
        "            self.gating_alpha = nn.Parameter(torch.tensor(2.0))\n",
        "\n",
        "        # Cache\n",
        "        self._cached_struct_edges = None\n",
        "        self._cached_struct_types = None\n",
        "\n",
        "    def init_mastery_matrix(self, device):\n",
        "        \"\"\"Initialize mastery matrix (call once per fold)\"\"\"\n",
        "        # ✅ FIX: Include UNK KC in mastery matrix\n",
        "        self.mastery_matrix = torch.full(\n",
        "            (self.num_students, self.num_kcs),  # Include UNK\n",
        "            self.mastery_init,\n",
        "            dtype=torch.float32,\n",
        "            device=device\n",
        "        )\n",
        "        print(f\"  ✓ Mastery matrix initialized: [{self.num_students}, {self.num_kcs}] with value={self.mastery_init}\")\n",
        "\n",
        "    def _build_structural_edges(self, hetero_data, device):\n",
        "        \"\"\"Build edge_index and edge_type for Q,T,C (BLOCK A)\"\"\"\n",
        "        if self._cached_struct_edges is not None:\n",
        "            return self._cached_struct_edges, self._cached_struct_types\n",
        "\n",
        "        all_edges = []\n",
        "        all_types = []\n",
        "\n",
        "        # ✓ LOCAL offsets for H_struct = [Q, T, C]\n",
        "        question_offset_local = 0\n",
        "        step_offset_local = self.num_questions\n",
        "        kc_offset_local = self.num_questions + self.num_steps\n",
        "\n",
        "        # Relation 0: Q → T (contains)\n",
        "        q_t = hetero_data['question', 'contains', 'step'].edge_index.clone()\n",
        "        q_t[0] += question_offset_local\n",
        "        q_t[1] += step_offset_local\n",
        "        all_edges.append(q_t)\n",
        "        all_types.append(torch.zeros(q_t.size(1), dtype=torch.long))\n",
        "\n",
        "        # Relation 1: T → Q (belongs_to)\n",
        "        t_q = hetero_data['step', 'belongs_to', 'question'].edge_index.clone()\n",
        "        t_q[0] += step_offset_local\n",
        "        t_q[1] += question_offset_local\n",
        "        all_edges.append(t_q)\n",
        "        all_types.append(torch.ones(t_q.size(1), dtype=torch.long))\n",
        "\n",
        "        # Relation 2: T → C (requires)\n",
        "        t_c = hetero_data['step', 'requires', 'kc'].edge_index.clone()\n",
        "        t_c[0] += step_offset_local\n",
        "        t_c[1] += kc_offset_local\n",
        "        all_edges.append(t_c)\n",
        "        all_types.append(torch.full((t_c.size(1),), 2, dtype=torch.long))\n",
        "\n",
        "        # Relation 3: C → T (required_by)\n",
        "        c_t = hetero_data['kc', 'required_by', 'step'].edge_index.clone()\n",
        "        c_t[0] += kc_offset_local\n",
        "        c_t[1] += step_offset_local\n",
        "        all_edges.append(c_t)\n",
        "        all_types.append(torch.full((c_t.size(1),), 3, dtype=torch.long))\n",
        "\n",
        "        self._cached_struct_edges = torch.cat(all_edges, dim=1).to(device)\n",
        "        self._cached_struct_types = torch.cat(all_types, dim=0).to(device)\n",
        "\n",
        "        return self._cached_struct_edges, self._cached_struct_types\n",
        "\n",
        "    def _build_sc_edges_batch(self, student_idx, kc_idx, device):\n",
        "        \"\"\"\n",
        "        Build S↔C edge_index for batch with mastery weights\n",
        "\n",
        "        Returns:\n",
        "            edge_index: [2, 2*batch_size]\n",
        "            mastery_weights: [2*batch_size]\n",
        "        \"\"\"\n",
        "        # ✓ LOCAL offset for H_know = [S, C]\n",
        "        kc_offset_local = self.num_students\n",
        "\n",
        "        # S → C edges\n",
        "        edge_index_sc = torch.stack([student_idx, kc_idx + kc_offset_local], dim=0)\n",
        "        # C → S edges (reverse)\n",
        "        edge_index_cs = torch.stack([kc_idx + kc_offset_local, student_idx], dim=0)\n",
        "\n",
        "        # Concatenate\n",
        "        edge_index = torch.cat([edge_index_sc, edge_index_cs], dim=1).to(device)\n",
        "\n",
        "        # Lookup mastery weights (VECTORIZED)\n",
        "        mastery_weights_sc = self.mastery_matrix[student_idx, kc_idx]\n",
        "        mastery_weights_cs = mastery_weights_sc.clone()\n",
        "\n",
        "        mastery_weights = torch.cat([mastery_weights_sc, mastery_weights_cs])\n",
        "\n",
        "        # Apply gating function\n",
        "        if self.mastery_gating == 'sigmoid':\n",
        "            mastery_weights = torch.sigmoid(\n",
        "                self.gating_alpha * (mastery_weights - 0.5)\n",
        "            )\n",
        "\n",
        "        return edge_index, mastery_weights\n",
        "\n",
        "    def forward(self, hetero_data, student_idx, step_idx, kc_idx, device):\n",
        "        \"\"\"\n",
        "        Forward pass with Structural + Knowledge propagation\n",
        "        NO event features to prevent leakage\n",
        "        \"\"\"\n",
        "        # === 1. Encode Nodes ===\n",
        "        h_s_base = self.student_encoder(hetero_data['student'].x.to(device))\n",
        "        h_q = self.question_encoder(hetero_data['question'].x.to(device))\n",
        "        h_t = self.step_encoder(hetero_data['step'].x.to(device))\n",
        "        h_c_base = self.kc_encoder(hetero_data['kc'].x.to(device))\n",
        "\n",
        "        # === 2. BLOCK A: Structural Propagation (Q,T,C) ===\n",
        "        H_struct = torch.cat([h_q, h_t, h_c_base], dim=0)\n",
        "        edge_index_struct, edge_type_struct = self._build_structural_edges(\n",
        "            hetero_data, device\n",
        "        )\n",
        "\n",
        "        for layer, norm in zip(self.structural_rgcn, self.struct_norms):\n",
        "            H_new = layer(H_struct, edge_index_struct, edge_type_struct)\n",
        "            H_new = norm(H_new)\n",
        "            H_new = F.relu(H_new)\n",
        "            H_new = self.struct_dropout(H_new)\n",
        "            H_struct = H_struct + H_new  # Residual connection\n",
        "\n",
        "        # Extract h_t^struct, h_c^struct\n",
        "        num_questions = h_q.size(0)\n",
        "        num_steps = h_t.size(0)\n",
        "        h_t_struct = H_struct[num_questions : num_questions + num_steps]\n",
        "        h_c_struct = H_struct[num_questions + num_steps :]\n",
        "\n",
        "        # === 3. BLOCK B: Knowledge Propagation (S↔C with mastery) ===\n",
        "        edge_index_sc, mastery_weights = self._build_sc_edges_batch(\n",
        "            student_idx, kc_idx, device\n",
        "        )\n",
        "\n",
        "        # Combine S + C nodes\n",
        "        H_know = torch.cat([h_s_base, h_c_base], dim=0)\n",
        "\n",
        "        # Message passing with mastery weighting\n",
        "        H_know = self.knowledge_conv(H_know, edge_index_sc, mastery_weights)\n",
        "\n",
        "        # Split back\n",
        "        h_s_know = H_know[:self.num_students]\n",
        "        h_c_know = H_know[self.num_students:]\n",
        "\n",
        "        # === 4. Fusion ===\n",
        "        # Student: [h_s_base, h_s_knowledge]\n",
        "        h_s_batch = h_s_base[student_idx]\n",
        "        h_s_know_batch = h_s_know[student_idx]\n",
        "        h_s_fused = self.fusion_student(\n",
        "            torch.cat([h_s_batch, h_s_know_batch], dim=-1)\n",
        "        )\n",
        "\n",
        "        # Step: structural only\n",
        "        h_t_batch = h_t_struct[step_idx]\n",
        "\n",
        "        # KC: [h_c_structural, h_c_knowledge]\n",
        "        h_c_struct_batch = h_c_struct[kc_idx]\n",
        "        h_c_know_batch = h_c_know[kc_idx]\n",
        "        h_c_fused = self.fusion_kc(\n",
        "            torch.cat([h_c_struct_batch, h_c_know_batch], dim=-1)\n",
        "        )\n",
        "\n",
        "        # === 5. Prediction ===\n",
        "        combined = torch.cat([h_s_fused, h_t_batch, h_c_fused], dim=-1)\n",
        "        logits = self.prediction_head(combined).squeeze(-1)\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def update_mastery_online(self, student_idx, kc_idx, y_true, lambda_ema):\n",
        "        \"\"\"\n",
        "        Update mastery AFTER observing outcome (prevents leakage)\n",
        "\n",
        "        Args:\n",
        "            student_idx: [batch] student indices\n",
        "            kc_idx: [batch] KC indices\n",
        "            y_true: [batch] outcomes (0 or 1)\n",
        "            lambda_ema: learning rate for EMA update\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            # EMA update: M ← (1-λ)M + λy\n",
        "            old_mastery = self.mastery_matrix[student_idx, kc_idx]\n",
        "            new_mastery = (1 - lambda_ema) * old_mastery + lambda_ema * y_true\n",
        "            self.mastery_matrix[student_idx, kc_idx] = new_mastery\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# FUNCTION 5: Dataset (UNCHANGED)\n",
        "# ============================================================\n",
        "\n",
        "class KTDatasetPure(Dataset):\n",
        "    \"\"\"Dataset for Knowledge Tracing\"\"\"\n",
        "    def __init__(self, df, stu2idx, t2idx, c2idx,\n",
        "                 unk_student_idx, unk_step_idx, unk_kc_idx):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.stu2idx = stu2idx\n",
        "        self.t2idx = t2idx\n",
        "        self.c2idx = c2idx\n",
        "        self.unk_student_idx = unk_student_idx\n",
        "        self.unk_step_idx = unk_step_idx\n",
        "        self.unk_kc_idx = unk_kc_idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        student_idx = self.stu2idx.get(row['student_id'], self.unk_student_idx)\n",
        "        step_idx = self.t2idx.get(row['step_id'], self.unk_step_idx)\n",
        "        kc_idx = self.c2idx.get(row['kc_id'], self.unk_kc_idx)\n",
        "        label = torch.tensor(row['correct'], dtype=torch.float32)\n",
        "        return student_idx, step_idx, kc_idx, label\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# FUNCTION 6: Training & Evaluation (UNCHANGED)\n",
        "# ============================================================\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stopping with model state saving\"\"\"\n",
        "    def __init__(self, patience=10, min_delta=0.001):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.best_state = None\n",
        "\n",
        "    def __call__(self, score, model):\n",
        "        if self.best_score is None or score > self.best_score + self.min_delta:\n",
        "            self.best_score = score\n",
        "            self.best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "\n",
        "    def load_best(self, model):\n",
        "        if self.best_state:\n",
        "            model.load_state_dict(self.best_state)\n",
        "\n",
        "\n",
        "def train_epoch(model, loader, optimizer, criterion, hetero_data, device,\n",
        "                config, grad_clip=1.0):\n",
        "    \"\"\"Train for one epoch with mastery update\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    for batch in loader:\n",
        "        student_idx, step_idx, kc_idx, labels = batch\n",
        "        student_idx = student_idx.to(device)\n",
        "        step_idx = step_idx.to(device)\n",
        "        kc_idx = kc_idx.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # 1. FORWARD (with current mastery - history up to t-1)\n",
        "        logits = model(hetero_data, student_idx, step_idx, kc_idx, device)\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        # 2. BACKWARD (update model weights)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        # 3. UPDATE MASTERY (AFTER backward, no gradient)\n",
        "        #    ⚠️ CRITICAL: This order prevents leakage\n",
        "        if hasattr(model, 'update_mastery_online'):\n",
        "            model.update_mastery_online(\n",
        "                student_idx, kc_idx, labels,\n",
        "                lambda_ema=config.LAMBDA_EMA\n",
        "            )\n",
        "\n",
        "        # Metrics\n",
        "        total_loss += loss.item() * len(labels)\n",
        "        all_preds.extend(torch.sigmoid(logits).detach().cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / len(loader.dataset)\n",
        "    auc = roc_auc_score(all_labels, all_preds) if len(set(all_labels)) > 1 else 0.5\n",
        "    acc = accuracy_score(all_labels, np.array(all_preds) > 0.5)\n",
        "\n",
        "    return avg_loss, auc, acc\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, criterion, hetero_data, device):\n",
        "    \"\"\"Evaluate without mastery update\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    for batch in loader:\n",
        "        student_idx, step_idx, kc_idx, labels = batch\n",
        "        student_idx = student_idx.to(device)\n",
        "        step_idx = step_idx.to(device)\n",
        "        kc_idx = kc_idx.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        logits = model(hetero_data, student_idx, step_idx, kc_idx, device)\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        total_loss += loss.item() * len(labels)\n",
        "        all_preds.extend(torch.sigmoid(logits).cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / len(loader.dataset)\n",
        "    auc = roc_auc_score(all_labels, all_preds) if len(set(all_labels)) > 1 else 0.5\n",
        "    acc = accuracy_score(all_labels, np.array(all_preds) > 0.5)\n",
        "\n",
        "    return avg_loss, auc, acc\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# FUNCTION 7: Full Single-Fold Pipeline (M3 FINAL - MODIFIED)\n",
        "# ============================================================\n",
        "\n",
        "def run_single_fold(df_train_fold, df_val_fold, config, fold_num=None, verbose=True):\n",
        "    \"\"\"\n",
        "    M3 FINAL: Run complete training pipeline for one fold\n",
        "\n",
        "    Key modification: RECALCULATE features each epoch with updated mastery\n",
        "    \"\"\"\n",
        "    device = config.DEVICE\n",
        "    prefix = f\"[Fold {fold_num}] \" if fold_num is not None else \"\"\n",
        "\n",
        "    # --- Step 1: Entity mappings ---\n",
        "    mappings, entity_counts, unk_indices = build_entity_mappings(df_train_fold)\n",
        "    if verbose:\n",
        "        print(f\"{prefix}Entities: S={entity_counts['num_students']}, \"\n",
        "              f\"Q={entity_counts['num_questions']}, \"\n",
        "              f\"T={entity_counts['num_steps']}, \"\n",
        "              f\"C={entity_counts['num_kcs']}\")\n",
        "\n",
        "    # --- Step 2: Build graph ---\n",
        "    hetero_data, total_edges = build_graph(df_train_fold, mappings, entity_counts, unk_indices)\n",
        "    if verbose:\n",
        "        print(f\"{prefix}Graph edges: {total_edges:,}\")\n",
        "\n",
        "    # --- Step 3: Model (init BEFORE features!) ---\n",
        "    model = GraphKTMinimal(\n",
        "        num_students=entity_counts['num_students'],\n",
        "        num_questions=entity_counts['num_questions'],\n",
        "        num_steps=entity_counts['num_steps'],\n",
        "        num_kcs=entity_counts['num_kcs'],\n",
        "        feature_dim=NUM_FEATURES,\n",
        "        embed_dim=config.EMBED_DIM,\n",
        "        hidden_dim=config.HIDDEN_DIM,\n",
        "        num_gnn_layers=config.NUM_GNN_LAYERS,\n",
        "        dropout=config.DROPOUT,\n",
        "        mastery_init=config.MASTERY_INIT,\n",
        "        mastery_gating=config.MASTERY_GATING\n",
        "    ).to(device)\n",
        "\n",
        "    # ⭐ M3 FINAL: Initialize mastery BEFORE computing features\n",
        "    model.init_mastery_matrix(device)\n",
        "\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    if verbose:\n",
        "        print(f\"{prefix}Model params: {total_params:,}\")\n",
        "\n",
        "    # --- Step 4: Initial node features WITH mastery ---\n",
        "    feat_tensors = compute_node_features_with_mastery(\n",
        "        df_train_fold, mappings, entity_counts, unk_indices,\n",
        "        model.mastery_matrix  # ← Pass current mastery\n",
        "    )\n",
        "    hetero_data['student'].x = feat_tensors['student']\n",
        "    hetero_data['question'].x = feat_tensors['question']\n",
        "    hetero_data['step'].x = feat_tensors['step']\n",
        "    hetero_data['kc'].x = feat_tensors['kc']\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"{prefix}Student features: {hetero_data['student'].x.shape} (5D + mastery)\")\n",
        "\n",
        "    # --- Step 5: DataLoaders ---\n",
        "    train_dataset = KTDatasetPure(\n",
        "        df_train_fold, mappings['stu2idx'], mappings['t2idx'], mappings['c2idx'],\n",
        "        unk_indices['student'], unk_indices['step'], unk_indices['kc']\n",
        "    )\n",
        "    val_dataset = KTDatasetPure(\n",
        "        df_val_fold, mappings['stu2idx'], mappings['t2idx'], mappings['c2idx'],\n",
        "        unk_indices['student'], unk_indices['step'], unk_indices['kc']\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True,\n",
        "                              pin_memory=True, num_workers=0)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=512, shuffle=False,\n",
        "                            pin_memory=True, num_workers=0)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"{prefix}Train: {len(train_loader.dataset):,} samples, \"\n",
        "              f\"Val: {len(val_loader.dataset):,} samples\")\n",
        "\n",
        "    # --- Step 6: Training setup ---\n",
        "    n_correct = df_train_fold['correct'].sum()\n",
        "    n_incorrect = len(df_train_fold) - n_correct\n",
        "    pos_weight = torch.tensor([n_incorrect / n_correct], dtype=torch.float32).to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=config.LEARNING_RATE,\n",
        "                                   weight_decay=config.WEIGHT_DECAY)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='max', factor=0.5, patience=5\n",
        "    )\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "    early_stopping = EarlyStopping(patience=config.PATIENCE)\n",
        "\n",
        "    # --- Step 7: Training loop ---\n",
        "    history = defaultdict(list)\n",
        "    best_val_auc = 0\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"{prefix}Training (pos_weight={pos_weight.item():.4f})...\")\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "    for epoch in range(config.EPOCHS):\n",
        "        epoch_start = time.time()\n",
        "\n",
        "        # ⭐ M3 FINAL: RECALCULATE features with updated mastery each epoch\n",
        "        feat_tensors = compute_node_features_with_mastery(\n",
        "            df_train_fold, mappings, entity_counts, unk_indices,\n",
        "            model.mastery_matrix  # ← Updated mastery from previous epoch\n",
        "        )\n",
        "        hetero_data['student'].x = feat_tensors['student']\n",
        "        hetero_data['question'].x = feat_tensors['question']\n",
        "        hetero_data['step'].x = feat_tensors['step']\n",
        "        hetero_data['kc'].x = feat_tensors['kc']\n",
        "\n",
        "        train_loss, train_auc, train_acc = train_epoch(\n",
        "            model, train_loader, optimizer, criterion, hetero_data, device, config, config.GRAD_CLIP\n",
        "        )\n",
        "        val_loss, val_auc, val_acc = evaluate(\n",
        "            model, val_loader, criterion, hetero_data, device\n",
        "        )\n",
        "\n",
        "        epoch_time = time.time() - epoch_start\n",
        "\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_auc'].append(train_auc)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_auc'].append(val_auc)\n",
        "        history['val_acc'].append(val_acc)\n",
        "\n",
        "        marker = \" ★\" if val_auc > best_val_auc else \"\"\n",
        "        if val_auc > best_val_auc:\n",
        "            best_val_auc = val_auc\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"{prefix}Epoch {epoch+1:3d}/{config.EPOCHS} | \"\n",
        "                  f\"Train AUC: {train_auc:.4f} | Val AUC: {val_auc:.4f} | \"\n",
        "                  f\"Val Acc: {val_acc:.4f} | Time: {epoch_time:.1f}s{marker}\")\n",
        "\n",
        "        scheduler.step(val_auc)\n",
        "        early_stopping(val_auc, model)\n",
        "\n",
        "        if early_stopping.early_stop:\n",
        "            if verbose:\n",
        "                print(f\"{prefix}Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "    early_stopping.load_best(model)\n",
        "\n",
        "    final_val_loss, final_val_auc, final_val_acc = evaluate(\n",
        "        model, val_loader, criterion, hetero_data, device\n",
        "    )\n",
        "\n",
        "    stopped_epoch = len(history['train_loss'])\n",
        "\n",
        "    if verbose:\n",
        "        print(\"-\" * 70)\n",
        "        print(f\"{prefix}Best Val AUC: {final_val_auc:.4f} | \"\n",
        "              f\"Val Acc: {final_val_acc:.4f} | Stopped at epoch: {stopped_epoch}\")\n",
        "\n",
        "    return {\n",
        "        'val_auc': final_val_auc,\n",
        "        'val_acc': final_val_acc,\n",
        "        'val_loss': final_val_loss,\n",
        "        'train_auc': history['train_auc'][-1],\n",
        "        'stopped_epoch': stopped_epoch,\n",
        "        'total_params': total_params,\n",
        "        'history': dict(history),\n",
        "        'model_state': early_stopping.best_state,\n",
        "        'hetero_data': hetero_data,\n",
        "        'mappings': mappings,\n",
        "        'entity_counts': entity_counts,\n",
        "        'unk_indices': unk_indices,\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Confirmation\n",
        "# ============================================================\n",
        "print(\"=\" * 60)\n",
        "print(\"✓ ALL PIPELINE FUNCTIONS DEFINED (M3 FINAL VERSION - FIXED)\")\n",
        "print(\"=\" * 60)\n",
        "print(\"  - build_entity_mappings() (unchanged)\")\n",
        "print(\"  - build_graph() (unchanged)\")\n",
        "print(\"  - compute_node_features_with_mastery() ⭐ NEW + FIXED\")\n",
        "print(\"  - GraphKTMinimal ⭐ FIXED (student encoder + mastery matrix)\")\n",
        "print(\"  - MasteryMessagePassing (mastery-weighted edges)\")\n",
        "print(\"  - KTDatasetPure (unchanged)\")\n",
        "print(\"  - train_epoch() / evaluate() (unchanged)\")\n",
        "print(\"  - run_single_fold() ⭐ MODIFIED (recalc features each epoch)\")\n",
        "print(\"=\" * 60)\n",
        "print(\"FIXES APPLIED:\")\n",
        "print(\"  ✅ mastery_matrix includes UNK KC: [num_students, num_kcs]\")\n",
        "print(\"  ✅ student_encoder input_dim: feature_dim + num_kcs\")\n",
        "print(\"  ✅ mastery moved to CPU before concatenation\")\n",
        "print(\"=\" * 60)\n",
        "print(\"M3 FINAL = M3a Features + M3b Weights + Dual Propagation\")\n",
        "print(\"=\" * 60)\n",
        "print(\"Ready for 5-Fold Cross-Validation! 🚀\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWsbyFg-o-po",
        "collapsed": true,
        "outputId": "93c47362-e5d4-49dd-c556-d9d516aa409c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "5-FOLD STUDENT-LEVEL CROSS-VALIDATION\n",
            "============================================================\n",
            "\n",
            "Protocol:\n",
            "  - 487 non-test students split into 5 folds\n",
            "  - Each fold: full pipeline rebuild (mappings, graph, features, model)\n",
            "  - All design decisions FROZEN before CV\n",
            "  - TEST set (87 students) completely untouched\n",
            "\n",
            "Frozen hyperparameters:\n",
            "  EMBED_DIM=32, HIDDEN_DIM=64\n",
            "  NUM_GNN_LAYERS=2, DROPOUT=0.2\n",
            "  LR=0.001, WEIGHT_DECAY=0.01\n",
            "  BATCH_SIZE=512, PATIENCE=10\n",
            "\n",
            "\n",
            "============================================================\n",
            "FOLD 1 / 5\n",
            "============================================================\n",
            "Train students: 389, Val students: 98\n",
            "Train interactions: 524,961, Val interactions: 166,472\n",
            "[Fold 1] Entities: S=390, Q=1064, T=146327, C=397\n",
            "[Fold 1] Graph edges: 662,288\n",
            "  ✓ Mastery matrix initialized: [390, 397] with value=0.5\n",
            "[Fold 1] Model params: 38,353\n",
            "[Fold 1] Student features: torch.Size([390, 402]) (5D + mastery)\n",
            "[Fold 1] Train: 524,961 samples, Val: 166,472 samples\n",
            "[Fold 1] Training (pos_weight=0.3041)...\n",
            "----------------------------------------------------------------------\n",
            "[Fold 1] Epoch   1/100 | Train AUC: 0.9036 | Val AUC: 0.7255 | Val Acc: 0.7284 | Time: 153.4s ★\n",
            "[Fold 1] Epoch   2/100 | Train AUC: 0.9146 | Val AUC: 0.7199 | Val Acc: 0.6447 | Time: 153.4s\n",
            "[Fold 1] Epoch   3/100 | Train AUC: 0.9179 | Val AUC: 0.7191 | Val Acc: 0.5743 | Time: 153.8s\n",
            "[Fold 1] Epoch   4/100 | Train AUC: 0.9192 | Val AUC: 0.7255 | Val Acc: 0.6063 | Time: 153.5s\n",
            "[Fold 1] Epoch   5/100 | Train AUC: 0.9200 | Val AUC: 0.7163 | Val Acc: 0.6036 | Time: 153.2s\n",
            "[Fold 1] Epoch   6/100 | Train AUC: 0.9206 | Val AUC: 0.7232 | Val Acc: 0.5847 | Time: 152.6s\n",
            "[Fold 1] Epoch   7/100 | Train AUC: 0.9212 | Val AUC: 0.7199 | Val Acc: 0.6185 | Time: 153.1s\n",
            "[Fold 1] Epoch   8/100 | Train AUC: 0.9222 | Val AUC: 0.7215 | Val Acc: 0.5507 | Time: 152.5s\n",
            "[Fold 1] Epoch   9/100 | Train AUC: 0.9225 | Val AUC: 0.7227 | Val Acc: 0.5736 | Time: 153.0s\n",
            "[Fold 1] Epoch  10/100 | Train AUC: 0.9227 | Val AUC: 0.7214 | Val Acc: 0.5679 | Time: 152.7s\n",
            "[Fold 1] Epoch  11/100 | Train AUC: 0.9229 | Val AUC: 0.7205 | Val Acc: 0.5898 | Time: 152.9s\n",
            "[Fold 1] Early stopping at epoch 11\n",
            "----------------------------------------------------------------------\n",
            "[Fold 1] Best Val AUC: 0.7251 | Val Acc: 0.7432 | Stopped at epoch: 11\n",
            "\n",
            "Fold 1 completed in 1777.5s\n",
            "\n",
            "============================================================\n",
            "FOLD 2 / 5\n",
            "============================================================\n",
            "Train students: 389, Val students: 98\n",
            "Train interactions: 579,228, Val interactions: 112,205\n",
            "[Fold 2] Entities: S=390, Q=1077, T=156768, C=406\n",
            "[Fold 2] Graph edges: 712,642\n",
            "  ✓ Mastery matrix initialized: [390, 406] with value=0.5\n",
            "[Fold 2] Model params: 38,641\n",
            "[Fold 2] Student features: torch.Size([390, 411]) (5D + mastery)\n",
            "[Fold 2] Train: 579,228 samples, Val: 112,205 samples\n",
            "[Fold 2] Training (pos_weight=0.2926)...\n",
            "----------------------------------------------------------------------\n",
            "[Fold 2] Epoch   1/100 | Train AUC: 0.9030 | Val AUC: 0.6964 | Val Acc: 0.6933 | Time: 160.5s ★\n",
            "[Fold 2] Epoch   2/100 | Train AUC: 0.9130 | Val AUC: 0.7003 | Val Acc: 0.6421 | Time: 160.0s ★\n",
            "[Fold 2] Epoch   3/100 | Train AUC: 0.9163 | Val AUC: 0.7110 | Val Acc: 0.6692 | Time: 160.3s ★\n",
            "[Fold 2] Epoch   4/100 | Train AUC: 0.9172 | Val AUC: 0.6952 | Val Acc: 0.6523 | Time: 159.5s\n",
            "[Fold 2] Epoch   5/100 | Train AUC: 0.9181 | Val AUC: 0.6937 | Val Acc: 0.5901 | Time: 160.1s\n",
            "[Fold 2] Epoch   6/100 | Train AUC: 0.9187 | Val AUC: 0.6989 | Val Acc: 0.6077 | Time: 160.6s\n",
            "[Fold 2] Epoch   7/100 | Train AUC: 0.9193 | Val AUC: 0.6923 | Val Acc: 0.6066 | Time: 160.3s\n",
            "[Fold 2] Epoch   8/100 | Train AUC: 0.9194 | Val AUC: 0.6943 | Val Acc: 0.6188 | Time: 159.8s\n",
            "[Fold 2] Epoch   9/100 | Train AUC: 0.9197 | Val AUC: 0.6949 | Val Acc: 0.5986 | Time: 159.9s\n",
            "[Fold 2] Epoch  10/100 | Train AUC: 0.9208 | Val AUC: 0.6978 | Val Acc: 0.5958 | Time: 159.9s\n",
            "[Fold 2] Epoch  11/100 | Train AUC: 0.9209 | Val AUC: 0.6987 | Val Acc: 0.6046 | Time: 160.0s\n",
            "[Fold 2] Epoch  12/100 | Train AUC: 0.9213 | Val AUC: 0.6947 | Val Acc: 0.6139 | Time: 160.2s\n",
            "[Fold 2] Epoch  13/100 | Train AUC: 0.9213 | Val AUC: 0.6943 | Val Acc: 0.6343 | Time: 159.9s\n",
            "[Fold 2] Early stopping at epoch 13\n",
            "----------------------------------------------------------------------\n",
            "[Fold 2] Best Val AUC: 0.7109 | Val Acc: 0.6711 | Stopped at epoch: 13\n",
            "\n",
            "Fold 2 completed in 2171.9s\n",
            "\n",
            "============================================================\n",
            "FOLD 3 / 5\n",
            "============================================================\n",
            "Train students: 390, Val students: 97\n",
            "Train interactions: 537,828, Val interactions: 153,605\n",
            "[Fold 3] Entities: S=391, Q=1078, T=150244, C=415\n",
            "[Fold 3] Graph edges: 680,518\n",
            "  ✓ Mastery matrix initialized: [391, 415] with value=0.5\n",
            "[Fold 3] Model params: 38,929\n",
            "[Fold 3] Student features: torch.Size([391, 420]) (5D + mastery)\n",
            "[Fold 3] Train: 537,828 samples, Val: 153,605 samples\n",
            "[Fold 3] Training (pos_weight=0.3030)...\n",
            "----------------------------------------------------------------------\n",
            "[Fold 3] Epoch   1/100 | Train AUC: 0.9050 | Val AUC: 0.7662 | Val Acc: 0.7421 | Time: 156.5s ★\n",
            "[Fold 3] Epoch   2/100 | Train AUC: 0.9158 | Val AUC: 0.7610 | Val Acc: 0.6806 | Time: 155.9s\n",
            "[Fold 3] Epoch   3/100 | Train AUC: 0.9188 | Val AUC: 0.7495 | Val Acc: 0.6417 | Time: 155.5s\n",
            "[Fold 3] Epoch   4/100 | Train AUC: 0.9204 | Val AUC: 0.7443 | Val Acc: 0.6199 | Time: 155.5s\n",
            "[Fold 3] Epoch   5/100 | Train AUC: 0.9212 | Val AUC: 0.7396 | Val Acc: 0.5777 | Time: 155.1s\n",
            "[Fold 3] Epoch   6/100 | Train AUC: 0.9217 | Val AUC: 0.7443 | Val Acc: 0.4079 | Time: 156.0s\n",
            "[Fold 3] Epoch   7/100 | Train AUC: 0.9221 | Val AUC: 0.7364 | Val Acc: 0.6039 | Time: 156.2s\n",
            "[Fold 3] Epoch   8/100 | Train AUC: 0.9232 | Val AUC: 0.7361 | Val Acc: 0.6021 | Time: 156.0s\n",
            "[Fold 3] Epoch   9/100 | Train AUC: 0.9232 | Val AUC: 0.7332 | Val Acc: 0.6093 | Time: 154.9s\n",
            "[Fold 3] Epoch  10/100 | Train AUC: 0.9237 | Val AUC: 0.7323 | Val Acc: 0.5817 | Time: 155.1s\n",
            "[Fold 3] Epoch  11/100 | Train AUC: 0.9239 | Val AUC: 0.7307 | Val Acc: 0.6152 | Time: 155.5s\n",
            "[Fold 3] Early stopping at epoch 11\n",
            "----------------------------------------------------------------------\n",
            "[Fold 3] Best Val AUC: 0.7634 | Val Acc: 0.7599 | Stopped at epoch: 11\n",
            "\n",
            "Fold 3 completed in 1805.2s\n",
            "\n",
            "============================================================\n",
            "FOLD 4 / 5\n",
            "============================================================\n",
            "Train students: 390, Val students: 97\n",
            "Train interactions: 557,654, Val interactions: 133,779\n",
            "[Fold 4] Entities: S=391, Q=1078, T=154760, C=415\n",
            "[Fold 4] Graph edges: 701,006\n",
            "  ✓ Mastery matrix initialized: [391, 415] with value=0.5\n",
            "[Fold 4] Model params: 38,929\n",
            "[Fold 4] Student features: torch.Size([391, 420]) (5D + mastery)\n",
            "[Fold 4] Train: 557,654 samples, Val: 133,779 samples\n",
            "[Fold 4] Training (pos_weight=0.3031)...\n",
            "----------------------------------------------------------------------\n",
            "[Fold 4] Epoch   1/100 | Train AUC: 0.9051 | Val AUC: 0.7271 | Val Acc: 0.7254 | Time: 157.3s ★\n",
            "[Fold 4] Epoch   2/100 | Train AUC: 0.9151 | Val AUC: 0.7282 | Val Acc: 0.6765 | Time: 158.0s ★\n",
            "[Fold 4] Epoch   3/100 | Train AUC: 0.9185 | Val AUC: 0.7291 | Val Acc: 0.6413 | Time: 158.6s ★\n",
            "[Fold 4] Epoch   4/100 | Train AUC: 0.9199 | Val AUC: 0.7305 | Val Acc: 0.6260 | Time: 158.7s ★\n",
            "[Fold 4] Epoch   5/100 | Train AUC: 0.9206 | Val AUC: 0.7309 | Val Acc: 0.6314 | Time: 159.1s ★\n",
            "[Fold 4] Epoch   6/100 | Train AUC: 0.9214 | Val AUC: 0.7232 | Val Acc: 0.5987 | Time: 158.1s\n",
            "[Fold 4] Epoch   7/100 | Train AUC: 0.9219 | Val AUC: 0.7276 | Val Acc: 0.5464 | Time: 159.0s\n",
            "[Fold 4] Epoch   8/100 | Train AUC: 0.9222 | Val AUC: 0.7252 | Val Acc: 0.6230 | Time: 157.9s\n",
            "[Fold 4] Epoch   9/100 | Train AUC: 0.9224 | Val AUC: 0.7231 | Val Acc: 0.6337 | Time: 158.2s\n",
            "[Fold 4] Epoch  10/100 | Train AUC: 0.9227 | Val AUC: 0.7256 | Val Acc: 0.5807 | Time: 158.6s\n",
            "[Fold 4] Epoch  11/100 | Train AUC: 0.9232 | Val AUC: 0.7201 | Val Acc: 0.6102 | Time: 157.8s\n",
            "[Fold 4] Epoch  12/100 | Train AUC: 0.9240 | Val AUC: 0.7277 | Val Acc: 0.6058 | Time: 158.5s\n",
            "[Fold 4] Epoch  13/100 | Train AUC: 0.9241 | Val AUC: 0.7200 | Val Acc: 0.5974 | Time: 158.0s\n",
            "[Fold 4] Epoch  14/100 | Train AUC: 0.9243 | Val AUC: 0.7246 | Val Acc: 0.6191 | Time: 158.8s\n",
            "[Fold 4] Early stopping at epoch 14\n",
            "----------------------------------------------------------------------\n",
            "[Fold 4] Best Val AUC: 0.7304 | Val Acc: 0.6259 | Stopped at epoch: 14\n",
            "\n",
            "Fold 4 completed in 2308.3s\n",
            "\n",
            "============================================================\n",
            "FOLD 5 / 5\n",
            "============================================================\n",
            "Train students: 390, Val students: 97\n",
            "Train interactions: 566,061, Val interactions: 125,372\n",
            "[Fold 5] Entities: S=391, Q=1072, T=155983, C=414\n",
            "[Fold 5] Graph edges: 707,298\n",
            "  ✓ Mastery matrix initialized: [391, 414] with value=0.5\n",
            "[Fold 5] Model params: 38,897\n",
            "[Fold 5] Student features: torch.Size([391, 419]) (5D + mastery)\n",
            "[Fold 5] Train: 566,061 samples, Val: 125,372 samples\n",
            "[Fold 5] Training (pos_weight=0.2975)...\n",
            "----------------------------------------------------------------------\n",
            "[Fold 5] Epoch   1/100 | Train AUC: 0.9061 | Val AUC: 0.7271 | Val Acc: 0.7451 | Time: 158.9s ★\n",
            "[Fold 5] Epoch   2/100 | Train AUC: 0.9155 | Val AUC: 0.7248 | Val Acc: 0.6549 | Time: 159.3s\n",
            "[Fold 5] Epoch   3/100 | Train AUC: 0.9184 | Val AUC: 0.7226 | Val Acc: 0.6057 | Time: 159.5s\n",
            "[Fold 5] Epoch   4/100 | Train AUC: 0.9198 | Val AUC: 0.7220 | Val Acc: 0.5773 | Time: 159.5s\n",
            "[Fold 5] Epoch   5/100 | Train AUC: 0.9206 | Val AUC: 0.7231 | Val Acc: 0.6164 | Time: 158.8s\n",
            "[Fold 5] Epoch   6/100 | Train AUC: 0.9213 | Val AUC: 0.7241 | Val Acc: 0.6211 | Time: 159.7s\n",
            "[Fold 5] Epoch   7/100 | Train AUC: 0.9217 | Val AUC: 0.7226 | Val Acc: 0.5413 | Time: 160.2s\n",
            "[Fold 5] Epoch   8/100 | Train AUC: 0.9225 | Val AUC: 0.7236 | Val Acc: 0.5856 | Time: 159.3s\n",
            "[Fold 5] Epoch   9/100 | Train AUC: 0.9231 | Val AUC: 0.7240 | Val Acc: 0.6200 | Time: 161.4s\n",
            "[Fold 5] Epoch  10/100 | Train AUC: 0.9233 | Val AUC: 0.7245 | Val Acc: 0.6053 | Time: 158.7s\n",
            "[Fold 5] Epoch  11/100 | Train AUC: 0.9234 | Val AUC: 0.7264 | Val Acc: 0.5971 | Time: 159.5s\n",
            "[Fold 5] Early stopping at epoch 11\n",
            "----------------------------------------------------------------------\n",
            "[Fold 5] Best Val AUC: 0.7271 | Val Acc: 0.7878 | Stopped at epoch: 11\n",
            "\n",
            "Fold 5 completed in 1846.6s\n",
            "\n",
            "============================================================\n",
            "5-FOLD CROSS-VALIDATION RESULTS\n",
            "============================================================\n",
            "\n",
            "Fold     Val AUC      Val Acc      Epochs    \n",
            "------------------------------------------\n",
            "Fold 1   0.7251       0.7432       11        \n",
            "Fold 2   0.7109       0.6711       13        \n",
            "Fold 3   0.7634       0.7599       11        \n",
            "Fold 4   0.7304       0.6259       14        \n",
            "Fold 5   0.7271       0.7878       11        \n",
            "------------------------------------------\n",
            "Mean     0.7314       0.7176       12.0      \n",
            "Std      0.0174       0.0599       1.3       \n",
            "Min      0.7109       0.6259       11        \n",
            "Max      0.7634       0.7878       14        \n",
            "\n",
            "╔══════════════════════════════════════════════╗\n",
            "║  CV Val AUC: 0.7314 ± 0.0174              ║\n",
            "║  CV Val Acc: 0.7176 ± 0.0599              ║\n",
            "╚══════════════════════════════════════════════╝\n",
            "\n",
            "Total CV time: 9909.3s (165.2 min)\n",
            "\n",
            "Average stopping epoch: 12 (will use for final training)\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Cell 6: Run 5-Fold Student-Level Cross-Validation\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"5-FOLD STUDENT-LEVEL CROSS-VALIDATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\"\"\n",
        "Protocol:\n",
        "  - {len(non_test_students)} non-test students split into 5 folds\n",
        "  - Each fold: full pipeline rebuild (mappings, graph, features, model)\n",
        "  - All design decisions FROZEN before CV\n",
        "  - TEST set ({len(test_students)} students) completely untouched\n",
        "\n",
        "Frozen hyperparameters:\n",
        "  EMBED_DIM={config.EMBED_DIM}, HIDDEN_DIM={config.HIDDEN_DIM}\n",
        "  NUM_GNN_LAYERS={config.NUM_GNN_LAYERS}, DROPOUT={config.DROPOUT}\n",
        "  LR={config.LEARNING_RATE}, WEIGHT_DECAY={config.WEIGHT_DECAY}\n",
        "  BATCH_SIZE=512, PATIENCE={config.PATIENCE}\n",
        "\"\"\")\n",
        "\n",
        "cv_results = []\n",
        "cv_start = time.time()\n",
        "\n",
        "for fold_idx in range(5):\n",
        "    fold_start = time.time()\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"FOLD {fold_idx + 1} / 5\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Get this fold's students\n",
        "    train_students_fold = fold_assignments[fold_idx]['train_students']\n",
        "    val_students_fold = fold_assignments[fold_idx]['val_students']\n",
        "\n",
        "    # Create dataframes for this fold\n",
        "    df_train_fold = df_non_test[df_non_test['student_id'].isin(train_students_fold)].copy()\n",
        "    df_val_fold = df_non_test[df_non_test['student_id'].isin(val_students_fold)].copy()\n",
        "\n",
        "    print(f\"Train students: {len(train_students_fold)}, \"\n",
        "          f\"Val students: {len(val_students_fold)}\")\n",
        "    print(f\"Train interactions: {len(df_train_fold):,}, \"\n",
        "          f\"Val interactions: {len(df_val_fold):,}\")\n",
        "\n",
        "    # Run full pipeline for this fold\n",
        "    result = run_single_fold(\n",
        "        df_train_fold, df_val_fold, config,\n",
        "        fold_num=fold_idx + 1, verbose=True\n",
        "    )\n",
        "\n",
        "    fold_time = time.time() - fold_start\n",
        "    result['fold_time'] = fold_time\n",
        "    cv_results.append(result)\n",
        "\n",
        "    print(f\"\\nFold {fold_idx + 1} completed in {fold_time:.1f}s\")\n",
        "\n",
        "total_cv_time = time.time() - cv_start\n",
        "\n",
        "# ============================================================\n",
        "# CV Summary\n",
        "# ============================================================\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"5-FOLD CROSS-VALIDATION RESULTS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "val_aucs = [r['val_auc'] for r in cv_results]\n",
        "val_accs = [r['val_acc'] for r in cv_results]\n",
        "stopped_epochs = [r['stopped_epoch'] for r in cv_results]\n",
        "\n",
        "print(f\"\\n{'Fold':<8} {'Val AUC':<12} {'Val Acc':<12} {'Epochs':<10}\")\n",
        "print(\"-\" * 42)\n",
        "for i, r in enumerate(cv_results):\n",
        "    print(f\"Fold {i+1:<3} {r['val_auc']:<12.4f} {r['val_acc']:<12.4f} {r['stopped_epoch']:<10}\")\n",
        "\n",
        "print(\"-\" * 42)\n",
        "print(f\"{'Mean':<8} {np.mean(val_aucs):<12.4f} {np.mean(val_accs):<12.4f} {np.mean(stopped_epochs):<10.1f}\")\n",
        "print(f\"{'Std':<8} {np.std(val_aucs):<12.4f} {np.std(val_accs):<12.4f} {np.std(stopped_epochs):<10.1f}\")\n",
        "print(f\"{'Min':<8} {np.min(val_aucs):<12.4f} {np.min(val_accs):<12.4f} {np.min(stopped_epochs):<10}\")\n",
        "print(f\"{'Max':<8} {np.max(val_aucs):<12.4f} {np.max(val_accs):<12.4f} {np.max(stopped_epochs):<10}\")\n",
        "\n",
        "print(f\"\\n╔══════════════════════════════════════════════╗\")\n",
        "print(f\"║  CV Val AUC: {np.mean(val_aucs):.4f} ± {np.std(val_aucs):.4f}              ║\")\n",
        "print(f\"║  CV Val Acc: {np.mean(val_accs):.4f} ± {np.std(val_accs):.4f}              ║\")\n",
        "print(f\"╚══════════════════════════════════════════════╝\")\n",
        "\n",
        "print(f\"\\nTotal CV time: {total_cv_time:.1f}s ({total_cv_time/60:.1f} min)\")\n",
        "\n",
        "# Store average epochs for final training\n",
        "avg_epochs_cv = int(np.mean(stopped_epochs))\n",
        "print(f\"\\nAverage stopping epoch: {avg_epochs_cv} (will use for final training)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "id": "RDUnF4Kto-pp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80bb60e5-3fb3-4f98-a2b7-ecdc1d9fa20e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "FINAL TEST EVALUATION (M3 FINAL)\n",
            "============================================================\n",
            "\n",
            "Protocol:\n",
            "  - Train on ALL 487 non-test students (no validation split)\n",
            "  - Train for 12 epochs (average from CV, no early stopping)\n",
            "  - Evaluate on held-out TEST set (87 students)\n",
            "  - Features recalculated each epoch with updated mastery (M3 FINAL)\n",
            "  - This number appears in the paper as TEST performance\n",
            "\n",
            "[1/6] Building entity mappings from all non-test data...\n",
            "  S=488, Q=1081, T=184307, C=428\n",
            "[2/6] Building graph...\n",
            "  Edges: 839,032\n",
            "[3/6] Creating model...\n",
            "  ✓ Mastery matrix initialized: [488, 428] with value=0.5\n",
            "  Model params: 39,345\n",
            "[4/6] Computing initial node features WITH mastery...\n",
            "  Student features: torch.Size([488, 433]) (5D + mastery)\n",
            "[5/6] Creating dataloaders...\n",
            "  Train: 691,433 samples\n",
            "  Test:  118,261 samples\n",
            "[6/6] Training final model...\n",
            "\n",
            "Training for 12 epochs (CV average)...\n",
            "----------------------------------------------------------------------\n",
            "Epoch   1/12 | Train Loss: 0.1760 | Train AUC: 0.9050 | Train Acc: 0.8091 | Time: 180.4s\n",
            "Epoch   5/12 | Train Loss: 0.1621 | Train AUC: 0.9185 | Train Acc: 0.8226 | Time: 179.7s\n",
            "Epoch  10/12 | Train Loss: 0.1602 | Train AUC: 0.9203 | Train Acc: 0.8237 | Time: 179.6s\n",
            "Epoch  12/12 | Train Loss: 0.1598 | Train AUC: 0.9208 | Train Acc: 0.8247 | Time: 180.1s\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Evaluating on TEST set...\n",
            "\n",
            "============================================================\n",
            "FINAL RESULTS (M3 FINAL)\n",
            "============================================================\n",
            "\n",
            "╔══════════════════════════════════════════════════════════════╗\n",
            "║         GraphKT M3 FINAL (Features + Weights + Dual)         ║\n",
            "║                    Algebra 2005-2006 Dataset                 ║\n",
            "╠══════════════════════════════════════════════════════════════╣\n",
            "║                                                              ║\n",
            "║  5-Fold CV Validation:                                       ║\n",
            "║    AUC:      0.7314 ± 0.0174                              ║\n",
            "║    Accuracy: 0.7176 ± 0.0599                              ║\n",
            "║                                                              ║\n",
            "║  Test Set (held-out, 87 students):                          ║\n",
            "║    AUC:      0.7203                                        ║\n",
            "║    Accuracy: 0.6444                                        ║\n",
            "║                                                              ║\n",
            "║  Model: 39,345 parameters                              ║\n",
            "║  Training: 12 epochs (CV average)                           ║\n",
            "║  Split: Student-level (Split B), no leakage                  ║\n",
            "║                                                              ║\n",
            "║  Architecture:                                               ║\n",
            "║    • Student features: [5D + mastery] dynamic                ║\n",
            "║    • Dual propagation (Structural + Knowledge)               ║\n",
            "║    • Mastery in features AND weights                         ║\n",
            "║                                                              ║\n",
            "╚══════════════════════════════════════════════════════════════╝\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Cell 7: Final TEST Set Evaluation (M3 FINAL)\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"FINAL TEST EVALUATION (M3 FINAL)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\"\"\n",
        "Protocol:\n",
        "  - Train on ALL {len(non_test_students)} non-test students (no validation split)\n",
        "  - Train for {avg_epochs_cv} epochs (average from CV, no early stopping)\n",
        "  - Evaluate on held-out TEST set ({len(test_students)} students)\n",
        "  - Features recalculated each epoch with updated mastery (M3 FINAL)\n",
        "  - This number appears in the paper as TEST performance\n",
        "\"\"\")\n",
        "\n",
        "# --- Train on all non-test data ---\n",
        "df_train_final = df_non_test.copy()\n",
        "\n",
        "print(\"[1/6] Building entity mappings from all non-test data...\")\n",
        "mappings_final, entity_counts_final, unk_indices_final = build_entity_mappings(df_train_final)\n",
        "print(f\"  S={entity_counts_final['num_students']}, \"\n",
        "      f\"Q={entity_counts_final['num_questions']}, \"\n",
        "      f\"T={entity_counts_final['num_steps']}, \"\n",
        "      f\"C={entity_counts_final['num_kcs']}\")\n",
        "\n",
        "print(\"[2/6] Building graph...\")\n",
        "hetero_data_final, total_edges_final = build_graph(\n",
        "    df_train_final, mappings_final, entity_counts_final, unk_indices_final\n",
        ")\n",
        "print(f\"  Edges: {total_edges_final:,}\")\n",
        "\n",
        "# ⭐ M3 FINAL: Create model BEFORE features\n",
        "print(\"[3/6] Creating model...\")\n",
        "device = config.DEVICE\n",
        "\n",
        "model_final = GraphKTMinimal(\n",
        "    num_students=entity_counts_final['num_students'],\n",
        "    num_questions=entity_counts_final['num_questions'],\n",
        "    num_steps=entity_counts_final['num_steps'],\n",
        "    num_kcs=entity_counts_final['num_kcs'],\n",
        "    feature_dim=NUM_FEATURES,\n",
        "    embed_dim=config.EMBED_DIM,\n",
        "    hidden_dim=config.HIDDEN_DIM,\n",
        "    num_gnn_layers=config.NUM_GNN_LAYERS,\n",
        "    dropout=config.DROPOUT,\n",
        "    mastery_init=config.MASTERY_INIT,\n",
        "    mastery_gating=config.MASTERY_GATING\n",
        ").to(device)\n",
        "\n",
        "# ⭐ M3 FINAL: Init mastery BEFORE features\n",
        "model_final.init_mastery_matrix(device)\n",
        "\n",
        "total_params_final = sum(p.numel() for p in model_final.parameters())\n",
        "print(f\"  Model params: {total_params_final:,}\")\n",
        "\n",
        "print(\"[4/6] Computing initial node features WITH mastery...\")\n",
        "feat_tensors_final = compute_node_features_with_mastery(\n",
        "    df_train_final, mappings_final, entity_counts_final, unk_indices_final,\n",
        "    model_final.mastery_matrix  # ← Pass mastery\n",
        ")\n",
        "hetero_data_final['student'].x = feat_tensors_final['student']\n",
        "hetero_data_final['question'].x = feat_tensors_final['question']\n",
        "hetero_data_final['step'].x = feat_tensors_final['step']\n",
        "hetero_data_final['kc'].x = feat_tensors_final['kc']\n",
        "\n",
        "print(f\"  Student features: {hetero_data_final['student'].x.shape} (5D + mastery)\")\n",
        "\n",
        "print(\"[5/6] Creating dataloaders...\")\n",
        "train_dataset_final = KTDatasetPure(\n",
        "    df_train_final,\n",
        "    mappings_final['stu2idx'], mappings_final['t2idx'], mappings_final['c2idx'],\n",
        "    unk_indices_final['student'], unk_indices_final['step'], unk_indices_final['kc']\n",
        ")\n",
        "test_dataset_final = KTDatasetPure(\n",
        "    df_test_final,\n",
        "    mappings_final['stu2idx'], mappings_final['t2idx'], mappings_final['c2idx'],\n",
        "    unk_indices_final['student'], unk_indices_final['step'], unk_indices_final['kc']\n",
        ")\n",
        "\n",
        "train_loader_final = DataLoader(train_dataset_final, batch_size=512, shuffle=True,\n",
        "                                 pin_memory=True, num_workers=0)\n",
        "test_loader_final = DataLoader(test_dataset_final, batch_size=512, shuffle=False,\n",
        "                                pin_memory=True, num_workers=0)\n",
        "\n",
        "print(f\"  Train: {len(train_dataset_final):,} samples\")\n",
        "print(f\"  Test:  {len(test_dataset_final):,} samples\")\n",
        "\n",
        "print(\"[6/6] Training final model...\")\n",
        "\n",
        "# Class weights from full training set\n",
        "n_correct = df_train_final['correct'].sum()\n",
        "n_incorrect = len(df_train_final) - n_correct\n",
        "pos_weight_final = torch.tensor([n_incorrect / n_correct], dtype=torch.float32).to(device)\n",
        "\n",
        "optimizer_final = torch.optim.AdamW(model_final.parameters(), lr=config.LEARNING_RATE,\n",
        "                                      weight_decay=config.WEIGHT_DECAY)\n",
        "scheduler_final = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer_final, mode='min', factor=0.5, patience=5\n",
        ")\n",
        "criterion_final = nn.BCEWithLogitsLoss(pos_weight=pos_weight_final)\n",
        "\n",
        "# Train for fixed number of epochs (from CV average)\n",
        "print(f\"\\nTraining for {avg_epochs_cv} epochs (CV average)...\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "for epoch in range(avg_epochs_cv):\n",
        "    epoch_start = time.time()\n",
        "\n",
        "    # ⭐ M3 FINAL: RECALCULATE features with updated mastery each epoch\n",
        "    feat_tensors_final = compute_node_features_with_mastery(\n",
        "        df_train_final, mappings_final, entity_counts_final, unk_indices_final,\n",
        "        model_final.mastery_matrix  # ← Updated mastery from previous epoch\n",
        "    )\n",
        "    hetero_data_final['student'].x = feat_tensors_final['student']\n",
        "    hetero_data_final['question'].x = feat_tensors_final['question']\n",
        "    hetero_data_final['step'].x = feat_tensors_final['step']\n",
        "    hetero_data_final['kc'].x = feat_tensors_final['kc']\n",
        "\n",
        "    train_loss, train_auc, train_acc = train_epoch(\n",
        "        model_final, train_loader_final, optimizer_final, criterion_final,\n",
        "        hetero_data_final, device, config, config.GRAD_CLIP\n",
        "    )\n",
        "\n",
        "    epoch_time = time.time() - epoch_start\n",
        "\n",
        "    if (epoch + 1) % 5 == 0 or epoch == 0 or (epoch + 1) == avg_epochs_cv:\n",
        "        print(f\"Epoch {epoch+1:3d}/{avg_epochs_cv} | \"\n",
        "              f\"Train Loss: {train_loss:.4f} | Train AUC: {train_auc:.4f} | \"\n",
        "              f\"Train Acc: {train_acc:.4f} | Time: {epoch_time:.1f}s\")\n",
        "\n",
        "    scheduler_final.step(train_loss)\n",
        "\n",
        "print(\"-\" * 70)\n",
        "\n",
        "# --- Final TEST evaluation ---\n",
        "print(\"\\nEvaluating on TEST set...\")\n",
        "test_loss, test_auc, test_acc = evaluate(\n",
        "    model_final, test_loader_final, criterion_final,\n",
        "    hetero_data_final, device\n",
        ")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"FINAL RESULTS (M3 FINAL)\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"\"\"\n",
        "╔══════════════════════════════════════════════════════════════╗\n",
        "║         GraphKT M3 FINAL (Features + Weights + Dual)         ║\n",
        "║                    Algebra 2005-2006 Dataset                 ║\n",
        "╠══════════════════════════════════════════════════════════════╣\n",
        "║                                                              ║\n",
        "║  5-Fold CV Validation:                                       ║\n",
        "║    AUC:      {np.mean(val_aucs):.4f} ± {np.std(val_aucs):.4f}                              ║\n",
        "║    Accuracy: {np.mean(val_accs):.4f} ± {np.std(val_accs):.4f}                              ║\n",
        "║                                                              ║\n",
        "║  Test Set (held-out, {len(test_students)} students):                          ║\n",
        "║    AUC:      {test_auc:.4f}                                        ║\n",
        "║    Accuracy: {test_acc:.4f}                                        ║\n",
        "║                                                              ║\n",
        "║  Model: {total_params_final:,} parameters                              ║\n",
        "║  Training: {avg_epochs_cv} epochs (CV average)                           ║\n",
        "║  Split: Student-level (Split B), no leakage                  ║\n",
        "║                                                              ║\n",
        "║  Architecture:                                               ║\n",
        "║    • Student features: [5D + mastery] dynamic                ║\n",
        "║    • Dual propagation (Structural + Knowledge)               ║\n",
        "║    • Mastery in features AND weights                         ║\n",
        "║                                                              ║\n",
        "╚══════════════════════════════════════════════════════════════╝\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9qu-TFRao-pp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "533883ac-a3e1-4e67-ee08-fd82dd59f2a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "DETAILED RESULTS FOR PAPER (M3 FINAL)\n",
            "============================================================\n",
            "\n",
            "Table 1: Per-Fold Cross-Validation Results\n",
            "-------------------------------------------------------\n",
            "Fold   Students   Interactions   Val AUC    Val Acc    Epochs  \n",
            "-------------------------------------------------------\n",
            "1      98         166,472        0.7251     0.7432     11      \n",
            "2      98         112,205        0.7109     0.6711     13      \n",
            "3      97         153,605        0.7634     0.7599     11      \n",
            "4      97         133,779        0.7304     0.6259     14      \n",
            "5      97         125,372        0.7271     0.7878     11      \n",
            "-------------------------------------------------------\n",
            "Mean                             0.7314     0.7176     12.0    \n",
            "±Std                             0.0174     0.0599     1.3     \n",
            "\n",
            "\n",
            "Table 2: Model Comparison (for paper)\n",
            "-----------------------------------------------------------------\n",
            "Model                Val AUC          Test AUC     Params    \n",
            "-----------------------------------------------------------------\n",
            "GraphKT M3 Final     0.7314 ± 0.0174   0.7203       39,345\n",
            "\n",
            "  Architecture: Features + Weights + Dual Propagation\n",
            "  - Student features: [5D + mastery] (dynamic)\n",
            "  - Dual propagation: Structural (Q↔T↔C) + Knowledge (S↔C weighted)\n",
            "  - Mastery in both features AND edge weights\n",
            "\n",
            "\n",
            "Consistency Analysis:\n",
            "  AUC range across folds: 0.0525\n",
            "  ⚠ High variance across folds - investigate fold differences\n",
            "\n",
            "  Coefficient of variation: 2.37%\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# Cell 8: Paper-Ready Results Summary & Per-Fold Analysis (M3 FINAL)\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"DETAILED RESULTS FOR PAPER (M3 FINAL)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Per-fold table\n",
        "print(\"\\nTable 1: Per-Fold Cross-Validation Results\")\n",
        "print(\"-\" * 55)\n",
        "print(f\"{'Fold':<6} {'Students':<10} {'Interactions':<14} {'Val AUC':<10} {'Val Acc':<10} {'Epochs':<8}\")\n",
        "print(\"-\" * 55)\n",
        "for i, r in enumerate(cv_results):\n",
        "    n_val_stu = len(fold_assignments[i]['val_students'])\n",
        "    df_val_f = df_non_test[df_non_test['student_id'].isin(fold_assignments[i]['val_students'])]\n",
        "    n_val_int = len(df_val_f)\n",
        "    print(f\"{i+1:<6} {n_val_stu:<10} {n_val_int:<14,} {r['val_auc']:<10.4f} {r['val_acc']:<10.4f} {r['stopped_epoch']:<8}\")\n",
        "\n",
        "print(\"-\" * 55)\n",
        "print(f\"{'Mean':<6} {'':10} {'':14} {np.mean(val_aucs):<10.4f} {np.mean(val_accs):<10.4f} {np.mean(stopped_epochs):<8.1f}\")\n",
        "print(f\"{'±Std':<6} {'':10} {'':14} {np.std(val_aucs):<10.4f} {np.std(val_accs):<10.4f} {np.std(stopped_epochs):<8.1f}\")\n",
        "\n",
        "# Summary table for paper\n",
        "print(f\"\\n\\nTable 2: Model Comparison (for paper)\")\n",
        "print(\"-\" * 65)\n",
        "print(f\"{'Model':<20} {'Val AUC':<16} {'Test AUC':<12} {'Params':<10}\")\n",
        "print(\"-\" * 65)\n",
        "print(f\"{'GraphKT M3 Final':<20} {np.mean(val_aucs):.4f} ± {np.std(val_aucs):.4f}   {test_auc:<12.4f} {sum(p.numel() for p in model_final.parameters()):,}\")\n",
        "\n",
        "print(\"\\n  Architecture: Features + Weights + Dual Propagation\")\n",
        "print(\"  - Student features: [5D + mastery] (dynamic)\")\n",
        "print(\"  - Dual propagation: Structural (Q↔T↔C) + Knowledge (S↔C weighted)\")\n",
        "print(\"  - Mastery in both features AND edge weights\")\n",
        "\n",
        "# Consistency check\n",
        "auc_range = np.max(val_aucs) - np.min(val_aucs)\n",
        "print(f\"\\n\\nConsistency Analysis:\")\n",
        "print(f\"  AUC range across folds: {auc_range:.4f}\")\n",
        "if auc_range < 0.03:\n",
        "    print(f\"  ✓ Highly consistent (range < 0.03)\")\n",
        "elif auc_range < 0.05:\n",
        "    print(f\"  ~ Moderately consistent (range < 0.05)\")\n",
        "else:\n",
        "    print(f\"  ⚠ High variance across folds - investigate fold differences\")\n",
        "\n",
        "print(f\"\\n  Coefficient of variation: {np.std(val_aucs)/np.mean(val_aucs)*100:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}